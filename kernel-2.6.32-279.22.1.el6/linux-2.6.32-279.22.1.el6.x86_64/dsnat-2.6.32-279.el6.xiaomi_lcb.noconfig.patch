diff --git a/include/linux/ip_vs.h b/include/linux/ip_vs.h
old mode 100644
new mode 100755
index fc3e41b..0359ee2
--- a/include/linux/ip_vs.h
+++ b/include/linux/ip_vs.h
@@ -1,6 +1,9 @@
 /*
  *      IP Virtual Server
  *      data structure and functionality definitions
+ *
+ *  Changes:
+ *      Yu Bo        <yubo@xiaomi.com>
  */
 
 #ifndef _IP_VS_H
@@ -55,7 +58,11 @@
 #define IP_VS_SO_SET_RESTORE    (IP_VS_BASE_CTL+13)
 #define IP_VS_SO_SET_SAVE       (IP_VS_BASE_CTL+14)
 #define IP_VS_SO_SET_ZERO	(IP_VS_BASE_CTL+15)
-#define IP_VS_SO_SET_MAX	IP_VS_SO_SET_ZERO
+#define IP_VS_SO_SET_ADDLADDR	(IP_VS_BASE_CTL+16)
+#define IP_VS_SO_SET_DELLADDR	(IP_VS_BASE_CTL+17)
+#define IP_VS_SO_SET_ADDZONE	(IP_VS_BASE_CTL+18)
+#define IP_VS_SO_SET_DELZONE	(IP_VS_BASE_CTL+19)
+#define IP_VS_SO_SET_MAX	IP_VS_SO_SET_DELZONE
 
 #define IP_VS_SO_GET_VERSION	IP_VS_BASE_CTL
 #define IP_VS_SO_GET_INFO	(IP_VS_BASE_CTL+1)
@@ -65,28 +72,35 @@
 #define IP_VS_SO_GET_DEST	(IP_VS_BASE_CTL+5)	/* not used now */
 #define IP_VS_SO_GET_TIMEOUT	(IP_VS_BASE_CTL+6)
 #define IP_VS_SO_GET_DAEMON	(IP_VS_BASE_CTL+7)
-#define IP_VS_SO_GET_MAX	IP_VS_SO_GET_DAEMON
-
+#define IP_VS_SO_GET_LADDRS	(IP_VS_BASE_CTL+8)
+#define IP_VS_SO_GET_ZONES	(IP_VS_BASE_CTL+9)
+#define IP_VS_SO_GET_ZONE	(IP_VS_BASE_CTL+10)
+#define IP_VS_SO_GET_MAX	IP_VS_SO_GET_ZONE
 
 /*
  *      IPVS Connection Flags
  */
-#define IP_VS_CONN_F_FWD_MASK	0x0007		/* mask for the fwd methods */
-#define IP_VS_CONN_F_MASQ	0x0000		/* masquerading/NAT */
-#define IP_VS_CONN_F_LOCALNODE	0x0001		/* local node */
-#define IP_VS_CONN_F_TUNNEL	0x0002		/* tunneling */
-#define IP_VS_CONN_F_DROUTE	0x0003		/* direct routing */
-#define IP_VS_CONN_F_BYPASS	0x0004		/* cache bypass */
-#define IP_VS_CONN_F_SYNC	0x0020		/* entry created by sync */
-#define IP_VS_CONN_F_HASHED	0x0040		/* hashed entry */
-#define IP_VS_CONN_F_NOOUTPUT	0x0080		/* no output packets */
-#define IP_VS_CONN_F_INACTIVE	0x0100		/* not established */
-#define IP_VS_CONN_F_OUT_SEQ	0x0200		/* must do output seq adjust */
-#define IP_VS_CONN_F_IN_SEQ	0x0400		/* must do input seq adjust */
-#define IP_VS_CONN_F_SEQ_MASK	0x0600		/* in/out sequence mask */
-#define IP_VS_CONN_F_NO_CPORT	0x0800		/* no client port set yet */
-#define IP_VS_CONN_F_TEMPLATE	0x1000		/* template, not connection */
-#define IP_VS_CONN_F_ONE_PACKET	0x2000		/* forward only one packet */
+#define IP_VS_CONN_F_FWD_MASK	0x0007		/* mask for the fwd methods */
+#define IP_VS_CONN_F_MASQ	0x0000		/* masquerading/NAT */
+#define IP_VS_CONN_F_LOCALNODE	0x0001		/* local node */
+#define IP_VS_CONN_F_TUNNEL	0x0002		/* tunneling */
+#define IP_VS_CONN_F_DROUTE	0x0003		/* direct routing */
+#define IP_VS_CONN_F_BYPASS	0x0004		/* cache bypass */
+#define IP_VS_CONN_F_FULLNAT	0x0005		/* full nat */
+#define IP_VS_CONN_F_SYNC	0x0020		/* entry created by sync */
+#define IP_VS_CONN_F_HASHED	0x0040		/* hashed entry */
+#define IP_VS_CONN_F_NOOUTPUT	0x0080		/* no output packets */
+#define IP_VS_CONN_F_INACTIVE	0x0100		/* not established */
+#define IP_VS_CONN_F_OUT_SEQ	0x0200		/* must do output seq adjust */
+#define IP_VS_CONN_F_IN_SEQ	0x0400		/* must do input seq adjust */
+#define IP_VS_CONN_F_SEQ_MASK	0x0600		/* in/out sequence mask */
+#define IP_VS_CONN_F_NO_CPORT	0x0800		/* no client port set yet */
+#define IP_VS_CONN_F_TEMPLATE	0x1000		/* template, not connection */
+#define IP_VS_CONN_F_ONE_PACKET	0x2000		/* forward only one packet */
+#define IP_VS_CONN_F_CIP_INSERTED 0x4000	/* client ip address has inserted */
+#define IP_VS_CONN_F_SYNPROXY	0x8000		/* syn proxy flag */
+#define IP_VS_CONN_F_DSNAT	0x010000
+
 
 #define IP_VS_SCHEDNAME_MAXLEN	16
 #define IP_VS_IFNAME_MAXLEN	16
@@ -125,23 +139,31 @@ struct ip_vs_dest_user {
 	__u32		l_threshold;	/* lower threshold */
 };
 
+struct ip_vs_zone_user {
+	__be32 addr;		/* ipv4 address */
+	__be32 netmask;		/* ipv4 netmask */
+};
+
+
+struct ip_vs_laddr_user {
+	__be32 addr;		/* ipv4 address */
+};
 
 /*
  *	IPVS statistics object (for user space)
  */
-struct ip_vs_stats_user
-{
-	__u32                   conns;          /* connections scheduled */
-	__u32                   inpkts;         /* incoming packets */
-	__u32                   outpkts;        /* outgoing packets */
-	__u64                   inbytes;        /* incoming bytes */
-	__u64                   outbytes;       /* outgoing bytes */
-
-	__u32			cps;		/* current connection rate */
-	__u32			inpps;		/* current in packet rate */
-	__u32			outpps;		/* current out packet rate */
-	__u32			inbps;		/* current in byte rate */
-	__u32			outbps;		/* current out byte rate */
+struct ip_vs_stats_user {
+	__u64                   conns;          /* connections scheduled */
+	__u64                   inpkts;         /* incoming packets */
+	__u64                   outpkts;        /* outgoing packets */
+	__u64                   inbytes;        /* incoming bytes */
+	__u64                   outbytes;       /* outgoing bytes */
+
+	__u32			cps;		/* current connection rate */
+	__u32			inpps;		/* current in packet rate */
+	__u32			outpps;		/* current out packet rate */
+	__u32			inbps;		/* current in byte rate */
+	__u32			outbps;		/* current out byte rate */
 };
 
 
@@ -155,6 +177,9 @@ struct ip_vs_getinfo {
 
 	/* number of virtual services */
 	unsigned int		num_services;
+
+	/* number of zones */
+	unsigned int		num_zones;	
 };
 
 
@@ -175,10 +200,20 @@ struct ip_vs_service_entry {
 	/* number of real servers */
 	unsigned int		num_dests;
 
+	/* number of local address */
+	unsigned int 		num_laddrs;
+
 	/* statistics */
 	struct ip_vs_stats_user stats;
 };
 
+struct ip_vs_zone_entry {
+	__be32 			addr;
+	__be32 			netmask;
+
+	/* number of local address */
+	unsigned int 		num_laddrs;
+};
 
 struct ip_vs_dest_entry {
 	__be32			addr;		/* destination address */
@@ -197,6 +232,12 @@ struct ip_vs_dest_entry {
 	struct ip_vs_stats_user stats;
 };
 
+struct ip_vs_laddr_entry {
+	__be32 addr;		/* ipv4 address */
+
+	__u64 port_conflict;	/* conflict counts */
+	__u32 conn_counts;	/* current connects */
+};
 
 /* The argument to IP_VS_SO_GET_DESTS */
 struct ip_vs_get_dests {
@@ -214,6 +255,28 @@ struct ip_vs_get_dests {
 };
 
 
+/* The argument to IP_VS_SO_GET_ZONES */
+struct ip_vs_get_zones {
+	/* number of virtual services */
+	unsigned int		num_zones;
+
+	/* service table */
+	struct ip_vs_zone_entry entrytable[0];
+};
+
+
+/* The argument to IP_VS_SO_GET_LADDRS */
+struct ip_vs_get_laddrs {
+	__be32 		addr;		/* ipv4 address */
+	__be32 		netmask;
+
+	/* number of local address */
+	unsigned int 	num_laddrs;
+
+	/* the local address */
+	struct ip_vs_laddr_entry entrytable[0];
+};
+
 /* The argument to IP_VS_SO_GET_SERVICES */
 struct ip_vs_get_services {
 	/* number of virtual services */
@@ -260,6 +323,7 @@ struct ip_vs_flags {
 	__be32 mask;
 };
 
+
 /* Generic Netlink command attributes */
 enum {
 	IPVS_CMD_UNSPEC = 0,
@@ -287,6 +351,14 @@ enum {
 	IPVS_CMD_ZERO,			/* zero all counters and stats */
 	IPVS_CMD_FLUSH,			/* flush services and dests */
 
+	IPVS_CMD_NEW_LADDR,		/* add local address */
+	IPVS_CMD_DEL_LADDR,		/* del local address */
+	IPVS_CMD_GET_LADDR,		/* dump local address */
+
+	IPVS_CMD_NEW_ZONE,		/* add zone */
+	IPVS_CMD_DEL_ZONE,		/* del zone */
+	IPVS_CMD_GET_ZONE,		/* get zone info */
+
 	__IPVS_CMD_MAX,
 };
 
@@ -301,11 +373,28 @@ enum {
 	IPVS_CMD_ATTR_TIMEOUT_TCP,	/* TCP connection timeout */
 	IPVS_CMD_ATTR_TIMEOUT_TCP_FIN,	/* TCP FIN wait timeout */
 	IPVS_CMD_ATTR_TIMEOUT_UDP,	/* UDP timeout */
+	IPVS_CMD_ATTR_LADDR,		/* nested local address attribute */
+	IPVS_CMD_ATTR_ZONE,		/* nested zone attribute */
 	__IPVS_CMD_ATTR_MAX,
 };
 
 #define IPVS_CMD_ATTR_MAX (__IPVS_SVC_ATTR_MAX - 1)
 
+
+/*
+ * Attributes used to describe a service
+ *
+ * Used inside nested attribute IPVS_CMD_ATTR_ZONE
+ */
+enum {
+	IPVS_ZONE_ATTR_UNSPEC = 0,
+	IPVS_ZONE_ATTR_ADDR,		/* address  */
+	IPVS_ZONE_ATTR_NETMASK,		/* netmask */
+	__IPVS_ZONE_ATTR_MAX,
+};
+
+#define IPVS_ZONE_ATTR_MAX (__IPVS_ZONE_ATTR_MAX - 1)
+
 /*
  * Attributes used to describe a service
  *
@@ -357,6 +446,21 @@ enum {
 #define IPVS_DEST_ATTR_MAX (__IPVS_DEST_ATTR_MAX - 1)
 
 /*
+ *  Attirbutes used to describe a local address
+ *  
+ */
+
+enum {
+	IPVS_LADDR_ATTR_UNSPEC = 0,
+	IPVS_LADDR_ATTR_ADDR,
+	IPVS_LADDR_ATTR_PORT_CONFLICT,
+	IPVS_LADDR_ATTR_CONN_COUNTS,
+	__IPVS_LADDR_ATTR_MAX,
+};
+
+#define IPVS_LADDR_ATTR_MAX (__IPVS_LADDR_ATTR_MAX - 1)
+
+/*
  * Attributes describing a sync daemon
  *
  * Used inside nested attribute IPVS_CMD_ATTR_DAEMON
diff --git a/include/net/ip_vs.h b/include/net/ip_vs.h
old mode 100644
new mode 100755
index a7b0f48..12bb748
--- a/include/net/ip_vs.h
+++ b/include/net/ip_vs.h
@@ -69,6 +69,7 @@ static inline int ip_vs_addr_equal(int af, const union nf_inet_addr *a,
 				   const union nf_inet_addr *b)
 {
 #ifdef CONFIG_IP_VS_IPV6
+	af &= ~IP_VS_CONN_F_DSNAT;
 	if (af == AF_INET6)
 		return ipv6_addr_equal(&a->in6, &b->in6);
 #endif
@@ -185,6 +186,9 @@ static inline const char *ip_vs_dbg_addr(int af, char *buf, size_t buf_len,
 #define FTPPORT  cpu_to_be16(21)
 #define FTPDATA  cpu_to_be16(20)
 
+#define IP_VS_DSNAT_RS_ADDR	cpu_to_be32((1<<24)+1)
+#define IP_VS_DSNAT_RS_PORT	cpu_to_be16(1)
+
 /*
  *      TCP State Values
  */
@@ -249,6 +253,7 @@ struct ip_vs_seq {
 	__u32			delta;		/* Delta in sequence numbers */
 	__u32			previous_delta;	/* Delta in sequence numbers
 						   before last resized pkt */
+	__u32 fdata_seq;			/* sequence of first data packet */
 };
 
 
@@ -260,15 +265,15 @@ struct ip_vs_estimator {
 
 	u64			last_inbytes;
 	u64			last_outbytes;
-	u32			last_conns;
-	u32			last_inpkts;
-	u32			last_outpkts;
+	u64			last_conns;
+	u64			last_inpkts;
+	u64			last_outpkts;
 
 	u32			cps;
 	u32			inpps;
 	u32			outpps;
-	u32			inbps;
-	u32			outbps;
+	u64			inbps;
+	u64			outbps;
 };
 
 struct ip_vs_stats
@@ -308,7 +313,7 @@ struct ip_vs_protocol {
 		       struct ip_vs_protocol *pp,
 		       const struct ip_vs_iphdr *iph,
 		       unsigned int proto_off,
-		       int inverse);
+		       int inverse, int *res_dir);
 
 	struct ip_vs_conn *
 	(*conn_out_get)(int af,
@@ -316,7 +321,7 @@ struct ip_vs_protocol {
 			struct ip_vs_protocol *pp,
 			const struct ip_vs_iphdr *iph,
 			unsigned int proto_off,
-			int inverse);
+			int inverse, int *res_dir);
 
 	int (*snat_handler)(struct sk_buff *skb,
 			    struct ip_vs_protocol *pp, struct ip_vs_conn *cp);
@@ -324,6 +329,15 @@ struct ip_vs_protocol {
 	int (*dnat_handler)(struct sk_buff *skb,
 			    struct ip_vs_protocol *pp, struct ip_vs_conn *cp);
 
+
+	int (*fnat_in_handler) (struct sk_buff **skb_p, struct ip_vs_protocol *pp,
+                           struct ip_vs_conn *cp);
+
+
+	int (*fnat_out_handler) (struct sk_buff *skb, struct ip_vs_protocol *pp,
+                           struct ip_vs_conn *cp);
+
+
 	int (*csum_check)(int af, struct sk_buff *skb,
 			  struct ip_vs_protocol *pp);
 
@@ -347,25 +361,55 @@ struct ip_vs_protocol {
 	void (*timeout_change)(struct ip_vs_protocol *pp, int flags);
 
 	int (*set_state_timeout)(struct ip_vs_protocol *pp, char *sname, int to);
+
+	void (*conn_expire_handler) (struct ip_vs_protocol *pp, struct ip_vs_conn *cp);
+
 };
 
 extern struct ip_vs_protocol * ip_vs_proto_get(unsigned short proto);
 
 /*
+ *      Connection Index Flags
+ */
+#define IP_VS_CIDX_F_OUT2IN     0x0001	/* packet director, OUTside2INside */
+#define IP_VS_CIDX_F_IN2OUT     0x0002	/* packet director, INside2OUTside */
+#define IP_VS_CIDX_F_DIR_MASK	0x0003	/* packet director mask */
+
+/*
+ *      Connection index in HASH TABLE, each connection has two index
+ */
+struct ip_vs_conn_idx {
+	struct list_head 	c_list;		/* hashed list heads */
+
+	u16 			af;		/* address family */
+	__u16 			protocol;	/* Which protocol (TCP/UDP) */
+	union nf_inet_addr 	s_addr;		/* source address */
+	union nf_inet_addr 	d_addr;		/* destination address */
+	__be16 			s_port;		/* source port */
+	__be16 			d_port;		/* destination port */
+
+	struct ip_vs_conn 	*cp;		/* point to connection */
+	volatile __u16 		flags;		/* status flags */
+};
+
+/*
  *	IP_VS structure allocated for each dynamically scheduled connection
  */
 struct ip_vs_conn {
-	struct list_head        c_list;         /* hashed list heads */
+	struct ip_vs_conn_idx *in_idx;		/* client-vs hash index */
+	struct ip_vs_conn_idx *out_idx;		/* rs-vs hash index */
 
 	/* Protocol, addresses and port numbers */
 	u16                      af;		/* address family */
+	__u16                    protocol;	/* Which protocol (TCP/UDP) */
 	union nf_inet_addr       caddr;          /* client address */
 	union nf_inet_addr       vaddr;          /* virtual address */
+	union nf_inet_addr       laddr;          /* local address */
 	union nf_inet_addr       daddr;          /* destination address */
 	__be16                   cport;
 	__be16                   vport;
+	__be16                   lport;
 	__be16                   dport;
-	__u16                   protocol;       /* Which protocol (TCP/UDP) */
 
 	/* counter and timer */
 	atomic_t		refcnt;		/* reference count */
@@ -385,8 +429,12 @@ struct ip_vs_conn {
 	struct ip_vs_conn       *control;       /* Master control connection */
 	atomic_t                n_control;      /* Number of controlled ones */
 	struct ip_vs_dest       *dest;          /* real server */
+	struct ip_vs_laddr 	*local;		/* local address */
 	atomic_t                in_pkts;        /* incoming packet counter */
 
+	/* for fullnat */
+	struct ip_vs_seq 	fnat_seq;
+
 	/* packet transmitter for different forwarding methods.  If it
 	   mangles the packet, it must return NF_DROP or better NF_STOLEN,
 	   otherwise this must be changed to a sk_buff **.
@@ -401,8 +449,23 @@ struct ip_vs_conn {
 	void                    *app_data;      /* Application private data */
 	struct ip_vs_seq        in_seq;         /* incoming seq. struct */
 	struct ip_vs_seq        out_seq;        /* outgoing seq. struct */
-};
 
+	/* syn-proxy related members
+	 */
+	struct ip_vs_seq 		syn_proxy_seq;		/* seq. used in syn proxy */
+	struct sk_buff_head 		ack_skb;		/* ack skb, save in step2 */
+	struct sk_buff 			*syn_skb;		/* saved rs syn packet */
+	atomic_t 			syn_retry_max;		/* syn retransmition max count */
+
+	/* add for stopping ack storm */
+	__u32 					last_seq;	/* seq of the last ack packet */
+	__u32 					last_ack_seq;	/* ack seq of the last ack packet */
+	atomic_t 				dup_ack_cnt;	/* count of repeated ack packets */
+
+	/* for RST */
+	__u32 					rs_end_seq;		/* end seq(seq+datalen) of the last ack packet from rs */
+	__u32 					rs_ack_seq;		/* ack seq of the last ack packet from rs */
+};
 
 /*
  *	Extended internal versions of struct ip_vs_service_user and
@@ -442,6 +505,27 @@ struct ip_vs_dest_user_kern {
 	u32			l_threshold;	/* lower threshold */
 };
 
+struct ip_vs_laddr_user_kern {
+	union nf_inet_addr 		addr;	/* ip address */
+};
+
+struct ip_vs_zone_user_kern {
+	union nf_inet_addr 		addr;	/* ip address */
+	__be32					netmask;
+};
+
+
+/*
+ * dsnat 
+ */
+struct ip_vs_dsnat {
+	struct ip_vs_service *svc[IPPROTO_MAX];
+	char iniface[IFNAMSIZ], outiface[IFNAMSIZ];
+	unsigned char iniface_mask[IFNAMSIZ], outiface_mask[IFNAMSIZ];	
+};
+
+
+
 
 /*
  *	The information about the virtual service offered to the net
@@ -464,6 +548,13 @@ struct ip_vs_service {
 
 	struct list_head	destinations;  /* real server d-linked list */
 	__u32			num_dests;     /* number of servers */
+
+	/* for local ip address list, now only used in FULL NAT model */
+	struct list_head 	laddr_list;	/* local ip address list */
+	rwlock_t 		laddr_lock;	/* lock for protect curr_laddr */
+	__u32 			num_laddrs;	/* number of local ip address */
+	struct list_head 	*curr_laddr;	/* laddr data list head */
+
 	struct ip_vs_stats      stats;         /* statistics for the service */
 	struct ip_vs_app	*inc;	  /* bind conns to this app inc */
 
@@ -493,11 +584,11 @@ struct ip_vs_dest {
 	struct ip_vs_stats      stats;          /* statistics */
 
 	/* connection counters and thresholds */
-	atomic_t		activeconns;	/* active connections */
-	atomic_t		inactconns;	/* inactive connections */
-	atomic_t		persistconns;	/* persistent connections */
-	__u32			u_threshold;	/* upper threshold */
-	__u32			l_threshold;	/* lower threshold */
+	atomic_t		activeconns;	/* active connections */
+	atomic_t		inactconns;	/* inactive connections */
+	atomic_t		persistconns;	/* persistent connections */
+	__u32			u_threshold;	/* upper threshold */
+	__u32			l_threshold;	/* lower threshold */
 
 	/* for destination cache */
 	spinlock_t		dst_lock;	/* lock of dst_cache */
@@ -514,6 +605,41 @@ struct ip_vs_dest {
 
 
 /*
+ *	The information about the  zone 
+ */
+struct ip_vs_zone {
+	struct list_head	s_list;   /* for normal zone table */
+	atomic_t		refcnt;   /* reference counter */
+	atomic_t		usecnt;   /* use counter */
+
+	union nf_inet_addr	addr;	  /* IP address for virtual service */
+	__be32			netmask;
+
+	/* for local ip address list, now only used in FULL NAT model */
+	struct list_head 	laddr_list;	/* local ip address list */
+	rwlock_t 		laddr_lock;	/* lock for protect curr_laddr */
+	__u32 			num_laddrs;	/* number of local ip address */
+	struct list_head	*curr_laddr;	/* laddr data list head */
+
+};
+
+
+
+/*
+ *	Local ip address object, now only used in FULL NAT model
+ */
+struct ip_vs_laddr {
+	struct list_head 	n_list;		/* for the local address in the service */
+	u16 			af;		/* address family */
+	union nf_inet_addr 	addr;		/* ip address */
+	atomic64_t 		port;		/* port counts */
+	atomic_t 		refcnt;		/* reference count */
+
+	atomic64_t 		port_conflict;	/* conflict counts */
+	atomic_t 		conn_counts;	/* connects counts */
+};
+
+/*
  *	The scheduler object
  */
 struct ip_vs_scheduler {
@@ -598,6 +724,78 @@ struct ip_vs_app
 	void (*timeout_change)(struct ip_vs_app *app, int flags);
 };
 
+#define TCPOPT_ADDR  200
+#define TCPOLEN_ADDR 8		/* |opcode|size|ip+port| = 1 + 1 + 6 */
+
+/*
+ * insert client ip in tcp option, now only support IPV4,
+ * must be 4 bytes alignment.
+ */
+struct ip_vs_tcpo_addr {
+	__u8 		opcode;
+	__u8		opsize;
+	__u16 		port;
+	__u32 		addr;
+};
+
+/*
+ * statistics for FULLNAT and SYNPROXY
+ * in /proc/net/ip_vs_ext_stats
+ */
+enum {
+	FULLNAT_ADD_TOA_OK = 1,
+	FULLNAT_ADD_TOA_FAIL_LEN,
+	FULLNAT_ADD_TOA_FAIL_MEM,
+	FULLNAT_ADD_TOA_FAIL_PROTO,
+	FULLNAT_CONN_REUSED,
+	FULLNAT_CONN_REUSED_CLOSE,
+	FULLNAT_CONN_REUSED_TIMEWAIT,
+	FULLNAT_CONN_REUSED_FINWAIT,
+	FULLNAT_CONN_REUSED_CLOSEWAIT,
+	FULLNAT_CONN_REUSED_LASTACK,
+	FULLNAT_CONN_REUSED_ESTAB,
+	SYNPROXY_RS_ERROR,
+	SYNPROXY_NULL_ACK,
+	SYNPROXY_BAD_ACK,
+	SYNPROXY_OK_ACK,
+	SYNPROXY_SYN_CNT,
+	SYNPROXY_ACK_STORM,
+	SYNPROXY_SYNSEND_QLEN,
+	SYNPROXY_CONN_REUSED,
+	SYNPROXY_CONN_REUSED_CLOSE,
+	SYNPROXY_CONN_REUSED_TIMEWAIT,
+	SYNPROXY_CONN_REUSED_FINWAIT,
+	SYNPROXY_CONN_REUSED_CLOSEWAIT,
+	SYNPROXY_CONN_REUSED_LASTACK,
+	DEFENCE_IP_FRAG_DROP,
+	DEFENCE_TCP_DROP,
+	DEFENCE_UDP_DROP,
+	IP_VS_EXT_STAT_LAST
+};
+
+struct ip_vs_estats_entry {
+	char 		*name;
+	int 		entry;
+};
+
+#define IP_VS_ESTATS_ITEM(_name, _entry) { \
+        .name 		= _name,            \
+        .entry 	= _entry,          \
+}
+
+#define IP_VS_ESTATS_LAST {    \
+        NULL,           \
+        0,              \
+}
+
+struct ip_vs_estats_mib {
+	unsigned long mibs[IP_VS_EXT_STAT_LAST];
+};
+
+#define IP_VS_INC_ESTATS(mib, field)         \
+        (per_cpu_ptr(mib, smp_processor_id())->mibs[field]++)
+
+extern struct ip_vs_estats_mib *ip_vs_esmib;
 
 /*
  *      IPVS core functions
@@ -618,7 +816,7 @@ extern void ip_vs_init_hash_table(struct list_head *table, int rows);
  *     IPVS connection entry hash table
  */
 #ifndef CONFIG_IP_VS_TAB_BITS
-#define CONFIG_IP_VS_TAB_BITS   12
+#define CONFIG_IP_VS_TAB_BITS   22
 #endif
 
 #define IP_VS_CONN_TAB_BITS	CONFIG_IP_VS_TAB_BITS
@@ -632,9 +830,9 @@ enum {
 	IP_VS_DIR_LAST,
 };
 
-extern struct ip_vs_conn *ip_vs_conn_in_get
+extern struct ip_vs_conn *ip_vs_conn_get
 (int af, int protocol, const union nf_inet_addr *s_addr, __be16 s_port,
- const union nf_inet_addr *d_addr, __be16 d_port);
+ const union nf_inet_addr *d_addr, __be16 d_port, int *res_dir);
 
 extern struct ip_vs_conn *ip_vs_ct_in_get
 (int af, int protocol, const union nf_inet_addr *s_addr, __be16 s_port,
@@ -644,7 +842,7 @@ struct ip_vs_conn * ip_vs_conn_in_get_proto(int af, const struct sk_buff *skb,
 					    struct ip_vs_protocol *pp,
 					    const struct ip_vs_iphdr *iph,
 					    unsigned int proto_off,
-					    int inverse);
+					    int inverse, int *res_dir);
 
 extern struct ip_vs_conn *ip_vs_conn_out_get
 (int af, int protocol, const union nf_inet_addr *s_addr, __be16 s_port,
@@ -654,7 +852,7 @@ struct ip_vs_conn * ip_vs_conn_out_get_proto(int af, const struct sk_buff *skb,
 					     struct ip_vs_protocol *pp,
 					     const struct ip_vs_iphdr *iph,
 					     unsigned int proto_off,
-					     int inverse);
+					     int inverse, int *res_dir);
 
 /* put back the conn without restarting its timer */
 static inline void __ip_vs_conn_put(struct ip_vs_conn *cp)
@@ -668,7 +866,7 @@ extern struct ip_vs_conn *
 ip_vs_conn_new(int af, int proto, const union nf_inet_addr *caddr, __be16 cport,
 	       const union nf_inet_addr *vaddr, __be16 vport,
 	       const union nf_inet_addr *daddr, __be16 dport, unsigned flags,
-	       struct ip_vs_dest *dest);
+	       struct ip_vs_dest *dest, struct sk_buff *skb, int is_synproxy_on);
 extern void ip_vs_conn_expire_now(struct ip_vs_conn *cp);
 
 extern const char * ip_vs_state_name(__u16 proto, int state);
@@ -795,7 +993,7 @@ extern int ip_vs_unbind_scheduler(struct ip_vs_service *svc);
 extern struct ip_vs_scheduler *ip_vs_scheduler_get(const char *sched_name);
 extern void ip_vs_scheduler_put(struct ip_vs_scheduler *scheduler);
 extern struct ip_vs_conn *
-ip_vs_schedule(struct ip_vs_service *svc, const struct sk_buff *skb);
+	ip_vs_schedule(struct ip_vs_service *svc,  struct sk_buff *skb, int is_synproxy_on);
 extern int ip_vs_leave(struct ip_vs_service *svc, struct sk_buff *skb,
 			struct ip_vs_protocol *pp);
 
@@ -810,16 +1008,37 @@ extern int sysctl_ip_vs_sync_threshold[2];
 extern int sysctl_ip_vs_nat_icmp_send;
 extern struct ip_vs_stats ip_vs_stats;
 extern const struct ctl_path net_vs_ctl_path[];
-
+extern int sysctl_ip_vs_timestamp_remove_entry;
+extern int sysctl_ip_vs_mss_adjust_entry;
+extern int sysctl_ip_vs_conn_reused_entry;
+extern int sysctl_ip_vs_toa_entry;
+extern int sysctl_ip_vs_lport_max;
+extern int sysctl_ip_vs_lport_min;
+extern int sysctl_ip_vs_lport_tries;
+extern int sysctl_ip_vs_frag_drop_entry;
+extern int sysctl_ip_vs_tcp_drop_entry;
+extern int sysctl_ip_vs_udp_drop_entry;
+extern int sysctl_ip_vs_conn_expire_tcp_rst;
+extern struct ip_vs_zone  *ip_vs_zone_get(const union nf_inet_addr *addr);
 extern struct ip_vs_service *
 ip_vs_service_get(int af, __u32 fwmark, __u16 protocol,
 		  const union nf_inet_addr *vaddr, __be16 vport);
+extern struct ip_vs_service * ip_vs_lookup_vip(int af, __u16 protocol,
+					      const union nf_inet_addr *vaddr);
 
 static inline void ip_vs_service_put(struct ip_vs_service *svc)
 {
 	atomic_dec(&svc->usecnt);
 }
 
+
+static inline void ip_vs_zone_put(struct ip_vs_zone *zone)
+{
+	atomic_dec(&zone->usecnt);
+}
+
+
+
 extern struct ip_vs_dest *
 ip_vs_lookup_real_service(int af, __u16 protocol,
 			  const union nf_inet_addr *daddr, __be16 dport);
@@ -833,6 +1052,8 @@ ip_vs_find_dest(int af, const union nf_inet_addr *daddr, __be16 dport,
 		const union nf_inet_addr *vaddr, __be16 vport, __u16 protocol);
 extern struct ip_vs_dest *ip_vs_try_bind_dest(struct ip_vs_conn *cp);
 
+extern void ip_vs_laddr_hold(struct ip_vs_laddr *addr);
+extern void ip_vs_laddr_put(struct ip_vs_laddr *addr);
 
 /*
  *      IPVS sync daemon data and function prototypes
@@ -858,6 +1079,15 @@ extern void ip_vs_kill_estimator(struct ip_vs_stats *stats);
 extern void ip_vs_zero_estimator(struct ip_vs_stats *stats);
 
 /*
+ *	Lookup route table
+ */
+extern struct rtable *ip_vs_get_rt(union nf_inet_addr *addr, u32 rtos);
+
+#ifdef CONFIG_IP_VS_IPV6
+extern struct rt6_info *ip_vs_get_rt_v6(union nf_inet_addr *addr);
+#endif
+
+/*
  *	Various IPVS packet transmitters (from ip_vs_xmit.c)
  */
 extern int ip_vs_null_xmit
@@ -866,6 +1096,8 @@ extern int ip_vs_bypass_xmit
 (struct sk_buff *skb, struct ip_vs_conn *cp, struct ip_vs_protocol *pp);
 extern int ip_vs_nat_xmit
 (struct sk_buff *skb, struct ip_vs_conn *cp, struct ip_vs_protocol *pp);
+extern int ip_vs_fnat_xmit
+(struct sk_buff *skb, struct ip_vs_conn *cp, struct ip_vs_protocol *pp);
 extern int ip_vs_tunnel_xmit
 (struct sk_buff *skb, struct ip_vs_conn *cp, struct ip_vs_protocol *pp);
 extern int ip_vs_dr_xmit
@@ -873,12 +1105,26 @@ extern int ip_vs_dr_xmit
 extern int ip_vs_icmp_xmit
 (struct sk_buff *skb, struct ip_vs_conn *cp, struct ip_vs_protocol *pp, int offset);
 extern void ip_vs_dst_reset(struct ip_vs_dest *dest);
+extern int ip_vs_normal_response_xmit
+(struct sk_buff *skb, struct ip_vs_protocol *pp, struct ip_vs_conn *cp,
+ int ihl);
+extern int ip_vs_fnat_response_xmit
+(struct sk_buff *skb, struct ip_vs_protocol *pp, struct ip_vs_conn *cp,
+ int ihl);
+extern int ip_vs_normal_response_icmp_xmit
+(struct sk_buff *skb, struct ip_vs_protocol *pp, struct ip_vs_conn *cp,
+ int offset);
+extern int ip_vs_fnat_response_icmp_xmit
+(struct sk_buff *skb, struct ip_vs_protocol *pp, struct ip_vs_conn *cp,
+ int offset);
 
 #ifdef CONFIG_IP_VS_IPV6
 extern int ip_vs_bypass_xmit_v6
 (struct sk_buff *skb, struct ip_vs_conn *cp, struct ip_vs_protocol *pp);
 extern int ip_vs_nat_xmit_v6
 (struct sk_buff *skb, struct ip_vs_conn *cp, struct ip_vs_protocol *pp);
+extern int ip_vs_fnat_xmit_v6
+(struct sk_buff *skb, struct ip_vs_conn *cp, struct ip_vs_protocol *pp);
 extern int ip_vs_tunnel_xmit_v6
 (struct sk_buff *skb, struct ip_vs_conn *cp, struct ip_vs_protocol *pp);
 extern int ip_vs_dr_xmit_v6
@@ -886,6 +1132,19 @@ extern int ip_vs_dr_xmit_v6
 extern int ip_vs_icmp_xmit_v6
 (struct sk_buff *skb, struct ip_vs_conn *cp, struct ip_vs_protocol *pp,
  int offset);
+extern int ip_vs_normal_response_xmit_v6
+(struct sk_buff *skb, struct ip_vs_protocol *pp, struct ip_vs_conn *cp,
+ int ihl);
+extern int ip_vs_fnat_response_xmit_v6
+(struct sk_buff *skb, struct ip_vs_protocol *pp, struct ip_vs_conn *cp,
+ int ihl);
+extern int ip_vs_normal_response_icmp_xmit_v6
+(struct sk_buff *skb, struct ip_vs_protocol *pp, struct ip_vs_conn *cp,
+ int offset);
+
+extern int ip_vs_fnat_response_icmp_xmit_v6
+(struct sk_buff *skb, struct ip_vs_protocol *pp, struct ip_vs_conn *cp, 
+ int offset);
 #endif
 
 /*
@@ -924,20 +1183,14 @@ static inline char ip_vs_fwd_tag(struct ip_vs_conn *cp)
 		fwd = 'R'; break;
 	case IP_VS_CONN_F_BYPASS:
 		fwd = 'B'; break;
+	case IP_VS_CONN_F_FULLNAT:
+		fwd = 'F'; break;
 	default:
 		fwd = '?'; break;
 	}
 	return fwd;
 }
 
-extern void ip_vs_nat_icmp(struct sk_buff *skb, struct ip_vs_protocol *pp,
-			   struct ip_vs_conn *cp, int dir);
-
-#ifdef CONFIG_IP_VS_IPV6
-extern void ip_vs_nat_icmp_v6(struct sk_buff *skb, struct ip_vs_protocol *pp,
-			      struct ip_vs_conn *cp, int dir);
-#endif
-
 extern __sum16 ip_vs_checksum_complete(struct sk_buff *skb, int offset);
 
 static inline __wsum ip_vs_check_diff4(__be32 old, __be32 new, __wsum oldsum)
diff --git a/include/net/ip_vs_synproxy.h b/include/net/ip_vs_synproxy.h
new file mode 100644
index 0000000..7c223e1
--- /dev/null
+++ b/include/net/ip_vs_synproxy.h
@@ -0,0 +1,135 @@
+/*
+ *     IP Virtual Server Syn-Proxy
+ *     data structure and functionality definitions
+ */
+
+#ifndef _NET_IP_VS_SYNPROXY_H
+#define _NET_IP_VS_SYNPROXY_H
+
+#include <net/ip_vs.h>
+
+/* Add MASKs for TCP OPT in "data" coded in cookie */
+/* |[21][20][19-16][15-0]|
+ * [21]    SACK
+ * [20]    TimeStamp
+ * [19-16] snd_wscale
+ * [15-0]  MSSIND
+ */
+#define IP_VS_SYNPROXY_MSS_BITS 16
+#define IP_VS_SYNPROXY_MSS_MASK (((__u32)1 << IP_VS_SYNPROXY_MSS_BITS) - 1)
+
+#define IP_VS_SYNPROXY_SACKOK_BIT 21
+#define IP_VS_SYNPROXY_SACKOK_MASK ((__u32)1 << IP_VS_SYNPROXY_SACKOK_BIT)
+
+#define IP_VS_SYNPROXY_TSOK_BIT 20
+#define IP_VS_SYNPROXY_TSOK_MASK ((__u32)1 << IP_VS_SYNPROXY_TSOK_BIT)
+
+#define IP_VS_SYNPROXY_SND_WSCALE_BITS 16
+#define IP_VS_SYNPROXY_SND_WSCALE_MASK ((__u32)0xf << IP_VS_SYNPROXY_SND_WSCALE_BITS)
+
+#define IP_VS_SYNPROXY_WSCALE_MAX          14
+
+/* add for supporting tcp options' in syn-proxy */
+struct ip_vs_synproxy_opt {
+	u16 snd_wscale:8,	/* Window scaling received from sender          */
+	 tstamp_ok:1,		/* TIMESTAMP seen on SYN packet                 */
+	 wscale_ok:1,		/* Wscale seen on SYN packet                    */
+	 sack_ok:1;		/* SACK seen on SYN packet                      */
+	u16 mss_clamp;		/* Maximal mss, negotiated at connection setup  */
+};
+
+/* 
+ * For syncookie compute and check 
+ */
+extern __u32 ip_vs_synproxy_cookie_v4_init_sequence(struct sk_buff *skb,
+						    struct ip_vs_synproxy_opt
+						    *opts);
+extern int ip_vs_synproxy_v4_cookie_check(struct sk_buff *skb, __u32 cookie,
+					  struct ip_vs_synproxy_opt *opt);
+
+extern __u32 ip_vs_synproxy_cookie_v6_init_sequence(struct sk_buff *skb,
+						    struct ip_vs_synproxy_opt
+						    *opts);
+extern int ip_vs_synproxy_v6_cookie_check(struct sk_buff *skb, __u32 cookie,
+					  struct ip_vs_synproxy_opt *opt);
+
+/*
+ * Syn-proxy step 1 logic: receive client's Syn.
+ */
+extern int ip_vs_synproxy_syn_rcv(int af, struct sk_buff *skb,
+				  struct ip_vs_iphdr *iph, int *verdict);
+/*
+ * Syn-proxy step 2 logic: receive client's Ack.
+ */
+extern int ip_vs_synproxy_ack_rcv(int af, struct sk_buff *skb,
+				  struct tcphdr *th, struct ip_vs_protocol *pp,
+				  struct ip_vs_conn **cpp,
+				  struct ip_vs_iphdr *iph, int *verdict);
+/*
+ * Syn-proxy step 3 logic: receive rs's Syn/Ack.
+ */
+extern int ip_vs_synproxy_synack_rcv(struct sk_buff *skb, struct ip_vs_conn *cp,
+				     struct ip_vs_protocol *pp,
+				     int ihl, int *verdict);
+/*
+ * Syn-proxy conn reuse logic: receive client's Ack.
+ */
+extern int ip_vs_synproxy_reuse_conn(int af, struct sk_buff *skb,
+				     struct ip_vs_conn *cp,
+				     struct ip_vs_protocol *pp,
+				     struct ip_vs_iphdr *iph, int *verdict);
+/*
+ * Store or drop client's ack packet, when lvs is waiting for 
+ * rs's Syn/Ack packet.
+ */
+extern int ip_vs_synproxy_filter_ack(struct sk_buff *skb, struct ip_vs_conn *cp,
+				     struct ip_vs_protocol *pp,
+				     struct ip_vs_iphdr *iph, int *verdict);
+
+/*
+ * Tranfer ack seq and sack opt for Out-In packet.
+ */
+extern void ip_vs_synproxy_dnat_handler(struct tcphdr *tcph,
+					struct ip_vs_seq *sp_seq);
+/*
+ * Tranfer seq for In-Out packet.
+ */
+extern int ip_vs_synproxy_snat_handler(struct tcphdr *tcph,
+				       struct ip_vs_conn *cp);
+
+/* syn-proxy sysctl variables */
+#define IP_VS_SYNPROXY_INIT_MSS_DEFAULT  	1452
+#define IP_VS_SYNPROXY_TTL_DEFAULT     	63
+#define IP_VS_SYNPROXY_TTL_MIN     		1
+#define IP_VS_SYNPROXY_TTL_MAX     		255
+#define IP_VS_SYNPROXY_SACK_DEFAULT  		1
+#define IP_VS_SYNPROXY_WSCALE_DEFAULT  	0
+#define IP_VS_SYNPROXY_TIMESTAMP_DEFAULT  	0
+#define IP_VS_SYNPROXY_DEFER_DEFAULT   	1
+#define IP_VS_SYNPROXY_DUP_ACK_DEFAULT     	10
+#define IP_VS_SYNPROXY_SKB_STORE_DEFAULT     	3
+#define IP_VS_SYNPROXY_CONN_REUSE_DEFAULT	1
+#define IP_VS_SYNPROXY_CONN_REUSE_CL_DEFAULT	1
+#define IP_VS_SYNPROXY_CONN_REUSE_TW_DEFAULT	1
+#define IP_VS_SYNPROXY_CONN_REUSE_FW_DEFAULT	0
+#define IP_VS_SYNPROXY_CONN_REUSE_CW_DEFAULT	0
+#define IP_VS_SYNPROXY_CONN_REUSE_LA_DEFAULT	0
+#define IP_VS_SYNPROXY_SYN_RETRY_DEFAULT	3
+
+extern int sysctl_ip_vs_synproxy_sack;
+extern int sysctl_ip_vs_synproxy_wscale;
+extern int sysctl_ip_vs_synproxy_timestamp;
+extern int sysctl_ip_vs_synproxy_synack_ttl;
+extern int sysctl_ip_vs_synproxy_init_mss;
+extern int sysctl_ip_vs_synproxy_defer;
+extern int sysctl_ip_vs_synproxy_dup_ack_thresh;
+extern int sysctl_ip_vs_synproxy_skb_store_thresh;
+extern int sysctl_ip_vs_synproxy_syn_retry;
+extern int sysctl_ip_vs_synproxy_conn_reuse;
+extern int sysctl_ip_vs_synproxy_conn_reuse_cl;
+extern int sysctl_ip_vs_synproxy_conn_reuse_tw;
+extern int sysctl_ip_vs_synproxy_conn_reuse_fw;
+extern int sysctl_ip_vs_synproxy_conn_reuse_cw;
+extern int sysctl_ip_vs_synproxy_conn_reuse_la;
+
+#endif
diff --git a/net/core/secure_seq.c b/net/core/secure_seq.c
index 07502b4..95a2566 100644
--- a/net/core/secure_seq.c
+++ b/net/core/secure_seq.c
@@ -105,6 +105,7 @@ __u32 secure_tcp_sequence_number(__be32 saddr, __be32 daddr,
 
 	return seq_scale(hash[0]);
 }
+EXPORT_SYMBOL(secure_tcp_sequence_number);
 
 u32 secure_ipv4_port_ephemeral(__be32 saddr, __be32 daddr, __be16 dport)
 {
diff --git a/net/ipv4/syncookies.c b/net/ipv4/syncookies.c
index 8fafe92..ad14a0b 100644
--- a/net/ipv4/syncookies.c
+++ b/net/ipv4/syncookies.c
@@ -8,6 +8,12 @@
  *      modify it under the terms of the GNU General Public License
  *      as published by the Free Software Foundation; either version
  *      2 of the License, or (at your option) any later version.
+ *
+ * Changes:
+ *	Jian Chen <jian.chen1225@gmail.com>
+ *	Yan Tian <tianyan.7c00@gmail.com>
+ *
+ *	add synproxy cookies for ipvs module
  */
 
 #include <linux/tcp.h>
@@ -17,6 +23,7 @@
 #include <linux/kernel.h>
 #include <net/tcp.h>
 #include <net/route.h>
+#include <net/ip_vs_synproxy.h>
 
 /* Timestamps: lowest 9 bits store TCP options */
 #define TSBITS 9
@@ -366,3 +373,89 @@ struct sock *cookie_v4_check(struct sock *sk, struct sk_buff *skb,
 	ret = get_cookie_sock(sk, skb, req, &rt->u.dst);
 out:	return ret;
 }
+
+/*
+ * Generate a syncookie for ip_vs module. 
+ * Besides mss, we store additional tcp options in cookie "data".
+ * 
+ * Cookie "data" format: 
+ * |[21][20][19-16][15-0]|
+ * [21] SACKOK
+ * [20] TimeStampOK
+ * [19-16] snd_wscale
+ * [15-0] MSSIND 
+ */
+__u32 ip_vs_synproxy_cookie_v4_init_sequence(struct sk_buff *skb, 
+                                            struct ip_vs_synproxy_opt *opts) 
+{
+       const struct iphdr *iph = ip_hdr(skb);
+       const struct tcphdr *th = tcp_hdr(skb);
+       int mssind;
+       const __u16 mss = opts->mss_clamp;
+       __u32 data = 0;
+
+       /* XXX sort msstab[] by probability?  Binary search? */
+       for (mssind = 0; mss > msstab[mssind + 1]; mssind++)
+               ;
+       opts->mss_clamp = msstab[mssind] + 1;
+
+       data = mssind & IP_VS_SYNPROXY_MSS_MASK;
+       data |= opts->sack_ok << IP_VS_SYNPROXY_SACKOK_BIT;
+       data |= opts->tstamp_ok << IP_VS_SYNPROXY_TSOK_BIT;
+       data |= ((opts->snd_wscale & 0x0f) << IP_VS_SYNPROXY_SND_WSCALE_BITS);
+
+       return secure_tcp_syn_cookie(iph->saddr, iph->daddr,
+                                    th->source, th->dest, ntohl(th->seq),
+                                    jiffies/(HZ * 60), data);
+}
+EXPORT_SYMBOL(ip_vs_synproxy_cookie_v4_init_sequence);
+
+
+/*
+ * when ip_vs_synproxy_cookie_v4_init_sequence is used, we check
+ * cookie as follow:
+ *  1. mssind check.
+ *  2. get sack/timestamp/wscale options.
+ */
+int ip_vs_synproxy_v4_cookie_check(struct sk_buff * skb, __u32 cookie, 
+                             struct ip_vs_synproxy_opt * opt) 
+{
+       const struct iphdr *iph = ip_hdr(skb);
+       const struct tcphdr *th = tcp_hdr(skb);
+       __u32 seq = ntohl(th->seq) - 1;
+       __u32 mssind;
+       int   ret = 0;
+       __u32 res = check_tcp_syn_cookie(cookie, iph->saddr, iph->daddr,
+                                        th->source, th->dest, seq,
+                                        jiffies/(HZ * 60),
+                                        COUNTER_TRIES);
+
+       if(res == (__u32)-1) /* count is invalid, jiffies' >> jiffies */
+               goto out;
+
+       mssind = res & IP_VS_SYNPROXY_MSS_MASK;
+
+       memset(opt, 0, sizeof(struct ip_vs_synproxy_opt));
+
+       if (mssind < NUM_MSS) {
+               opt->mss_clamp = msstab[mssind] + 1;
+               opt->sack_ok = (res & IP_VS_SYNPROXY_SACKOK_MASK) >> 
+                                       IP_VS_SYNPROXY_SACKOK_BIT;
+               opt->tstamp_ok = (res & IP_VS_SYNPROXY_TSOK_MASK) >> 
+                                       IP_VS_SYNPROXY_TSOK_BIT;
+               opt->snd_wscale = (res & IP_VS_SYNPROXY_SND_WSCALE_MASK) >> 
+                                       IP_VS_SYNPROXY_SND_WSCALE_BITS;
+                if (opt->snd_wscale > 0 && 
+                   opt->snd_wscale <= IP_VS_SYNPROXY_WSCALE_MAX)
+                        opt->wscale_ok = 1;
+                else if (opt->snd_wscale == 0)
+                        opt->wscale_ok = 0;
+                else
+                        goto out;
+
+               ret = 1;
+       }
+
+out:   return ret;
+}
+EXPORT_SYMBOL(ip_vs_synproxy_v4_cookie_check);
diff --git a/net/ipv6/syncookies.c b/net/ipv6/syncookies.c
index 3fd3b1b..d6cc8a9 100644
--- a/net/ipv6/syncookies.c
+++ b/net/ipv6/syncookies.c
@@ -12,6 +12,12 @@
  *      as published by the Free Software Foundation; either version
  *      2 of the License, or (at your option) any later version.
  *
+ * Changes:
+ *	Jian Chen <jian.chen1225@gmail.com>
+ *	Yan Tian <tianyan.7c00@gmail.com>
+ *
+ *	add synproxy cookies for ipvs module
+ *
  */
 
 #include <linux/tcp.h>
@@ -20,6 +26,7 @@
 #include <linux/kernel.h>
 #include <net/ipv6.h>
 #include <net/tcp.h>
+#include <net/ip_vs_synproxy.h>
 
 extern int sysctl_tcp_syncookies;
 extern __u32 syncookie_secret[2][16-4+SHA_DIGEST_WORDS];
@@ -280,3 +287,87 @@ out_free:
 	return NULL;
 }
 
+/*
+ * Generate a syncookie for ip_vs module. 
+ * Besides mss, we store additional tcp options in cookie "data".
+ * 
+ * Cookie "data" format: 
+ * |[21][20][19-16][15-0]|
+ * [21] SACKOK
+ * [20] TimeStampOK
+ * [19-16] snd_wscale
+ * [15-0] MSSIND 
+ */
+__u32 ip_vs_synproxy_cookie_v6_init_sequence(struct sk_buff *skb, 
+                                            struct ip_vs_synproxy_opt *opts) 
+{
+       struct ipv6hdr *iph = ipv6_hdr(skb);
+       const struct tcphdr *th = tcp_hdr(skb);
+       int mssind;
+       const __u16 mss = opts->mss_clamp;
+       __u32 data = 0;
+
+       /* XXX sort msstab[] by probability?  Binary search? */
+       for (mssind = 0; mss > msstab[mssind + 1]; mssind++)
+               ;
+       opts->mss_clamp = msstab[mssind] + 1;
+
+       data = mssind & IP_VS_SYNPROXY_MSS_MASK;
+       data |= opts->sack_ok << IP_VS_SYNPROXY_SACKOK_BIT;
+       data |= opts->tstamp_ok << IP_VS_SYNPROXY_TSOK_BIT;
+       data |= ((opts->snd_wscale & 0x0f) << IP_VS_SYNPROXY_SND_WSCALE_BITS);
+
+       return secure_tcp_syn_cookie(&iph->saddr, &iph->daddr,
+                                    th->source, th->dest, ntohl(th->seq),
+                                    jiffies/(HZ * 60), data);
+}
+EXPORT_SYMBOL(ip_vs_synproxy_cookie_v6_init_sequence);
+
+/*
+ * when ip_vs_synproxy_cookie_v6_init_sequence is used, we check
+ * cookie as follow:
+ *  1. mssind check.
+ *  2. get sack/timestamp/wscale options.
+ */
+int ip_vs_synproxy_v6_cookie_check(struct sk_buff * skb, __u32 cookie, 
+                             struct ip_vs_synproxy_opt * opt) 
+{
+       struct ipv6hdr *iph = ipv6_hdr(skb);
+       const struct tcphdr *th = tcp_hdr(skb);
+       __u32 seq = ntohl(th->seq) - 1;
+       __u32 mssind;
+       int   ret = 0;
+       __u32 res = check_tcp_syn_cookie(cookie, &iph->saddr, &iph->daddr,
+                                        th->source, th->dest, seq,
+                                        jiffies/(HZ * 60),
+                                        COUNTER_TRIES);
+
+       if(res == (__u32)-1) /* count is invalid, jiffies' >> jiffies */
+               goto out;
+
+       mssind = res & IP_VS_SYNPROXY_MSS_MASK;
+
+       memset(opt, 0, sizeof(struct ip_vs_synproxy_opt));
+
+       if (mssind < NUM_MSS) {
+               opt->mss_clamp = msstab[mssind] + 1;
+               opt->sack_ok = (res & IP_VS_SYNPROXY_SACKOK_MASK) >> 
+                                       IP_VS_SYNPROXY_SACKOK_BIT;
+               opt->tstamp_ok = (res & IP_VS_SYNPROXY_TSOK_MASK) >> 
+                                       IP_VS_SYNPROXY_TSOK_BIT;
+               opt->snd_wscale = (res & IP_VS_SYNPROXY_SND_WSCALE_MASK) >> 
+                                       IP_VS_SYNPROXY_SND_WSCALE_BITS;
+                if (opt->snd_wscale > 0 && 
+                   opt->snd_wscale <= IP_VS_SYNPROXY_WSCALE_MAX)
+                        opt->wscale_ok = 1;
+                else if (opt->snd_wscale == 0)
+                        opt->wscale_ok = 0;
+                else
+                        goto out;
+
+               ret = 1;
+       }
+
+out:   return ret;
+}
+EXPORT_SYMBOL(ip_vs_synproxy_v6_cookie_check);
diff --git a/net/netfilter/ipvs/Kconfig b/net/netfilter/ipvs/Kconfig
index 54895e3..9a260ce 100644
--- a/net/netfilter/ipvs/Kconfig
+++ b/net/netfilter/ipvs/Kconfig
@@ -43,8 +43,8 @@ config	IP_VS_DEBUG
 
 config	IP_VS_TAB_BITS
 	int "IPVS connection table size (the Nth power of 2)"
-	range 8 20
-	default 12
+	range 8 22
+	default 22
 	---help---
 	  The IPVS connection hash table uses the chaining scheme to handle
 	  hash collisions. Using a big IPVS connection hash table will greatly
diff --git a/net/netfilter/ipvs/Makefile b/net/netfilter/ipvs/Makefile
index e3baefd..8253398 100644
--- a/net/netfilter/ipvs/Makefile
+++ b/net/netfilter/ipvs/Makefile
@@ -12,6 +12,7 @@ ip_vs_proto-objs-$(CONFIG_IP_VS_PROTO_SCTP) += ip_vs_proto_sctp.o
 ip_vs-objs :=	ip_vs_conn.o ip_vs_core.o ip_vs_ctl.o ip_vs_sched.o	   \
 		ip_vs_xmit.o ip_vs_app.o ip_vs_sync.o	   		   \
 		ip_vs_est.o ip_vs_proto.o 				   \
+		ip_vs_synproxy.o 				   \
 		$(ip_vs_proto-objs-y)
 
 
diff --git a/net/netfilter/ipvs/ip_vs_conn.c b/net/netfilter/ipvs/ip_vs_conn.c
old mode 100644
new mode 100755
index c979ffb..534cdf9
--- a/net/netfilter/ipvs/ip_vs_conn.c
+++ b/net/netfilter/ipvs/ip_vs_conn.c
@@ -19,7 +19,14 @@
  * and others. Many code here is taken from IP MASQ code of kernel 2.2.
  *
  * Changes:
+ *             Yi Yang       <specific@gmail.com>
+ *             Wen Li        <steel.mental@gmail.com>
+ *             Yaoguang Sun  <sunyaoguang@gmail.com>
+ *             Jiaming Wu    <pukong.wjm@taobao.com>
  *
+ *             Modify connection manager to support FULLNAT (a new packet forwarding method)
+ *
+ *	        Yu Bo        <yubo@xiaomi.com>
  */
 
 #define KMSG_COMPONENT "IPVS"
@@ -60,7 +67,7 @@ static unsigned int ip_vs_conn_rnd;
 /*
  *  Fine locking granularity for big connection hash table
  */
-#define CT_LOCKARRAY_BITS  4
+#define CT_LOCKARRAY_BITS  8
 #define CT_LOCKARRAY_SIZE  (1<<CT_LOCKARRAY_BITS)
 #define CT_LOCKARRAY_MASK  (CT_LOCKARRAY_SIZE-1)
 
@@ -113,45 +120,88 @@ static inline void ct_write_unlock_bh(unsigned key)
 	write_unlock_bh(&__ip_vs_conntbl_lock_array[key&CT_LOCKARRAY_MASK].l);
 }
 
-
 /*
  *	Returns hash value for IPVS connection entry
  */
-static unsigned int ip_vs_conn_hashkey(int af, unsigned proto,
-				       const union nf_inet_addr *addr,
-				       __be16 port)
+static unsigned int ip_vs_conn_hashkey(int af, const union nf_inet_addr *s_addr,
+				       __be16 s_port,
+				       const union nf_inet_addr *d_addr,
+				       __be16 d_port)
 {
 #ifdef CONFIG_IP_VS_IPV6
 	if (af == AF_INET6)
-		return jhash_3words(jhash(addr, 16, ip_vs_conn_rnd),
-				    (__force u32)port, proto, ip_vs_conn_rnd)
-			& IP_VS_CONN_TAB_MASK;
+		return jhash_3words(jhash(s_addr, 16, ip_vs_conn_rnd),
+				    jhash(d_addr, 16, ip_vs_conn_rnd),
+				    ((__force u32)s_port) << 16 | (__force u32)d_port, ip_vs_conn_rnd)
+
+		    & IP_VS_CONN_TAB_MASK;
 #endif
-	return jhash_3words((__force u32)addr->ip, (__force u32)port, proto,
+	return jhash_3words((__force u32)s_addr->ip, (__force u32)d_addr->ip,
+			    ((__force u32)s_port) << 16 | (__force u32)d_port,
 			    ip_vs_conn_rnd)
-		& IP_VS_CONN_TAB_MASK;
+		& IP_VS_CONN_TAB_MASK;
 }
 
-
 /*
- *	Hashes ip_vs_conn in ip_vs_conn_tab by proto,addr,port.
- *	returns bool success.
+ * Lock two buckets of ip_vs_conn_tab
  */
-static inline int ip_vs_conn_hash(struct ip_vs_conn *cp)
+static inline void ip_vs_conn_lock2(unsigned ihash, unsigned ohash)
 {
-	unsigned hash;
-	int ret;
+	unsigned ilock, olock;
+
+	ilock = ihash & CT_LOCKARRAY_MASK;
+	olock = ohash & CT_LOCKARRAY_MASK;
+
+	/* lock the conntab bucket */
+	if (ilock < olock) {
+		ct_write_lock(ihash);
+		ct_write_lock(ohash);
+	} else if (ilock > olock) {
+		ct_write_lock(ohash);
+		ct_write_lock(ihash);
+	} else {
+		ct_write_lock(ihash);
+	}
+}
 
-	if (cp->flags & IP_VS_CONN_F_ONE_PACKET)
-		return 0;
+/*
+ * Unlock two buckets of ip_vs_conn_tab
+ */
+static inline void ip_vs_conn_unlock2(unsigned ihash, unsigned ohash)
+{
+	unsigned ilock, olock;
+
+	ilock = ihash & CT_LOCKARRAY_MASK;
+	olock = ohash & CT_LOCKARRAY_MASK;
+
+	/* lock the conntab bucket */
+	if (ilock < olock) {
+		ct_write_unlock(ohash);
+		ct_write_unlock(ihash);
+	} else if (ilock > olock) {
+		ct_write_unlock(ihash);
+		ct_write_unlock(ohash);
+	} else {
+		ct_write_unlock(ihash);
+	}
+}
 
-	/* Hash by protocol, client address and port */
-	hash = ip_vs_conn_hashkey(cp->af, cp->protocol, &cp->caddr, cp->cport);
+/*
+ *      Hashed ip_vs_conn into ip_vs_conn_tab
+ *	returns bool success.
+ */
 
-	ct_write_lock(hash);
+static inline int __ip_vs_conn_hash(struct ip_vs_conn *cp, unsigned ihash,
+				    unsigned ohash)
+{
+	struct ip_vs_conn_idx *ci_idx, *co_idx;
+	int ret;
 
 	if (!(cp->flags & IP_VS_CONN_F_HASHED)) {
-		list_add(&cp->c_list, &ip_vs_conn_tab[hash]);
+		ci_idx = cp->in_idx;
+		co_idx = cp->out_idx;
+		list_add(&ci_idx->c_list, &ip_vs_conn_tab[ihash]);
+		list_add(&co_idx->c_list, &ip_vs_conn_tab[ohash]);
 		cp->flags |= IP_VS_CONN_F_HASHED;
 		atomic_inc(&cp->refcnt);
 		ret = 1;
@@ -161,35 +211,82 @@ static inline int ip_vs_conn_hash(struct ip_vs_conn *cp)
 		ret = 0;
 	}
 
-	ct_write_unlock(hash);
-
 	return ret;
 }
 
+/*
+ *	Hashed ip_vs_conn in two buckets of ip_vs_conn_tab
+ *	by caddr/cport/vaddr/vport and raddr/rport/laddr/lport,
+ *	returns bool success.
+ */
+static inline int ip_vs_conn_hash(struct ip_vs_conn *cp)
+{
+	unsigned ihash, ohash;
+	int ret;
+
+	if (cp->flags & IP_VS_CONN_F_ONE_PACKET)
+		return 0;
+
+	/*OUTside2INside: hashed by client address and port, virtual address and port */
+	ihash = ip_vs_conn_hashkey(cp->af, &cp->caddr, cp->cport, &cp->vaddr,
+			       cp->vport);
+
+	/*INside2OUTside: hashed by destination address and port, local address and port */
+	ohash = ip_vs_conn_hashkey(cp->af, &cp->daddr, cp->dport, &cp->laddr,
+			       cp->lport);
+
+
+	/* locked */
+	ip_vs_conn_lock2(ihash, ohash);
+
+	/* hashed */
+	ret = __ip_vs_conn_hash(cp, ihash, ohash);
+
+	/* unlocked */
+	ip_vs_conn_unlock2(ihash, ohash);
+
+	return ret;
+}
 
 /*
  *	UNhashes ip_vs_conn from ip_vs_conn_tab.
+ *	cp->refcnt must be equal 2,
  *	returns bool success.
  */
 static inline int ip_vs_conn_unhash(struct ip_vs_conn *cp)
 {
-	unsigned hash;
+	unsigned ihash, ohash;
+	struct ip_vs_conn_idx *ci_idx, *co_idx;
 	int ret;
 
-	/* unhash it and decrease its reference counter */
-	hash = ip_vs_conn_hashkey(cp->af, cp->protocol, &cp->caddr, cp->cport);
-
-	ct_write_lock(hash);
-
-	if (cp->flags & IP_VS_CONN_F_HASHED) {
-		list_del(&cp->c_list);
+	/* OUTside2INside: unhash it and decrease its reference counter */
+	ihash = ip_vs_conn_hashkey(cp->af, &cp->caddr, cp->cport, &cp->vaddr,
+			       cp->vport);
+
+	/* INside2OUTside: unhash it and decrease its reference counter */
+	ohash = ip_vs_conn_hashkey(cp->af, &cp->daddr, cp->dport, &cp->laddr,
+			       cp->lport);
+
+
+	/* locked */
+	ip_vs_conn_lock2(ihash, ohash);
+
+	/* unhashed */
+	if ((cp->flags & IP_VS_CONN_F_HASHED)
+	    && (atomic_read(&cp->refcnt) == 2)) {
+		ci_idx = cp->in_idx;
+		co_idx = cp->out_idx;
+		list_del(&ci_idx->c_list);
+		list_del(&co_idx->c_list);
 		cp->flags &= ~IP_VS_CONN_F_HASHED;
 		atomic_dec(&cp->refcnt);
 		ret = 1;
-	} else
+	} else {
 		ret = 0;
+	}
 
-	ct_write_unlock(hash);
+	/* unlocked */
+	ip_vs_conn_unlock2(ihash, ohash);
 
 	return ret;
 }
@@ -197,30 +294,32 @@ static inline int ip_vs_conn_unhash(struct ip_vs_conn *cp)
 
 /*
  *  Gets ip_vs_conn associated with supplied parameters in the ip_vs_conn_tab.
- *  Called for pkts coming from OUTside-to-INside.
- *	s_addr, s_port: pkt source address (foreign host)
- *	d_addr, d_port: pkt dest address (load balancer)
+ *  Return director: OUTside-to-INside or INside-to-OUTside in res_dir.
+ *	s_addr, s_port: pkt source address (foreign host/realserver)
+ *	d_addr, d_port: pkt dest address (virtual address/local address)
  */
-static inline struct ip_vs_conn *__ip_vs_conn_in_get
-(int af, int protocol, const union nf_inet_addr *s_addr, __be16 s_port,
- const union nf_inet_addr *d_addr, __be16 d_port)
-{
+static inline struct ip_vs_conn *__ip_vs_conn_get
+    (int af, int protocol, const union nf_inet_addr *s_addr, __be16 s_port,
+     const union nf_inet_addr *d_addr, __be16 d_port, int *res_dir) {
 	unsigned hash;
 	struct ip_vs_conn *cp;
+	struct ip_vs_conn_idx *cidx;
 
-	hash = ip_vs_conn_hashkey(af, protocol, s_addr, s_port);
+	hash = ip_vs_conn_hashkey(af, s_addr, s_port, d_addr, d_port);
 
 	ct_read_lock(hash);
 
-	list_for_each_entry(cp, &ip_vs_conn_tab[hash], c_list) {
-		if (cp->af == af &&
-		    ip_vs_addr_equal(af, s_addr, &cp->caddr) &&
-		    ip_vs_addr_equal(af, d_addr, &cp->vaddr) &&
-		    s_port == cp->cport && d_port == cp->vport &&
+	list_for_each_entry(cidx, &ip_vs_conn_tab[hash], c_list) {
+		cp = cidx->cp;
+		if (cidx->af == af &&
+		    ip_vs_addr_equal(af, s_addr, &cidx->s_addr) &&
+		    ip_vs_addr_equal(af, d_addr, &cidx->d_addr) &&
+		    s_port == cidx->s_port && d_port == cidx->d_port &&
 		    ((!s_port) ^ (!(cp->flags & IP_VS_CONN_F_NO_CPORT))) &&
-		    protocol == cp->protocol) {
+		    protocol == cidx->protocol) {
 			/* HIT */
 			atomic_inc(&cp->refcnt);
+			*res_dir = cidx->flags & IP_VS_CIDX_F_DIR_MASK;
 			ct_read_unlock(hash);
 			return cp;
 		}
@@ -231,18 +330,19 @@ static inline struct ip_vs_conn *__ip_vs_conn_in_get
 	return NULL;
 }
 
-struct ip_vs_conn *ip_vs_conn_in_get
+struct ip_vs_conn *ip_vs_conn_get
 (int af, int protocol, const union nf_inet_addr *s_addr, __be16 s_port,
- const union nf_inet_addr *d_addr, __be16 d_port)
+ const union nf_inet_addr *d_addr, __be16 d_port, int *res_dir)
 {
 	struct ip_vs_conn *cp;
 
-	cp = __ip_vs_conn_in_get(af, protocol, s_addr, s_port, d_addr, d_port);
+	cp = __ip_vs_conn_get(af, protocol, s_addr, s_port, d_addr, d_port,
+			      res_dir);
 	if (!cp && atomic_read(&ip_vs_conn_no_cport_cnt))
-		cp = __ip_vs_conn_in_get(af, protocol, s_addr, 0, d_addr,
-					 d_port);
+		cp = __ip_vs_conn_get(af, protocol, s_addr, 0, d_addr, d_port,
+				      res_dir);
 
-	IP_VS_DBG_BUF(9, "lookup/in %s %s:%d->%s:%d %s\n",
+	IP_VS_DBG_BUF(19, "lookup %s %s:%d->%s:%d %s\n",
 		      ip_vs_proto_name(protocol),
 		      IP_VS_DBG_ADDR(af, s_addr), ntohs(s_port),
 		      IP_VS_DBG_ADDR(af, d_addr), ntohs(d_port),
@@ -255,7 +355,7 @@ struct ip_vs_conn *
 ip_vs_conn_in_get_proto(int af, const struct sk_buff *skb,
 			struct ip_vs_protocol *pp,
 			const struct ip_vs_iphdr *iph,
-			unsigned int proto_off, int inverse)
+			unsigned int proto_off, int inverse, int *res_dir)
 {
 	__be16 _ports[2], *pptr;
 
@@ -264,13 +364,13 @@ ip_vs_conn_in_get_proto(int af, const struct sk_buff *skb,
 		return NULL;
 
 	if (likely(!inverse))
-		return ip_vs_conn_in_get(af, iph->protocol,
+		return ip_vs_conn_get(af, iph->protocol,
 					 &iph->saddr, pptr[0],
-					 &iph->daddr, pptr[1]);
+					 &iph->daddr, pptr[1], res_dir);
 	else
-		return ip_vs_conn_in_get(af, iph->protocol,
+		return ip_vs_conn_get(af, iph->protocol,
 					 &iph->daddr, pptr[1],
-					 &iph->saddr, pptr[0]);
+					 &iph->saddr, pptr[0], res_dir);
 }
 EXPORT_SYMBOL_GPL(ip_vs_conn_in_get_proto);
 
@@ -280,22 +380,24 @@ struct ip_vs_conn *ip_vs_ct_in_get
  const union nf_inet_addr *d_addr, __be16 d_port)
 {
 	unsigned hash;
+	struct ip_vs_conn_idx *cidx;
 	struct ip_vs_conn *cp;
 
-	hash = ip_vs_conn_hashkey(af, protocol, s_addr, s_port);
+	hash = ip_vs_conn_hashkey(af, s_addr, s_port, d_addr, d_port);
 
 	ct_read_lock(hash);
 
-	list_for_each_entry(cp, &ip_vs_conn_tab[hash], c_list) {
-		if (cp->af == af &&
-		    ip_vs_addr_equal(af, s_addr, &cp->caddr) &&
+	list_for_each_entry(cidx, &ip_vs_conn_tab[hash], c_list) {
+		cp = cidx->cp;
+		if (cidx->af == af &&
+		    ip_vs_addr_equal(af, s_addr, &cidx->s_addr) &&
 		    /* protocol should only be IPPROTO_IP if
 		     * d_addr is a fwmark */
 		    ip_vs_addr_equal(protocol == IPPROTO_IP ? AF_UNSPEC : af,
-		                     d_addr, &cp->vaddr) &&
-		    s_port == cp->cport && d_port == cp->vport &&
+				     d_addr, &cidx->d_addr) &&
+		    s_port == cidx->s_port && d_port == cidx->d_port &&
 		    cp->flags & IP_VS_CONN_F_TEMPLATE &&
-		    protocol == cp->protocol) {
+		    protocol == cidx->protocol) {
 			/* HIT */
 			atomic_inc(&cp->refcnt);
 			goto out;
@@ -306,7 +408,7 @@ struct ip_vs_conn *ip_vs_ct_in_get
   out:
 	ct_read_unlock(hash);
 
-	IP_VS_DBG_BUF(9, "template lookup/in %s %s:%d->%s:%d %s\n",
+	IP_VS_DBG_BUF(19, "template lookup %s %s:%d->%s:%d %s\n",
 		      ip_vs_proto_name(protocol),
 		      IP_VS_DBG_ADDR(af, s_addr), ntohs(s_port),
 		      IP_VS_DBG_ADDR(af, d_addr), ntohs(d_port),
@@ -315,55 +417,12 @@ struct ip_vs_conn *ip_vs_ct_in_get
 	return cp;
 }
 
-/*
- *  Gets ip_vs_conn associated with supplied parameters in the ip_vs_conn_tab.
- *  Called for pkts coming from inside-to-OUTside.
- *	s_addr, s_port: pkt source address (inside host)
- *	d_addr, d_port: pkt dest address (foreign host)
- */
-struct ip_vs_conn *ip_vs_conn_out_get
-(int af, int protocol, const union nf_inet_addr *s_addr, __be16 s_port,
- const union nf_inet_addr *d_addr, __be16 d_port)
-{
-	unsigned hash;
-	struct ip_vs_conn *cp, *ret=NULL;
-
-	/*
-	 *	Check for "full" addressed entries
-	 */
-	hash = ip_vs_conn_hashkey(af, protocol, d_addr, d_port);
-
-	ct_read_lock(hash);
-
-	list_for_each_entry(cp, &ip_vs_conn_tab[hash], c_list) {
-		if (cp->af == af &&
-		    ip_vs_addr_equal(af, d_addr, &cp->caddr) &&
-		    ip_vs_addr_equal(af, s_addr, &cp->daddr) &&
-		    d_port == cp->cport && s_port == cp->dport &&
-		    protocol == cp->protocol) {
-			/* HIT */
-			atomic_inc(&cp->refcnt);
-			ret = cp;
-			break;
-		}
-	}
-
-	ct_read_unlock(hash);
-
-	IP_VS_DBG_BUF(9, "lookup/out %s %s:%d->%s:%d %s\n",
-		      ip_vs_proto_name(protocol),
-		      IP_VS_DBG_ADDR(af, s_addr), ntohs(s_port),
-		      IP_VS_DBG_ADDR(af, d_addr), ntohs(d_port),
-		      ret ? "hit" : "not hit");
-
-	return ret;
-}
 
 struct ip_vs_conn *
 ip_vs_conn_out_get_proto(int af, const struct sk_buff *skb,
 			 struct ip_vs_protocol *pp,
 			 const struct ip_vs_iphdr *iph,
-			 unsigned int proto_off, int inverse)
+			 unsigned int proto_off, int inverse, int *res_dir)
 {
 	__be16 _ports[2], *pptr;
 
@@ -372,13 +431,13 @@ ip_vs_conn_out_get_proto(int af, const struct sk_buff *skb,
 		return NULL;
 
 	if (likely(!inverse))
-		return ip_vs_conn_out_get(af, iph->protocol,
+		return ip_vs_conn_get(af, iph->protocol,
 					  &iph->saddr, pptr[0],
-					  &iph->daddr, pptr[1]);
+					  &iph->daddr, pptr[1], res_dir);
 	else
-		return ip_vs_conn_out_get(af, iph->protocol,
+		return ip_vs_conn_get(af, iph->protocol,
 					  &iph->daddr, pptr[1],
-					  &iph->saddr, pptr[0]);
+					  &iph->saddr, pptr[0], res_dir);
 }
 EXPORT_SYMBOL_GPL(ip_vs_conn_out_get_proto);
 
@@ -430,6 +489,10 @@ static inline void ip_vs_bind_xmit(struct ip_vs_conn *cp)
 		cp->packet_xmit = ip_vs_nat_xmit;
 		break;
 
+	case IP_VS_CONN_F_FULLNAT:
+		cp->packet_xmit = ip_vs_fnat_xmit;
+		break;
+
 	case IP_VS_CONN_F_TUNNEL:
 		cp->packet_xmit = ip_vs_tunnel_xmit;
 		break;
@@ -456,6 +519,10 @@ static inline void ip_vs_bind_xmit_v6(struct ip_vs_conn *cp)
 		cp->packet_xmit = ip_vs_nat_xmit_v6;
 		break;
 
+	case IP_VS_CONN_F_FULLNAT:
+		cp->packet_xmit = ip_vs_fnat_xmit_v6;
+		break;
+
 	case IP_VS_CONN_F_TUNNEL:
 		cp->packet_xmit = ip_vs_tunnel_xmit_v6;
 		break;
@@ -616,6 +683,191 @@ static inline void ip_vs_unbind_dest(struct ip_vs_conn *cp)
 	atomic_dec(&dest->refcnt);
 }
 
+/*
+ * get a local address from given virtual service
+ */
+static struct ip_vs_laddr *ip_vs_get_laddr(const union nf_inet_addr *caddr)
+{
+	struct ip_vs_laddr *local;
+	struct list_head *p, *q;
+	struct ip_vs_zone *zone;
+
+	zone = ip_vs_zone_get(caddr);
+	if (zone == NULL)
+		return NULL;
+	
+	write_lock(&zone->laddr_lock);
+	p = zone->curr_laddr;
+	p = p->next;
+	q = p;
+	do {
+		/* skip list head */
+		if (q == &zone->laddr_list) {
+			q = q->next;
+			continue;
+		}
+		local = list_entry(q, struct ip_vs_laddr, n_list);
+		goto out;
+	} while (q != p);
+	write_unlock(&zone->laddr_lock);
+	return NULL;
+
+      out:
+	zone->curr_laddr = q;
+	write_unlock(&zone->laddr_lock);
+	return local;
+}
+
+/*
+ *	Bind a connection entry with a local address
+ *	and hashed it in connection table.
+ *	Called just after a new connection entry is created and destination has binded.
+ *	returns bool success.
+ */
+static inline int ip_vs_hbind_laddr(struct ip_vs_conn *cp)
+{
+	struct ip_vs_laddr *local;
+	int ret = 0;
+	int remaining, i, tport, hit = 0;
+	unsigned ihash, ohash;
+	struct ip_vs_conn_idx *cidx;
+
+
+
+
+	/* fwd methods: not IP_VS_CONN_F_FULLNAT */
+	switch (IP_VS_FWD_METHOD(cp)) {
+	case IP_VS_CONN_F_MASQ:
+	case IP_VS_CONN_F_TUNNEL:
+	case IP_VS_CONN_F_DROUTE:
+	case IP_VS_CONN_F_LOCALNODE:
+	case IP_VS_CONN_F_BYPASS:
+		ip_vs_addr_copy(cp->af, &cp->out_idx->d_addr, &cp->caddr);
+		cp->out_idx->d_port = cp->cport;
+		ip_vs_addr_copy(cp->af, &cp->laddr, &cp->caddr);
+		cp->lport = cp->cport;
+		cp->local = NULL;
+		ip_vs_conn_hash(cp);
+		ret = 1;
+		goto out;
+	}
+
+	if (cp->flags & IP_VS_CONN_F_TEMPLATE) {
+		ip_vs_addr_copy(cp->af, &cp->out_idx->d_addr, &cp->caddr);
+		cp->out_idx->d_port = cp->cport;
+		ip_vs_addr_copy(cp->af, &cp->laddr, &cp->caddr);
+		cp->lport = cp->cport;
+		cp->local = NULL;
+		ip_vs_conn_hash(cp);
+		ret = 1;
+		goto out;
+	}
+	/*
+	 * fwd methods: IP_VS_CONN_F_FULLNAT
+	 */
+	/* choose a local address by round-robin */
+	local = ip_vs_get_laddr(&cp->caddr);
+	if (local != NULL) {
+		/*OUTside2INside: hashed by client address and port, virtual address and port */
+		ihash =
+		    ip_vs_conn_hashkey(cp->af, &cp->caddr, cp->cport,
+				       &cp->vaddr, cp->vport);
+
+		/* increase the refcnt counter of the local address */
+		ip_vs_laddr_hold(local);
+		ip_vs_addr_copy(cp->af, &cp->out_idx->d_addr, &local->addr);
+		ip_vs_addr_copy(cp->af, &cp->laddr, &local->addr);
+		remaining = sysctl_ip_vs_lport_max - sysctl_ip_vs_lport_min + 1;
+		for (i = 0; i < sysctl_ip_vs_lport_tries; i++) {
+			/* choose a port */
+			tport =
+			    sysctl_ip_vs_lport_min +
+			    atomic64_inc_return(&local->port) % remaining;
+			cp->out_idx->d_port = cp->lport = htons(tport);
+
+			/* init hit everytime before lookup the tuple */
+			hit = 0;
+
+			/*INside2OUTside: hashed by destination address and port, local address and port */
+			ohash = ip_vs_conn_hashkey(cp->af, &cp->daddr, cp->dport,
+					       &cp->laddr, cp->lport);
+
+			/* lock the conntab bucket */
+			ip_vs_conn_lock2(ihash, ohash);
+			/*
+			 * check local address and port is valid by lookup connection table
+			 */
+			list_for_each_entry(cidx, &ip_vs_conn_tab[ohash],
+					    c_list) {
+				if (cidx->af == cp->af
+				    && ip_vs_addr_equal(cp->af, &cp->daddr,
+							&cidx->s_addr)
+				    && ip_vs_addr_equal(cp->af, &cp->laddr,
+							&cidx->d_addr)
+				    && cp->dport == cidx->s_port
+				    && cp->lport == cidx->d_port
+				    && cp->protocol == cidx->protocol) {
+					/* HIT */
+					atomic64_inc(&local->port_conflict);
+					hit = 1;
+					break;
+				}
+			}
+			if (hit == 0) {
+				cp->local = local;
+				/* hashed */
+				__ip_vs_conn_hash(cp, ihash, ohash);
+				ip_vs_conn_unlock2(ihash, ohash);
+				atomic_inc(&local->conn_counts);
+				ret = 1;
+				goto out;
+			}
+			ip_vs_conn_unlock2(ihash, ohash);
+		}
+		if (ret == 0) {
+			IP_VS_ERR_RL("bind local address: no port available\n");
+			ip_vs_laddr_put(local);
+			goto out;
+		}
+	}
+	IP_VS_DBG_BUF(7,"bind local address: no local address available\n");
+	ret = 0;
+
+      out:
+	return ret;
+}
+
+/*
+ *	Unbind a connection entry with its local address
+ *	Called by the ip_vs_conn_expire function.
+ */
+static inline void ip_vs_unbind_laddr(struct ip_vs_conn *cp)
+{
+	struct ip_vs_laddr *local = cp->local;
+
+	if (!local)
+		return;
+
+	IP_VS_DBG_BUF(7, "Unbind-laddr %s c:%s:%d v:%s:%d l:%s:%d "
+		      "d:%s:%d fwd:%c s:%u conn->flags:%X conn->refcnt:%d "
+		      "local->refcnt:%d\n",
+		      ip_vs_proto_name(cp->protocol),
+		      IP_VS_DBG_ADDR(cp->af, &cp->caddr), ntohs(cp->cport),
+		      IP_VS_DBG_ADDR(cp->af, &cp->vaddr), ntohs(cp->vport),
+		      IP_VS_DBG_ADDR(cp->af, &cp->laddr), ntohs(cp->lport),
+		      IP_VS_DBG_ADDR(cp->af, &cp->daddr), ntohs(cp->dport),
+		      ip_vs_fwd_tag(cp), cp->state,
+		      cp->flags, atomic_read(&cp->refcnt),
+		      atomic_read(&local->refcnt));
+
+	/* Update the connection counters */
+	atomic_dec(&local->conn_counts);
+
+	/*
+	 * Simply decrease the refcnt of the local address;
+	 */
+	ip_vs_laddr_put(local);
+}
 
 /*
  *	Checking if the destination of a connection template is available.
@@ -635,12 +887,14 @@ int ip_vs_check_template(struct ip_vs_conn *ct)
 	     (atomic_read(&dest->weight) == 0))) {
 		IP_VS_DBG_BUF(9, "check_template: dest not available for "
 			      "protocol %s s:%s:%d v:%s:%d "
-			      "-> d:%s:%d\n",
+			      "-> l:%s:%d d:%s:%d\n",
 			      ip_vs_proto_name(ct->protocol),
 			      IP_VS_DBG_ADDR(ct->af, &ct->caddr),
 			      ntohs(ct->cport),
 			      IP_VS_DBG_ADDR(ct->af, &ct->vaddr),
 			      ntohs(ct->vport),
+			      IP_VS_DBG_ADDR(ct->af, &ct->laddr),
+			      ntohs(ct->lport),
 			      IP_VS_DBG_ADDR(ct->af, &ct->daddr),
 			      ntohs(ct->dport));
 
@@ -651,6 +905,7 @@ int ip_vs_check_template(struct ip_vs_conn *ct)
 			if (ip_vs_conn_unhash(ct)) {
 				ct->dport = htons(0xffff);
 				ct->vport = htons(0xffff);
+				ct->lport = 0;
 				ct->cport = 0;
 				ip_vs_conn_hash(ct);
 			}
@@ -666,11 +921,46 @@ int ip_vs_check_template(struct ip_vs_conn *ct)
 	return 1;
 }
 
+/* Warning: only be allowed call in ip_vs_conn_new */
+static void ip_vs_conn_del(struct ip_vs_conn *cp)
+{
+	if (cp == NULL)
+		return;
+
+	/* delete the timer if it is activated by other users */
+	if (timer_pending(&cp->timer))
+		del_timer(&cp->timer);
+
+	/* does anybody control me? */
+	if (cp->control)
+		ip_vs_control_del(cp);
+
+	if (unlikely(cp->app != NULL))
+		ip_vs_unbind_app(cp);
+	ip_vs_unbind_dest(cp);
+	ip_vs_unbind_laddr(cp);
+	if (cp->flags & IP_VS_CONN_F_NO_CPORT)
+		atomic_dec(&ip_vs_conn_no_cport_cnt);
+	atomic_dec(&ip_vs_conn_count);
+
+	kmem_cache_free(ip_vs_conn_cachep, cp);
+	cp = NULL;
+}
+
 static void ip_vs_conn_expire(unsigned long data)
 {
 	struct ip_vs_conn *cp = (struct ip_vs_conn *)data;
+	struct sk_buff *tmp_skb = NULL;
+	struct ip_vs_protocol *pp = ip_vs_proto_get(cp->protocol);
 
-	cp->timeout = 60*HZ;
+	/*
+	 * Set proper timeout.
+	 */
+	if ((pp != NULL) && (pp->timeout_table != NULL)) {
+		cp->timeout = pp->timeout_table[cp->state];
+	} else {
+		cp->timeout = 60*HZ;
+	}
 
 	/*
 	 *	hey, I'm using it
@@ -678,7 +968,26 @@ static void ip_vs_conn_expire(unsigned long data)
 	atomic_inc(&cp->refcnt);
 
 	/*
-	 *	do I control anybody?
+	 * Retransmit syn packet to rs.
+	 * We just check syn_skb is not NULL, as syn_skb 
+	 * is stored only if syn-proxy is enabled.
+	 */
+	spin_lock(&cp->lock);
+	if (cp->syn_skb != NULL && atomic_read(&cp->syn_retry_max) > 0) {
+		atomic_dec(&cp->syn_retry_max);
+		if (cp->packet_xmit) {
+			tmp_skb = skb_copy(cp->syn_skb, GFP_ATOMIC);
+			cp->packet_xmit(tmp_skb, cp, pp);
+		}
+		/* statistics */
+		IP_VS_INC_ESTATS(ip_vs_esmib, SYNPROXY_RS_ERROR);
+		spin_unlock(&cp->lock);
+		goto expire_later;
+	}
+	spin_unlock(&cp->lock);
+
+	/*
+	 *      do I control anybody?
 	 */
 	if (atomic_read(&cp->n_control))
 		goto expire_later;
@@ -701,13 +1010,29 @@ static void ip_vs_conn_expire(unsigned long data)
 		if (cp->control)
 			ip_vs_control_del(cp);
 
+		if (pp->conn_expire_handler)
+			pp->conn_expire_handler(pp, cp);
+
 		if (unlikely(cp->app != NULL))
 			ip_vs_unbind_app(cp);
 		ip_vs_unbind_dest(cp);
+		ip_vs_unbind_laddr(cp);
 		if (cp->flags & IP_VS_CONN_F_NO_CPORT)
 			atomic_dec(&ip_vs_conn_no_cport_cnt);
 		atomic_dec(&ip_vs_conn_count);
 
+		/* free stored ack packet */
+		while ((tmp_skb = skb_dequeue(&cp->ack_skb)) != NULL) {
+			kfree_skb(tmp_skb);
+			tmp_skb = NULL;
+		}
+
+		/* free stored syn skb */
+		if ((tmp_skb = xchg(&cp->syn_skb, NULL)) != NULL) {
+			kfree_skb(tmp_skb);
+			tmp_skb = NULL;
+		}
+
 		kmem_cache_free(ip_vs_conn_cachep, cp);
 		return;
 	}
@@ -738,10 +1063,12 @@ struct ip_vs_conn *
 ip_vs_conn_new(int af, int proto, const union nf_inet_addr *caddr, __be16 cport,
 	       const union nf_inet_addr *vaddr, __be16 vport,
 	       const union nf_inet_addr *daddr, __be16 dport, unsigned flags,
-	       struct ip_vs_dest *dest)
+	       struct ip_vs_dest *dest, struct sk_buff *skb, int is_synproxy_on)
 {
 	struct ip_vs_conn *cp;
 	struct ip_vs_protocol *pp = ip_vs_proto_get(proto);
+	struct ip_vs_conn_idx *ci_idx, *co_idx;
+	struct tcphdr _tcph, *th;
 
 	cp = kmem_cache_zalloc(ip_vs_conn_cachep, GFP_ATOMIC);
 	if (cp == NULL) {
@@ -749,7 +1076,35 @@ ip_vs_conn_new(int af, int proto, const union nf_inet_addr *caddr, __be16 cport,
 		return NULL;
 	}
 
-	INIT_LIST_HEAD(&cp->c_list);
+	/* init connection index of OUTside2INside */
+	ci_idx =
+	    (struct ip_vs_conn_idx *)(((__u8 *) cp) +
+				      sizeof(struct ip_vs_conn));
+	INIT_LIST_HEAD(&ci_idx->c_list);
+	ci_idx->af = af;
+	ci_idx->protocol = proto;
+	ip_vs_addr_copy(af, &ci_idx->s_addr, caddr);
+	ci_idx->s_port = cport;
+	ip_vs_addr_copy(af, &ci_idx->d_addr, vaddr);
+	ci_idx->d_port = vport;
+	ci_idx->flags |= IP_VS_CIDX_F_OUT2IN;
+	ci_idx->cp = cp;
+
+	/* init connection index of INside2OUTside */
+	co_idx =
+	    (struct ip_vs_conn_idx *)(((__u8 *) cp) +
+				      sizeof(struct ip_vs_conn) +
+				      sizeof(struct ip_vs_conn_idx));
+	INIT_LIST_HEAD(&co_idx->c_list);
+	co_idx->af = af;
+	co_idx->protocol = proto;
+	ip_vs_addr_copy(proto == IPPROTO_IP ? AF_UNSPEC : af,
+			&co_idx->s_addr, daddr);
+	co_idx->s_port = dport;
+	co_idx->flags |= IP_VS_CIDX_F_IN2OUT;
+	co_idx->cp = cp;
+
+	/* now init connection */
 	setup_timer(&cp->timer, ip_vs_conn_expire, (unsigned long)cp);
 	cp->af		   = af;
 	cp->protocol	   = proto;
@@ -763,6 +1118,8 @@ ip_vs_conn_new(int af, int proto, const union nf_inet_addr *caddr, __be16 cport,
 	cp->dport          = dport;
 	cp->flags	   = flags;
 	spin_lock_init(&cp->lock);
+	cp->in_idx = ci_idx;
+	cp->out_idx = co_idx;
 
 	/*
 	 * Set the entry is referenced by the current thread before hashing
@@ -796,8 +1153,46 @@ ip_vs_conn_new(int af, int proto, const union nf_inet_addr *caddr, __be16 cport,
 	if (unlikely(pp && atomic_read(&pp->appcnt)))
 		ip_vs_bind_app(cp, pp);
 
-	/* Hash it in the ip_vs_conn_tab finally */
-	ip_vs_conn_hash(cp);
+
+	/* Set syn-proxy members 
+	 * Set cp->flag manually to avoid svn->flags change when 
+	 * ack_skb is on the way
+	 */
+	skb_queue_head_init(&cp->ack_skb);
+	atomic_set(&cp->syn_retry_max, 0);
+	if (is_synproxy_on == 1 && skb != NULL) {
+
+		th = skb_header_pointer(skb, ip_hdr(skb)->ihl * 4,
+					sizeof(_tcph), &_tcph);
+		if (th == NULL) {
+			IP_VS_ERR_RL("%s(): get tcphdr failed\n", __func__);
+			ip_vs_conn_del(cp);
+			return NULL;
+		}
+		/* Set syn-proxy flag */
+		cp->flags |= IP_VS_CONN_F_SYNPROXY;
+
+		/* Save ack packet */
+		skb_queue_tail(&cp->ack_skb, skb);
+		/* Save ack_seq - 1 */
+		cp->syn_proxy_seq.init_seq =
+		    htonl((__u32) ((htonl(th->ack_seq) - 1)));
+		/* Use IP_VS_TCP_S_SYN_SENT for syn */
+		cp->timeout = pp->timeout_table[cp->state =
+						IP_VS_TCP_S_SYN_SENT];
+	} else {
+		/* Unset syn-proxy flag */
+		cp->flags &= ~IP_VS_CONN_F_SYNPROXY;
+	}
+
+	/*
+	 * bind the connection with a local address
+	 * and hash it in the ip_vs_conn_tab finally.
+	 */
+	if (ip_vs_hbind_laddr(cp) == 0) {
+		ip_vs_conn_del(cp);
+		return NULL;
+	}
 
 	return cp;
 }
@@ -811,14 +1206,14 @@ ip_vs_conn_new(int af, int proto, const union nf_inet_addr *caddr, __be16 cport,
 static void *ip_vs_conn_array(struct seq_file *seq, loff_t pos)
 {
 	int idx;
-	struct ip_vs_conn *cp;
+	struct ip_vs_conn_idx *cidx;
 
-	for(idx = 0; idx < IP_VS_CONN_TAB_SIZE; idx++) {
+	for (idx = 0; idx < IP_VS_CONN_TAB_SIZE; idx++) {
 		ct_read_lock_bh(idx);
-		list_for_each_entry(cp, &ip_vs_conn_tab[idx], c_list) {
-			if (pos-- == 0) {
+		list_for_each_entry(cidx, &ip_vs_conn_tab[idx], c_list) {
+			if ((cidx->flags & IP_VS_CIDX_F_OUT2IN) && (pos-- == 0)) {
 				seq->private = &ip_vs_conn_tab[idx];
-				return cp;
+				return cidx->cp;
 			}
 		}
 		ct_read_unlock_bh(idx);
@@ -837,24 +1232,32 @@ static void *ip_vs_conn_seq_next(struct seq_file *seq, void *v, loff_t *pos)
 {
 	struct ip_vs_conn *cp = v;
 	struct list_head *e, *l = seq->private;
+	struct ip_vs_conn_idx *cidx;
 	int idx;
 
 	++*pos;
 	if (v == SEQ_START_TOKEN)
 		return ip_vs_conn_array(seq, 0);
 
+	cidx = cp->in_idx;
 	/* more on same hash chain? */
-	if ((e = cp->c_list.next) != l)
-		return list_entry(e, struct ip_vs_conn, c_list);
+	while ((e = cidx->c_list.next) != l) {
+		cidx = list_entry(e, struct ip_vs_conn_idx, c_list);
+		if (cidx->flags & IP_VS_CIDX_F_OUT2IN) {
+			return cidx->cp;
+		}
+	}
 
 	idx = l - ip_vs_conn_tab;
 	ct_read_unlock_bh(idx);
 
 	while (++idx < IP_VS_CONN_TAB_SIZE) {
 		ct_read_lock_bh(idx);
-		list_for_each_entry(cp, &ip_vs_conn_tab[idx], c_list) {
-			seq->private = &ip_vs_conn_tab[idx];
-			return cp;
+		list_for_each_entry(cidx, &ip_vs_conn_tab[idx], c_list) {
+			if (cidx->flags & IP_VS_CIDX_F_OUT2IN) {
+				seq->private = &ip_vs_conn_tab[idx];
+				return cidx->cp;
+			}
 		}
 		ct_read_unlock_bh(idx);
 	}
@@ -875,30 +1278,33 @@ static int ip_vs_conn_seq_show(struct seq_file *seq, void *v)
 
 	if (v == SEQ_START_TOKEN)
 		seq_puts(seq,
-   "Pro FromIP   FPrt ToIP     TPrt DestIP   DPrt State       Expires\n");
+   "Pro FromIP   FPrt ToIP     TPrt LocalIP  LPrt DestIP   DPrt State       Expires\n");
 	else {
 		const struct ip_vs_conn *cp = v;
 
 #ifdef CONFIG_IP_VS_IPV6
 		if (cp->af == AF_INET6)
-			seq_printf(seq, "%-3s %pI6 %04X %pI6 %04X %pI6 %04X %-11s %7lu\n",
-				ip_vs_proto_name(cp->protocol),
-				&cp->caddr.in6, ntohs(cp->cport),
-				&cp->vaddr.in6, ntohs(cp->vport),
-				&cp->daddr.in6, ntohs(cp->dport),
-				ip_vs_state_name(cp->protocol, cp->state),
-				(cp->timer.expires-jiffies)/HZ);
+			seq_printf(seq, "%-3s %pI6 %04X %pI6 %04X %pI6 %04X %pI6 %04X %-11s %7lu\n",
+				ip_vs_proto_name(cp->protocol),
+				&cp->caddr.in6, ntohs(cp->cport),
+				&cp->vaddr.in6, ntohs(cp->vport),
+				&cp->laddr.in6, ntohs(cp->lport),
+				&cp->daddr.in6, ntohs(cp->dport),
+				ip_vs_state_name(cp->protocol, cp->state),
+				(cp->timer.expires-jiffies)/HZ);
+
 		else
 #endif
 			seq_printf(seq,
-				"%-3s %08X %04X %08X %04X"
-				" %08X %04X %-11s %7lu\n",
-				ip_vs_proto_name(cp->protocol),
-				ntohl(cp->caddr.ip), ntohs(cp->cport),
-				ntohl(cp->vaddr.ip), ntohs(cp->vport),
-				ntohl(cp->daddr.ip), ntohs(cp->dport),
-				ip_vs_state_name(cp->protocol, cp->state),
-				(cp->timer.expires-jiffies)/HZ);
+				"%-3s %08X %04X %08X %04X"
+				" %08X %04X %08X %04X %-11s %7lu\n",
+				ip_vs_proto_name(cp->protocol),
+				ntohl(cp->caddr.ip), ntohs(cp->cport),
+				ntohl(cp->vaddr.ip), ntohs(cp->vport),
+				ntohl(cp->laddr.ip), ntohs(cp->lport),
+				ntohl(cp->daddr.ip), ntohs(cp->dport),
+				ip_vs_state_name(cp->protocol, cp->state),
+				(cp->timer.expires-jiffies)/HZ);
 	}
 	return 0;
 }
@@ -936,32 +1342,35 @@ static int ip_vs_conn_sync_seq_show(struct seq_file *seq, void *v)
 
 	if (v == SEQ_START_TOKEN)
 		seq_puts(seq,
-   "Pro FromIP   FPrt ToIP     TPrt DestIP   DPrt State       Origin Expires\n");
+   "Pro FromIP   FPrt ToIP     TPrt LocalIP  LPrt DestIP   DPrt State       Origin Expires\n");
 	else {
 		const struct ip_vs_conn *cp = v;
 
 #ifdef CONFIG_IP_VS_IPV6
 		if (cp->af == AF_INET6)
-			seq_printf(seq, "%-3s %pI6 %04X %pI6 %04X %pI6 %04X %-11s %-6s %7lu\n",
-				ip_vs_proto_name(cp->protocol),
-				&cp->caddr.in6, ntohs(cp->cport),
-				&cp->vaddr.in6, ntohs(cp->vport),
-				&cp->daddr.in6, ntohs(cp->dport),
-				ip_vs_state_name(cp->protocol, cp->state),
-				ip_vs_origin_name(cp->flags),
-				(cp->timer.expires-jiffies)/HZ);
+			seq_printf(seq, "%-3s %pI6 %04X %pI6 %04X %pI6 %04X %pI6 %04X %-11s %-6s %7lu\n",
+				ip_vs_proto_name(cp->protocol),
+				&cp->caddr.in6, ntohs(cp->cport),
+				&cp->vaddr.in6, ntohs(cp->vport),
+				&cp->laddr.in6, ntohs(cp->lport),
+				&cp->daddr.in6, ntohs(cp->dport),
+				ip_vs_state_name(cp->protocol, cp->state),
+				ip_vs_origin_name(cp->flags),
+				(cp->timer.expires-jiffies)/HZ);
+
 		else
 #endif
 			seq_printf(seq,
-				"%-3s %08X %04X %08X %04X "
-				"%08X %04X %-11s %-6s %7lu\n",
-				ip_vs_proto_name(cp->protocol),
-				ntohl(cp->caddr.ip), ntohs(cp->cport),
-				ntohl(cp->vaddr.ip), ntohs(cp->vport),
-				ntohl(cp->daddr.ip), ntohs(cp->dport),
-				ip_vs_state_name(cp->protocol, cp->state),
-				ip_vs_origin_name(cp->flags),
-				(cp->timer.expires-jiffies)/HZ);
+				"%-3s %08X %04X %08X %04X "
+				"%08X %04X %08X %04X %-11s %-6s %7lu\n",
+				ip_vs_proto_name(cp->protocol),
+				ntohl(cp->caddr.ip), ntohs(cp->cport),
+				ntohl(cp->vaddr.ip), ntohs(cp->vport),
+				ntohl(cp->laddr.ip), ntohs(cp->lport),
+				ntohl(cp->daddr.ip), ntohs(cp->dport),
+				ip_vs_state_name(cp->protocol, cp->state),
+				ip_vs_origin_name(cp->flags),
+				(cp->timer.expires-jiffies)/HZ);
 	}
 	return 0;
 }
@@ -1025,6 +1434,7 @@ void ip_vs_random_dropentry(void)
 {
 	int idx;
 	struct ip_vs_conn *cp;
+	struct ip_vs_conn_idx *cidx;
 
 	/*
 	 * Randomly scan 1/32 of the whole table every second
@@ -1037,7 +1447,8 @@ void ip_vs_random_dropentry(void)
 		 */
 		ct_write_lock_bh(hash);
 
-		list_for_each_entry(cp, &ip_vs_conn_tab[hash], c_list) {
+		list_for_each_entry(cidx, &ip_vs_conn_tab[hash], c_list) {
+			cp = cidx->cp;
 			if (cp->flags & IP_VS_CONN_F_TEMPLATE)
 				/* connection template */
 				continue;
@@ -1080,6 +1491,7 @@ static void ip_vs_conn_flush(void)
 {
 	int idx;
 	struct ip_vs_conn *cp;
+	struct ip_vs_conn_idx *cidx;
 
   flush_again:
 	for (idx=0; idx<IP_VS_CONN_TAB_SIZE; idx++) {
@@ -1088,9 +1500,9 @@ static void ip_vs_conn_flush(void)
 		 */
 		ct_write_lock_bh(idx);
 
-		list_for_each_entry(cp, &ip_vs_conn_tab[idx], c_list) {
-
+		list_for_each_entry(cidx, &ip_vs_conn_tab[idx], c_list) {
 			IP_VS_DBG(4, "del connection\n");
+			cp = cidx->cp;
 			ip_vs_conn_expire_now(cp);
 			if (cp->control) {
 				IP_VS_DBG(4, "del conn template\n");
@@ -1122,7 +1534,7 @@ int __init ip_vs_conn_init(void)
 
 	/* Allocate ip_vs_conn slab cache */
 	ip_vs_conn_cachep = kmem_cache_create("ip_vs_conn",
-					      sizeof(struct ip_vs_conn), 0,
+					      sizeof(struct ip_vs_conn) + 2 * sizeof(struct ip_vs_conn_idx), 0, 
 					      SLAB_HWCACHE_ALIGN, NULL);
 	if (!ip_vs_conn_cachep) {
 		vfree(ip_vs_conn_tab);
@@ -1134,7 +1546,7 @@ int __init ip_vs_conn_init(void)
 		IP_VS_CONN_TAB_SIZE,
 		(long)(IP_VS_CONN_TAB_SIZE*sizeof(struct list_head))/1024);
 	IP_VS_DBG(0, "Each connection entry needs %Zd bytes at least\n",
-		  sizeof(struct ip_vs_conn));
+		  sizeof(struct ip_vs_conn) + 2 * sizeof(struct ip_vs_conn_idx));
 
 	for (idx = 0; idx < IP_VS_CONN_TAB_SIZE; idx++) {
 		INIT_LIST_HEAD(&ip_vs_conn_tab[idx]);
diff --git a/net/netfilter/ipvs/ip_vs_core.c b/net/netfilter/ipvs/ip_vs_core.c
old mode 100644
new mode 100755
index d599bcc..4facbec
--- a/net/netfilter/ipvs/ip_vs_core.c
+++ b/net/netfilter/ipvs/ip_vs_core.c
@@ -22,6 +22,11 @@
  *	Paul `Rusty' Russell		properly handle non-linear skbs
  *	Harald Welte			don't use nfcache
  *
+ *	Wen Li       <steel.mental@gmail.com>
+ *	Jiaming Wu   <pukong.wjm@taobao.com>   support FULLNAT and SYNPROXY
+ *
+ *   Yu Bo        <yubo@xiaomi.com>
+ *
  */
 
 #define KMSG_COMPONENT "IPVS"
@@ -49,15 +54,14 @@
 #endif
 
 #include <net/ip_vs.h>
-
+#include <net/ip_vs_synproxy.h>
 
 EXPORT_SYMBOL(register_ip_vs_scheduler);
 EXPORT_SYMBOL(unregister_ip_vs_scheduler);
 EXPORT_SYMBOL(ip_vs_skb_replace);
 EXPORT_SYMBOL(ip_vs_proto_name);
 EXPORT_SYMBOL(ip_vs_conn_new);
-EXPORT_SYMBOL(ip_vs_conn_in_get);
-EXPORT_SYMBOL(ip_vs_conn_out_get);
+EXPORT_SYMBOL(ip_vs_conn_get);
 #ifdef CONFIG_IP_VS_PROTO_TCP
 EXPORT_SYMBOL(ip_vs_tcp_conn_listen);
 #endif
@@ -192,8 +196,9 @@ ip_vs_onepacket_enabled(struct ip_vs_service *svc, struct ip_vs_iphdr *iph)
  */
 static struct ip_vs_conn *
 ip_vs_sched_persist(struct ip_vs_service *svc,
-		    const struct sk_buff *skb,
-		    __be16 ports[2])
+					      struct sk_buff *skb,
+					      __be16 ports[2],
+					      int is_synproxy_on)
 {
 	struct ip_vs_conn *cp = NULL;
 	struct ip_vs_iphdr iph;
@@ -265,14 +270,14 @@ ip_vs_sched_persist(struct ip_vs_service *svc,
 						    ports[1],
 						    &dest->addr, dest->port,
 						    IP_VS_CONN_F_TEMPLATE,
-						    dest);
+						    dest, NULL, 0);
 			else
 				ct = ip_vs_conn_new(svc->af, iph.protocol,
 						    &snet, 0,
 						    &iph.daddr, 0,
 						    &dest->addr, 0,
 						    IP_VS_CONN_F_TEMPLATE,
-						    dest);
+						    dest, NULL, 0);
 			if (ct == NULL)
 				return NULL;
 
@@ -327,14 +332,14 @@ ip_vs_sched_persist(struct ip_vs_service *svc,
 						    &fwmark, 0,
 						    &dest->addr, 0,
 						    IP_VS_CONN_F_TEMPLATE,
-						    dest);
+						    dest, NULL, 0);
 			} else
 				ct = ip_vs_conn_new(svc->af, iph.protocol,
 						    &snet, 0,
 						    &iph.daddr, 0,
 						    &dest->addr, 0,
 						    IP_VS_CONN_F_TEMPLATE,
-						    dest);
+						    dest, NULL, 0);
 			if (ct == NULL)
 				return NULL;
 
@@ -354,7 +359,7 @@ ip_vs_sched_persist(struct ip_vs_service *svc,
 			    &iph.daddr, ports[1],
 			    &dest->addr, dport,
 			    ip_vs_onepacket_enabled(svc, &iph),
-			    dest);
+			    dest, skb, is_synproxy_on);
 	if (cp == NULL) {
 		ip_vs_conn_put(ct);
 		return NULL;
@@ -378,13 +383,14 @@ ip_vs_sched_persist(struct ip_vs_service *svc,
  *  Protocols supported: TCP, UDP
  */
 struct ip_vs_conn *
-ip_vs_schedule(struct ip_vs_service *svc, const struct sk_buff *skb)
+ip_vs_schedule(struct ip_vs_service *svc, struct sk_buff *skb, int is_synproxy_on)
 {
 	struct ip_vs_conn *cp = NULL;
 	struct ip_vs_iphdr iph;
 	struct ip_vs_dest *dest;
 	__be16 _ports[2], *pptr;
 
+	EnterFunction(11);
 	ip_vs_fill_iphdr(svc->af, skb_network_header(skb), &iph);
 	pptr = skb_header_pointer(skb, iph.len, sizeof(_ports), _ports);
 	if (pptr == NULL)
@@ -394,40 +400,81 @@ ip_vs_schedule(struct ip_vs_service *svc, const struct sk_buff *skb)
 	 *    Persistent service
 	 */
 	if (svc->flags & IP_VS_SVC_F_PERSISTENT)
-		return ip_vs_sched_persist(svc, skb, pptr);
+		return ip_vs_sched_persist(svc, skb, pptr, is_synproxy_on);
+
 
 	/*
-	 *    Non-persistent service
+	 *    dsnat yubo@xiaomi.com
 	 */
-	if (!svc->fwmark && pptr[1] != svc->port) {
-		if (!svc->port)
-			pr_err("Schedule: port zero only supported "
-			       "in persistent services, "
-			       "check your ipvs configuration\n");
-		return NULL;
-	}
+	if (svc->port == 0){	
+	EnterFunction(11);
 
-	dest = svc->scheduler->schedule(svc, skb);
-	if (dest == NULL) {
-		IP_VS_DBG(1, "Schedule: no dest found.\n");
-		return NULL;
+		dest = (struct ip_vs_dest *)svc->destinations.next;
+		if (dest == NULL) {
+			IP_VS_DBG(1, "Schedule: no dest found.\n");
+			return NULL;
+		}
+
+		/*
+		 *    Create a connection entry.
+		 */
+		cp = ip_vs_conn_new(svc->af, iph.protocol,
+				    &iph.saddr, pptr[0],
+				    &iph.daddr, pptr[1],
+				    &iph.daddr, pptr[1],
+				    ip_vs_onepacket_enabled(svc, &iph),
+				    dest, skb, is_synproxy_on);
+		
+		IP_VS_DBG_BUF(6, "Schedule dsnat fwd:%c c:%s:%u v:%s:%u "
+	      "l:%s:%u d:%s:%u conn->flags:%X conn->refcnt:%d\n",
+	      ip_vs_fwd_tag(cp),
+	      IP_VS_DBG_ADDR(svc->af, &cp->caddr), ntohs(cp->cport),
+	      IP_VS_DBG_ADDR(svc->af, &cp->vaddr), ntohs(cp->vport),
+	      IP_VS_DBG_ADDR(svc->af, &cp->laddr), ntohs(cp->lport),
+	      IP_VS_DBG_ADDR(svc->af, &cp->daddr), ntohs(cp->dport),
+	      cp->flags, atomic_read(&cp->refcnt));
+
+			
+	}else{
+		/*
+		 *    Non-persistent service
+		 */
+		if (!svc->fwmark && pptr[1] != svc->port) {
+			if (!svc->port)
+				pr_err("Schedule: port zero only supported "
+				       "in persistent services, "
+				       "check your ipvs configuration\n");
+			return NULL;
+		}
+
+		dest = svc->scheduler->schedule(svc, skb);
+
+		if (dest == NULL) {
+			IP_VS_DBG(1, "Schedule: no dest found.\n");
+			return NULL;
+		}
+
+		/*
+		 *    Create a connection entry.
+		 */
+		cp = ip_vs_conn_new(svc->af, iph.protocol,
+				    &iph.saddr, pptr[0],
+				    &iph.daddr, pptr[1],
+				    &dest->addr, dest->port ? dest->port : pptr[1],
+				    ip_vs_onepacket_enabled(svc, &iph),
+				    dest, skb, is_synproxy_on);
+
+		
 	}
+	
 
-	/*
-	 *    Create a connection entry.
-	 */
-	cp = ip_vs_conn_new(svc->af, iph.protocol,
-			    &iph.saddr, pptr[0],
-			    &iph.daddr, pptr[1],
-			    &dest->addr, dest->port ? dest->port : pptr[1],
-			    ip_vs_onepacket_enabled(svc, &iph),
-			    dest);
 	if (cp == NULL)
 		return NULL;
 
-	IP_VS_DBG_BUF(6, "Schedule fwd:%c c:%s:%u v:%s:%u "
+	IP_VS_DBG_BUF(6, "Schedule fwd:%c vs:%s:%u c:%s:%u v:%s:%u "
 		      "d:%s:%u conn->flags:%X conn->refcnt:%d\n",
 		      ip_vs_fwd_tag(cp),
+		      IP_VS_DBG_ADDR(svc->af, &svc->addr), ntohs(svc->port),
 		      IP_VS_DBG_ADDR(svc->af, &cp->caddr), ntohs(cp->cport),
 		      IP_VS_DBG_ADDR(svc->af, &cp->vaddr), ntohs(cp->vport),
 		      IP_VS_DBG_ADDR(svc->af, &cp->daddr), ntohs(cp->dport),
@@ -482,7 +529,7 @@ int ip_vs_leave(struct ip_vs_service *svc, struct sk_buff *skb,
 				    &daddr, 0,
 				    IP_VS_CONN_F_BYPASS |
 				    ip_vs_onepacket_enabled(svc, &iph),
-				    NULL);
+				    NULL, NULL, 0);
 		if (cp == NULL)
 			return NF_DROP;
 
@@ -575,98 +622,6 @@ static inline int ip_vs_gather_frags_v6(struct sk_buff *skb, u_int32_t user)
 }
 #endif
 
-/*
- * Packet has been made sufficiently writable in caller
- * - inout: 1=in->out, 0=out->in
- */
-void ip_vs_nat_icmp(struct sk_buff *skb, struct ip_vs_protocol *pp,
-		    struct ip_vs_conn *cp, int inout)
-{
-	struct iphdr *iph	 = ip_hdr(skb);
-	unsigned int icmp_offset = iph->ihl*4;
-	struct icmphdr *icmph	 = (struct icmphdr *)(skb_network_header(skb) +
-						      icmp_offset);
-	struct iphdr *ciph	 = (struct iphdr *)(icmph + 1);
-
-	if (inout) {
-		iph->saddr = cp->vaddr.ip;
-		ip_send_check(iph);
-		ciph->daddr = cp->vaddr.ip;
-		ip_send_check(ciph);
-	} else {
-		iph->daddr = cp->daddr.ip;
-		ip_send_check(iph);
-		ciph->saddr = cp->daddr.ip;
-		ip_send_check(ciph);
-	}
-
-	/* the TCP/UDP/SCTP port */
-	if (IPPROTO_TCP == ciph->protocol || IPPROTO_UDP == ciph->protocol ||
-	    IPPROTO_SCTP == ciph->protocol) {
-		__be16 *ports = (void *)ciph + ciph->ihl*4;
-
-		if (inout)
-			ports[1] = cp->vport;
-		else
-			ports[0] = cp->dport;
-	}
-
-	/* And finally the ICMP checksum */
-	icmph->checksum = 0;
-	icmph->checksum = ip_vs_checksum_complete(skb, icmp_offset);
-	skb->ip_summed = CHECKSUM_UNNECESSARY;
-
-	if (inout)
-		IP_VS_DBG_PKT(11, pp, skb, (void *)ciph - (void *)iph,
-			"Forwarding altered outgoing ICMP");
-	else
-		IP_VS_DBG_PKT(11, pp, skb, (void *)ciph - (void *)iph,
-			"Forwarding altered incoming ICMP");
-}
-
-#ifdef CONFIG_IP_VS_IPV6
-void ip_vs_nat_icmp_v6(struct sk_buff *skb, struct ip_vs_protocol *pp,
-		    struct ip_vs_conn *cp, int inout)
-{
-	struct ipv6hdr *iph	 = ipv6_hdr(skb);
-	unsigned int icmp_offset = sizeof(struct ipv6hdr);
-	struct icmp6hdr *icmph	 = (struct icmp6hdr *)(skb_network_header(skb) +
-						      icmp_offset);
-	struct ipv6hdr *ciph	 = (struct ipv6hdr *)(icmph + 1);
-
-	if (inout) {
-		iph->saddr = cp->vaddr.in6;
-		ciph->daddr = cp->vaddr.in6;
-	} else {
-		iph->daddr = cp->daddr.in6;
-		ciph->saddr = cp->daddr.in6;
-	}
-
-	/* the TCP/UDP/SCTP port */
-	if (IPPROTO_TCP == ciph->nexthdr || IPPROTO_UDP == ciph->nexthdr ||
-	    IPPROTO_SCTP == ciph->nexthdr) {
-		__be16 *ports = (void *)ciph + sizeof(struct ipv6hdr);
-
-		if (inout)
-			ports[1] = cp->vport;
-		else
-			ports[0] = cp->dport;
-	}
-
-	/* And finally the ICMP checksum */
-	icmph->icmp6_cksum = 0;
-	/* TODO IPv6: is this correct for ICMPv6? */
-	ip_vs_checksum_complete(skb, icmp_offset);
-	skb->ip_summed = CHECKSUM_UNNECESSARY;
-
-	if (inout)
-		IP_VS_DBG_PKT(11, pp, skb, (void *)ciph - (void *)iph,
-			"Forwarding altered outgoing ICMPv6");
-	else
-		IP_VS_DBG_PKT(11, pp, skb, (void *)ciph - (void *)iph,
-			"Forwarding altered incoming ICMPv6");
-}
-#endif
 
 /* Handle relevant response ICMP messages - forward to the right
  * destination host. Used for NAT and local client.
@@ -679,7 +634,8 @@ static int handle_response_icmp(int af, struct sk_buff *skb,
 {
 	unsigned int verdict = NF_DROP;
 
-	if (IP_VS_FWD_METHOD(cp) != 0) {
+	if ((IP_VS_FWD_METHOD(cp) != IP_VS_CONN_F_MASQ)
+	    && (IP_VS_FWD_METHOD(cp) != IP_VS_CONN_F_FULLNAT)) {
 		pr_err("shouldn't reach here, because the box is on the "
 		       "half connection in the tun/dr module.\n");
 	}
@@ -695,23 +651,35 @@ static int handle_response_icmp(int af, struct sk_buff *skb,
 	if (IPPROTO_TCP == protocol || IPPROTO_UDP == protocol ||
 	    IPPROTO_SCTP == protocol)
 		offset += 2 * sizeof(__u16);
-	if (!skb_make_writable(skb, offset))
-		goto out;
-
-#ifdef CONFIG_IP_VS_IPV6
-	if (af == AF_INET6)
-		ip_vs_nat_icmp_v6(skb, pp, cp, 1);
-	else
-#endif
-		ip_vs_nat_icmp(skb, pp, cp, 1);
 
 	/* do the statistics and put it back */
 	ip_vs_out_stats(cp, skb);
 
-	skb->ipvs_property = 1;
-	verdict = NF_ACCEPT;
+	if (IP_VS_FWD_METHOD(cp) == IP_VS_CONN_F_FULLNAT) {
+#ifdef CONFIG_IP_VS_IPV6
+		if (af == AF_INET6)
+			verdict = ip_vs_fnat_response_icmp_xmit_v6(skb, pp, cp, offset);
+
+
+		else
+#endif
+			verdict = ip_vs_fnat_response_icmp_xmit(skb, pp, cp, offset);
+
 
-out:
+	} else {
+#ifdef CONFIG_IP_VS_IPV6
+		if (af == AF_INET6)
+			verdict = ip_vs_normal_response_icmp_xmit_v6(skb, pp, cp, offset);
+
+
+		else
+#endif
+			verdict = ip_vs_normal_response_icmp_xmit(skb, pp, cp, offset);
+
+
+	}
+
+      out:
 	__ip_vs_conn_put(cp);
 
 	return verdict;
@@ -732,6 +700,7 @@ static int ip_vs_out_icmp(struct sk_buff *skb, int *related)
 	struct ip_vs_protocol *pp;
 	unsigned int offset, ihl;
 	union nf_inet_addr snet;
+	int res_dir;
 
 	*related = 1;
 
@@ -786,7 +755,7 @@ static int ip_vs_out_icmp(struct sk_buff *skb, int *related)
 
 	ip_vs_fill_iphdr(AF_INET, cih, &ciph);
 	/* The embedded headers contain source and dest in reverse order */
-	cp = pp->conn_out_get(AF_INET, skb, pp, &ciph, offset, 1);
+	cp = pp->conn_out_get(AF_INET, skb, pp, &ciph, offset, 1, &res_dir);
 	if (!cp)
 		return NF_ACCEPT;
 
@@ -807,6 +776,7 @@ static int ip_vs_out_icmp_v6(struct sk_buff *skb, int *related)
 	struct ip_vs_protocol *pp;
 	unsigned int offset;
 	union nf_inet_addr snet;
+	int res_dir;
 
 	*related = 1;
 
@@ -861,7 +831,7 @@ static int ip_vs_out_icmp_v6(struct sk_buff *skb, int *related)
 
 	ip_vs_fill_iphdr(AF_INET6, cih, &ciph);
 	/* The embedded headers contain source and dest in reverse order */
-	cp = pp->conn_out_get(AF_INET6, skb, pp, &ciph, offset, 1);
+	cp = pp->conn_out_get(AF_INET6, skb, pp, &ciph, offset, 1, &res_dir);
 	if (!cp)
 		return NF_ACCEPT;
 
@@ -897,61 +867,53 @@ static inline int is_tcp_reset(const struct sk_buff *skb, int nh_len)
 }
 
 /* Handle response packets: rewrite addresses and send away...
- * Used for NAT and local client.
+ * Used for NAT / local client / FULLNAT.
  */
 static unsigned int
 handle_response(int af, struct sk_buff *skb, struct ip_vs_protocol *pp,
 		struct ip_vs_conn *cp, int ihl)
 {
-	IP_VS_DBG_PKT(11, pp, skb, 0, "Outgoing packet");
+	unsigned int ret = NF_DROP;
+
+	/* statistics */
+	ip_vs_out_stats(cp, skb);
 
-	if (!skb_make_writable(skb, ihl))
-		goto drop;
+	/*
+	 * Syn-proxy step 3 logic: receive syn-ack from rs.
+	 */
+	if ( (pp->protocol == IPPROTO_TCP) && 
+		(ip_vs_synproxy_synack_rcv(skb, cp, pp, ihl, &ret) == 0) ) {
+		goto out;
+	}
 
-	/* mangle the packet */
-	if (pp->snat_handler && !pp->snat_handler(skb, pp, cp))
-		goto drop;
+	/* state transition */
+	ip_vs_set_state(cp, IP_VS_DIR_OUTPUT, skb, pp);
+	/* transmit */
 
+	if (cp->flags & IP_VS_CONN_F_FULLNAT) {
 #ifdef CONFIG_IP_VS_IPV6
-	if (af == AF_INET6)
-		ipv6_hdr(skb)->saddr = cp->vaddr.in6;
-	else
+		if (af == AF_INET6) {
+			ret = ip_vs_fnat_response_xmit_v6(skb, pp, cp, ihl);
+		} else
 #endif
-	{
-		ip_hdr(skb)->saddr = cp->vaddr.ip;
-		ip_send_check(ip_hdr(skb));
-	}
-
-	/* For policy routing, packets originating from this
-	 * machine itself may be routed differently to packets
-	 * passing through.  We want this packet to be routed as
-	 * if it came from this machine itself.  So re-compute
-	 * the routing information.
-	 */
+		{
+			ret = ip_vs_fnat_response_xmit(skb, pp, cp, ihl);
+		}
+	} else {
 #ifdef CONFIG_IP_VS_IPV6
-	if (af == AF_INET6) {
-		if (ip6_route_me_harder(skb) != 0)
-			goto drop;
-	} else
+		if (af == AF_INET6) {
+			ret = ip_vs_normal_response_xmit_v6(skb, pp, cp, ihl);
+		} else
 #endif
-		if (ip_route_me_harder(skb, RTN_LOCAL) != 0)
-			goto drop;
-
-	IP_VS_DBG_PKT(10, pp, skb, 0, "After SNAT");
-
-	ip_vs_out_stats(cp, skb);
-	ip_vs_set_state(cp, IP_VS_DIR_OUTPUT, skb, pp);
-	ip_vs_conn_put(cp);
-
-	skb->ipvs_property = 1;
+		{
+			ret = ip_vs_normal_response_xmit(skb, pp, cp, ihl);
+		}
 
-	LeaveFunction(11);
-	return NF_ACCEPT;
+	}
 
-drop:
+      out:
 	ip_vs_conn_put(cp);
-	kfree_skb(skb);
-	return NF_STOLEN;
+	return ret;
 }
 
 /*
@@ -967,6 +929,11 @@ ip_vs_out(unsigned int hooknum, struct sk_buff *skb,
 	struct ip_vs_protocol *pp;
 	struct ip_vs_conn *cp;
 	int af;
+	int res_dir;
+	int ret;
+	int v;
+	int pkts;
+	int forward = 0;
 
 	EnterFunction(11);
 
@@ -993,8 +960,11 @@ ip_vs_out(unsigned int hooknum, struct sk_buff *skb,
 			if (related)
 				return verdict;
 			ip_vs_fill_iphdr(af, skb_network_header(skb), &iph);
+		} else {
+			forward = 1;
 		}
 
+	/* Protocol supported? */
 	pp = ip_vs_proto_get(iph.protocol);
 	if (unlikely(!pp))
 		return NF_ACCEPT;
@@ -1023,34 +993,112 @@ ip_vs_out(unsigned int hooknum, struct sk_buff *skb,
 	/*
 	 * Check if the packet belongs to an existing entry
 	 */
-	cp = pp->conn_out_get(af, skb, pp, &iph, iph.len, 0);
+	cp = pp->conn_out_get(af, skb, pp, &iph, iph.len, 0, &res_dir);
+
+
+	//dsnat
+	if(forward){
+	EnterFunction(11);		
+		if (!cp) {
+			/* create a new connection */
+			int v;
+			IP_VS_DBG(11, "forward out 2 in  conn not found! -> tcp_conn_schedule\n");
+			if (!pp->conn_schedule(af | IP_VS_CONN_F_DSNAT, skb, pp, &v, &cp))
+				return v;
+	EnterFunction(11);	
+
+			if (unlikely(!cp)) {
+				/* sorry, all this trouble for a no-hit :) */
+				IP_VS_DBG_PKT(12, pp, skb, 0,
+					      "packet continues traversal as normal");
+				return NF_ACCEPT;
+			}		
+		}
 
-	if (unlikely(!cp)) {
-		if (sysctl_ip_vs_nat_icmp_send &&
-		    (pp->protocol == IPPROTO_TCP ||
-		     pp->protocol == IPPROTO_UDP ||
-		     pp->protocol == IPPROTO_SCTP)) {
-			__be16 _ports[2], *pptr;
-
-			pptr = skb_header_pointer(skb, iph.len,
-						  sizeof(_ports), _ports);
-			if (pptr == NULL)
-				return NF_ACCEPT;	/* Not for me */
-			if (ip_vs_lookup_real_service(af, iph.protocol,
-						      &iph.saddr,
-						      pptr[0])) {
-				/*
-				 * Notify the real server: there is no
-				 * existing entry if it is not RST
-				 * packet or not TCP packet.
-				 */
-				if ((iph.protocol != IPPROTO_TCP &&
-				     iph.protocol != IPPROTO_SCTP)
-				     || ((iph.protocol == IPPROTO_TCP
-					  && !is_tcp_reset(skb, iph.len))
-					 || (iph.protocol == IPPROTO_SCTP
-						&& !is_sctp_abort(skb,
-							iph.len)))) {
+		IP_VS_DBG_PKT(11, pp, skb, 0, "Incoming packet");
+		
+		ip_vs_in_stats(cp, skb);
+
+		/*
+		 * Filter out-in ack packet when cp is at SYN_SENT state.
+		 * DROP it if not a valid packet, STORE it if we have 
+		 * space left. 
+		 */
+		if ((cp->flags & IP_VS_CONN_F_SYNPROXY) &&
+		    (0 == ip_vs_synproxy_filter_ack(skb, cp, pp, &iph, &v))) {
+			ip_vs_conn_put(cp);
+			return v;
+		}
+
+
+		/*
+		 * "Reuse" syn-proxy sessions.
+		 * "Reuse" means update syn_proxy_seq struct and clean ack_skb etc.
+		 */
+		if ((cp->flags & IP_VS_CONN_F_SYNPROXY) &&
+		    (0 != sysctl_ip_vs_synproxy_conn_reuse)) {
+			int v = NF_DROP;
+
+			if (0 == ip_vs_synproxy_reuse_conn(af, skb, cp, pp, &iph, &v)) {
+				ip_vs_conn_put(cp);
+				return v;
+			}
+		}
+
+		ip_vs_set_state(cp, IP_VS_DIR_OUTPUT, skb, pp);
+		
+		if (cp->packet_xmit){
+			EnterFunction(11);		
+			ret = cp->packet_xmit(skb, cp, pp);
+		/* do not touch skb anymore */
+		} else {
+			IP_VS_DBG_RL("warning: packet_xmit is null");
+			ret = NF_ACCEPT;
+		}
+
+		pkts = atomic_add_return(1, &cp->in_pkts);
+		
+		if (af == AF_INET &&
+		    (ip_vs_sync_state & IP_VS_STATE_MASTER) &&
+		    (((cp->protocol != IPPROTO_TCP ||
+		       cp->state == IP_VS_TCP_S_ESTABLISHED) &&
+		      (pkts % sysctl_ip_vs_sync_threshold[1]
+		       == sysctl_ip_vs_sync_threshold[0])) ||
+		     ((cp->protocol == IPPROTO_TCP) && (cp->old_state != cp->state) &&
+		      ((cp->state == IP_VS_TCP_S_FIN_WAIT) ||
+		       (cp->state == IP_VS_TCP_S_CLOSE_WAIT) ||
+		       (cp->state == IP_VS_TCP_S_TIME_WAIT))))){
+			ip_vs_sync_conn(cp);
+
+		}
+		cp->old_state = cp->state;
+
+		ip_vs_conn_put(cp);
+		skb->ipvs_property = 1;
+		
+		return ret;
+	}else {
+EnterFunction(11);
+
+		if (unlikely(!cp)) {
+			if (sysctl_ip_vs_nat_icmp_send &&
+			    (pp->protocol == IPPROTO_TCP ||
+			     pp->protocol == IPPROTO_UDP)) {
+				__be16 _ports[2], *pptr;
+
+				pptr = skb_header_pointer(skb, iph.len,
+							  sizeof(_ports), _ports);
+				if (pptr == NULL)
+					return NF_ACCEPT;	/* Not for me */
+				if (ip_vs_lookup_real_service(af, iph.protocol,
+							      &iph.saddr, pptr[0])) {
+					/*
+					 * Notify the real server: there is no
+					 * existing entry if it is not RST
+					 * packet or not TCP packet.
+					 */
+					if (iph.protocol != IPPROTO_TCP
+					    || !is_tcp_reset(skb, iph.len)) {
 #ifdef CONFIG_IP_VS_IPV6
 					if (af == AF_INET6)
 						icmpv6_send(skb,
@@ -1063,18 +1111,22 @@ ip_vs_out(unsigned int hooknum, struct sk_buff *skb,
 							  ICMP_DEST_UNREACH,
 							  ICMP_PORT_UNREACH, 0);
 					return NF_DROP;
+                    }
 				}
 			}
+			IP_VS_DBG_PKT(12, pp, skb, 0,
+				      "packet continues traversal as normal");
+
+
+			return NF_ACCEPT;
 		}
-		IP_VS_DBG_PKT(12, pp, skb, 0,
-			      "packet continues traversal as normal");
-		return NF_ACCEPT;
-	}
 
-	return handle_response(af, skb, pp, cp, iph.len);
+	return handle_response(af, skb, pp, cp, iph.len);
+	}
 }
 
 
+
 /*
  *	Handle ICMP messages in the outside-to-inside direction (incoming).
  *	Find any that might be relevant, check against existing connections,
@@ -1092,6 +1144,7 @@ ip_vs_in_icmp(struct sk_buff *skb, int *related, unsigned int hooknum)
 	struct ip_vs_protocol *pp;
 	unsigned int offset, ihl, verdict;
 	union nf_inet_addr snet;
+	int res_dir;
 
 	*related = 1;
 
@@ -1147,19 +1200,18 @@ ip_vs_in_icmp(struct sk_buff *skb, int *related, unsigned int hooknum)
 
 	ip_vs_fill_iphdr(AF_INET, cih, &ciph);
 	/* The embedded headers contain source and dest in reverse order */
-	cp = pp->conn_in_get(AF_INET, skb, pp, &ciph, offset, 1);
+	cp = pp->conn_in_get(AF_INET, skb, pp, &ciph, offset, 1, &res_dir);
 	if (!cp) {
-		/* The packet could also belong to a local client */
-		cp = pp->conn_out_get(AF_INET, skb, pp, &ciph, offset, 1);
-		if (cp) {
-			snet.ip = iph->saddr;
-			return handle_response_icmp(AF_INET, skb, &snet,
-						    cih->protocol, cp, pp,
-						    offset, ihl);
-		}
 		return NF_ACCEPT;
 	}
 
+	if (res_dir == IP_VS_CIDX_F_IN2OUT) {
+		/* The packet belong to a local client / fullnat */
+		snet.ip = iph->saddr;
+		return handle_response_icmp(AF_INET, skb, &snet,
+					    cih->protocol, cp, pp, offset, ihl);
+	}
+
 	verdict = NF_DROP;
 
 	/* Ensure the checksum is correct */
@@ -1196,6 +1248,7 @@ ip_vs_in_icmp_v6(struct sk_buff *skb, int *related, unsigned int hooknum)
 	struct ip_vs_protocol *pp;
 	unsigned int offset, verdict;
 	union nf_inet_addr snet;
+	int res_dir;
 
 	*related = 1;
 
@@ -1252,20 +1305,19 @@ ip_vs_in_icmp_v6(struct sk_buff *skb, int *related, unsigned int hooknum)
 
 	ip_vs_fill_iphdr(AF_INET6, cih, &ciph);
 	/* The embedded headers contain source and dest in reverse order */
-	cp = pp->conn_in_get(AF_INET6, skb, pp, &ciph, offset, 1);
+	cp = pp->conn_in_get(AF_INET6, skb, pp, &ciph, offset, 1, &res_dir);
 	if (!cp) {
-		/* The packet could also belong to a local client */
-		cp = pp->conn_out_get(AF_INET6, skb, pp, &ciph, offset, 1);
-		if (cp) {
-			ipv6_addr_copy(&snet.in6, &iph->saddr);
-			return handle_response_icmp(AF_INET6, skb, &snet,
-						    cih->nexthdr,
-						    cp, pp, offset,
-						    sizeof(struct ipv6hdr));
-		}
 		return NF_ACCEPT;
 	}
 
+	if (res_dir == IP_VS_CIDX_F_IN2OUT) {
+		ipv6_addr_copy(&snet.in6, &iph->saddr);
+		return handle_response_icmp(AF_INET6, skb, &snet,
+					    cih->nexthdr,
+					    cp, pp, offset,
+					    sizeof(struct ipv6hdr));
+	}
+
 	verdict = NF_DROP;
 
 	/* do the statistics and put it back */
@@ -1296,6 +1348,10 @@ ip_vs_in(unsigned int hooknum, struct sk_buff *skb,
 	struct ip_vs_protocol *pp;
 	struct ip_vs_conn *cp;
 	int ret, restart, af, pkts;
+	int v = NF_DROP;
+	int res_dir;
+
+	EnterFunction(19);
 
 	af = (skb->protocol == htons(ETH_P_IP)) ? AF_INET : AF_INET6;
 
@@ -1312,7 +1368,6 @@ ip_vs_in(unsigned int hooknum, struct sk_buff *skb,
 			      IP_VS_DBG_ADDR(af, &iph.daddr));
 		return NF_ACCEPT;
 	}
-
 #ifdef CONFIG_IP_VS_IPV6
 	if (af == AF_INET6) {
 		if (unlikely(iph.protocol == IPPROTO_ICMPV6)) {
@@ -1340,15 +1395,16 @@ ip_vs_in(unsigned int hooknum, struct sk_buff *skb,
 	/*
 	 * Check if the packet belongs to an existing connection entry
 	 */
-	cp = pp->conn_in_get(af, skb, pp, &iph, iph.len, 0);
-
-	if (unlikely(!cp)) {
-		int v;
+	cp = pp->conn_in_get(af, skb, pp, &iph, iph.len, 0, &res_dir);
 
-		/* For local client packets, it could be a response */
-		cp = pp->conn_out_get(af, skb, pp, &iph, iph.len, 0);
-		if (cp)
+	if (likely(cp)) {
+		/* For full-nat/local-client packets, it could be a response */
+		if (res_dir == IP_VS_CIDX_F_IN2OUT) {
 			return handle_response(af, skb, pp, cp, iph.len);
+		}
+	} else {
+		/* create a new connection */
+		int v;
 
 		if (!pp->conn_schedule(af, skb, pp, &v, &cp))
 			return v;
@@ -1378,6 +1434,34 @@ ip_vs_in(unsigned int hooknum, struct sk_buff *skb,
 	}
 
 	ip_vs_in_stats(cp, skb);
+
+	/*
+	 * Filter out-in ack packet when cp is at SYN_SENT state.
+	 * DROP it if not a valid packet, STORE it if we have 
+	 * space left. 
+	 */
+	if ((cp->flags & IP_VS_CONN_F_SYNPROXY) &&
+	    (0 == ip_vs_synproxy_filter_ack(skb, cp, pp, &iph, &v))) {
+		ip_vs_conn_put(cp);
+		return v;
+	}
+
+	/*
+	 * "Reuse" syn-proxy sessions.
+	 * "Reuse" means update syn_proxy_seq struct and clean ack_skb etc.
+	 */
+	if ((cp->flags & IP_VS_CONN_F_SYNPROXY) &&
+	    (0 != sysctl_ip_vs_synproxy_conn_reuse)) {
+		int v = NF_DROP;
+
+		if (0 == ip_vs_synproxy_reuse_conn(af, skb, cp, pp, &iph, &v)) {
+			ip_vs_conn_put(cp);
+			return v;
+		}
+	}
+
+	
+
 	restart = ip_vs_set_state(cp, IP_VS_DIR_INPUT, skb, pp);
 	if (cp->packet_xmit)
 		ret = cp->packet_xmit(skb, cp, pp);
@@ -1465,6 +1549,50 @@ ip_vs_forward_icmp_v6(unsigned int hooknum, struct sk_buff *skb,
 }
 #endif
 
+#define IPPROTO_OSPF 89
+static unsigned int
+ip_vs_pre_routing(unsigned int hooknum, struct sk_buff *skb,
+		  const struct net_device *in, const struct net_device *out,
+		  int (*okfn) (struct sk_buff *))
+{
+	struct ip_vs_iphdr iph;
+	int af;
+	struct ip_vs_service *svc;
+
+	//EnterFunction(11);
+
+	
+	af = (skb->protocol == htons(ETH_P_IP)) ? AF_INET : AF_INET6;
+
+	ip_vs_fill_iphdr(af, skb_network_header(skb), &iph);
+
+	/* drop all ip fragment except ospf */
+	if ((sysctl_ip_vs_frag_drop_entry == 1)
+	    && (ip_hdr(skb)->frag_off & htons(IP_MF | IP_OFFSET))
+	    && (iph.protocol != IPPROTO_OSPF)) {
+		IP_VS_INC_ESTATS(ip_vs_esmib, DEFENCE_IP_FRAG_DROP);
+		return NF_DROP;
+	}
+
+	/* drop udp packet which send to tcp-vip */
+	if ((sysctl_ip_vs_udp_drop_entry == 1) && (iph.protocol == IPPROTO_UDP)) {
+		if ((svc =
+		     ip_vs_lookup_vip(af, IPPROTO_TCP, &iph.daddr)) != NULL) {
+			IP_VS_INC_ESTATS(ip_vs_esmib, DEFENCE_UDP_DROP);
+			return NF_DROP;
+		}
+	}
+
+	/* synproxy: defence synflood */
+	if (iph.protocol == IPPROTO_TCP) {
+		int v = NF_ACCEPT;
+		if (0 == ip_vs_synproxy_syn_rcv(af, skb, &iph, &v)) {
+			return v;
+		}
+	}
+
+	return NF_ACCEPT;
+}
 
 static struct nf_hook_ops ip_vs_ops[] __read_mostly = {
 	/* After packet filtering, forward packet through VS/DR, VS/TUN,
@@ -1502,6 +1630,14 @@ static struct nf_hook_ops ip_vs_ops[] __read_mostly = {
 		.hooknum        = NF_INET_POST_ROUTING,
 		.priority       = NF_IP_PRI_NAT_SRC-1,
 	},
+	/* Before the netfilter connection tracking, only deal with FULLNAT/NAT-SynProxy */
+	{
+	 	.hook 		= ip_vs_pre_routing,
+	 	.owner 		= THIS_MODULE,
+	 	.pf 		= PF_INET,
+	 	.hooknum 	= NF_INET_PRE_ROUTING,
+	 	.priority 	= NF_IP_PRI_CONNTRACK - 1,
+	 },
 #ifdef CONFIG_IP_VS_IPV6
 	/* After packet filtering, forward packet through VS/DR, VS/TUN,
 	 * or VS/NAT(change destination), so that filtering rules can be
@@ -1538,6 +1674,14 @@ static struct nf_hook_ops ip_vs_ops[] __read_mostly = {
 		.hooknum        = NF_INET_POST_ROUTING,
 		.priority       = NF_IP6_PRI_NAT_SRC-1,
 	},
+	/* Before the netfilter connection tracking, only deal with FULLNAT/NAT-SynProxy */
+	{
+	 	.hook 		= ip_vs_pre_routing,
+	 	.owner 		= THIS_MODULE,
+	 	.pf 		= PF_INET6,
+	 	.hooknum 	= NF_INET_PRE_ROUTING,
+	 	.priority 	= NF_IP6_PRI_CONNTRACK - 1,
+	 },
 #endif
 };
 
diff --git a/net/netfilter/ipvs/ip_vs_ctl.c b/net/netfilter/ipvs/ip_vs_ctl.c
old mode 100644
new mode 100755
index dd472c9..b96f16b
--- a/net/netfilter/ipvs/ip_vs_ctl.c
+++ b/net/netfilter/ipvs/ip_vs_ctl.c
@@ -15,7 +15,10 @@
  *              2 of the License, or (at your option) any later version.
  *
  * Changes:
+ *	Shunmin Zhu  <jianghe.zsm@taobao.com>
+ *	Jiaming Wu   <pukong.wjm@taobao.com>	support FULLNAT+SYNPROXY
  *
+ *   	Yu Bo        <yubo@xiaomi.com>
  */
 
 #define KMSG_COMPONENT "IPVS"
@@ -49,6 +52,7 @@
 #include <asm/uaccess.h>
 
 #include <net/ip_vs.h>
+#include <net/ip_vs_synproxy.h>
 
 /* semaphore for IPVS sockopts. And, [gs]etsockopt may sleep. */
 static DEFINE_MUTEX(__ip_vs_mutex);
@@ -56,6 +60,9 @@ static DEFINE_MUTEX(__ip_vs_mutex);
 /* lock for service table */
 static DEFINE_RWLOCK(__ip_vs_svc_lock);
 
+/* lock for zone table */
+static DEFINE_RWLOCK(__ip_vs_zone_lock);
+
 /* lock for table with the real services */
 static DEFINE_RWLOCK(__ip_vs_rs_lock);
 
@@ -76,6 +83,9 @@ static atomic_t ip_vs_dropentry = ATOMIC_INIT(0);
 /* number of virtual services */
 static int ip_vs_num_services = 0;
 
+/* number of zones */
+static int ip_vs_num_zones = 0;
+
 /* sysctl variables */
 static int sysctl_ip_vs_drop_entry = 0;
 static int sysctl_ip_vs_drop_packet = 0;
@@ -87,6 +97,67 @@ int sysctl_ip_vs_expire_nodest_conn = 0;
 int sysctl_ip_vs_expire_quiescent_template = 0;
 int sysctl_ip_vs_sync_threshold[2] = { 3, 50 };
 int sysctl_ip_vs_nat_icmp_send = 0;
+/*
+ * sysctl for FULLNAT
+ */
+int sysctl_ip_vs_timestamp_remove_entry = 1;
+int sysctl_ip_vs_mss_adjust_entry = 1;
+int sysctl_ip_vs_conn_reused_entry = 1;
+int sysctl_ip_vs_toa_entry = 1;
+static int ip_vs_entry_min = 0;
+static int ip_vs_entry_max = 1;
+extern int sysctl_ip_vs_tcp_timeouts[IP_VS_TCP_S_LAST + 1];
+/*
+ * sysctl for SYNPROXY
+ */
+/* syn-proxy sysctl variables */
+int sysctl_ip_vs_synproxy_init_mss = IP_VS_SYNPROXY_INIT_MSS_DEFAULT;
+int sysctl_ip_vs_synproxy_sack = IP_VS_SYNPROXY_SACK_DEFAULT;
+int sysctl_ip_vs_synproxy_wscale = IP_VS_SYNPROXY_WSCALE_DEFAULT;
+int sysctl_ip_vs_synproxy_timestamp = IP_VS_SYNPROXY_TIMESTAMP_DEFAULT;
+int sysctl_ip_vs_synproxy_synack_ttl = IP_VS_SYNPROXY_TTL_DEFAULT;
+int sysctl_ip_vs_synproxy_defer = IP_VS_SYNPROXY_DEFER_DEFAULT;
+int sysctl_ip_vs_synproxy_conn_reuse = IP_VS_SYNPROXY_CONN_REUSE_DEFAULT;
+int sysctl_ip_vs_synproxy_conn_reuse_cl = IP_VS_SYNPROXY_CONN_REUSE_CL_DEFAULT;
+int sysctl_ip_vs_synproxy_conn_reuse_tw = IP_VS_SYNPROXY_CONN_REUSE_TW_DEFAULT;
+int sysctl_ip_vs_synproxy_conn_reuse_fw = IP_VS_SYNPROXY_CONN_REUSE_FW_DEFAULT;
+int sysctl_ip_vs_synproxy_conn_reuse_cw = IP_VS_SYNPROXY_CONN_REUSE_CW_DEFAULT;
+int sysctl_ip_vs_synproxy_conn_reuse_la = IP_VS_SYNPROXY_CONN_REUSE_LA_DEFAULT;
+int sysctl_ip_vs_synproxy_dup_ack_thresh = IP_VS_SYNPROXY_DUP_ACK_DEFAULT;
+int sysctl_ip_vs_synproxy_skb_store_thresh = IP_VS_SYNPROXY_SKB_STORE_DEFAULT;
+int sysctl_ip_vs_synproxy_syn_retry = IP_VS_SYNPROXY_SYN_RETRY_DEFAULT;
+
+static int ip_vs_synproxy_switch_min = 0;
+static int ip_vs_synproxy_switch_max = 1;
+static int ip_vs_synproxy_wscale_min = 0;
+static int ip_vs_synproxy_wscale_max = IP_VS_SYNPROXY_WSCALE_MAX;
+static int ip_vs_synproxy_init_mss_min = 0;
+static int ip_vs_synproxy_init_mss_max = 65535;
+static int ip_vs_synproxy_synack_ttl_min = IP_VS_SYNPROXY_TTL_MIN;
+static int ip_vs_synproxy_synack_ttl_max = IP_VS_SYNPROXY_TTL_MAX;
+static int ip_vs_synproxy_dup_ack_cnt_min = 0;
+static int ip_vs_synproxy_dup_ack_cnt_max = 65535;
+static int ip_vs_synproxy_syn_retry_min = 0;
+static int ip_vs_synproxy_syn_retry_max = 6;
+static int ip_vs_synproxy_skb_store_thresh_min = 0;
+static int ip_vs_synproxy_skb_store_thresh_max = 5;
+/* local address port range */
+int sysctl_ip_vs_lport_max = 65535;
+int sysctl_ip_vs_lport_min = 5000;
+int sysctl_ip_vs_lport_tries = 10000;
+static int ip_vs_port_min = 1025;
+static int ip_vs_port_max = 65535;
+static int ip_vs_port_try_min = 10;
+static int ip_vs_port_try_max = 60000;
+/*
+ * sysctl for DEFENCE ATTACK
+ */
+int sysctl_ip_vs_frag_drop_entry = 1;
+int sysctl_ip_vs_tcp_drop_entry = 1;
+int sysctl_ip_vs_udp_drop_entry = 1;
+/* send rst when tcp session expire */
+int sysctl_ip_vs_conn_expire_tcp_rst = 1;
+
 
 
 #ifdef CONFIG_IP_VS_DEBUG
@@ -284,6 +355,7 @@ static struct list_head ip_vs_svc_table[IP_VS_SVC_TAB_SIZE];
 /* the service table hashed by fwmark */
 static struct list_head ip_vs_svc_fwm_table[IP_VS_SVC_TAB_SIZE];
 
+static struct list_head ip_vs_zone;
 /*
  *	Hash table: for real service lookups
  */
@@ -309,10 +381,8 @@ static atomic_t ip_vs_nullsvc_counter = ATOMIC_INIT(0);
  *	Returns hash value for virtual service
  */
 static __inline__ unsigned
-ip_vs_svc_hashkey(int af, unsigned proto, const union nf_inet_addr *addr,
-		  __be16 port)
+ip_vs_svc_hashkey(int af, unsigned proto, const union nf_inet_addr *addr)
 {
-	register unsigned porth = ntohs(port);
 	__be32 addr_fold = addr->ip;
 
 #ifdef CONFIG_IP_VS_IPV6
@@ -321,10 +391,15 @@ ip_vs_svc_hashkey(int af, unsigned proto, const union nf_inet_addr *addr,
 			    addr->ip6[2]^addr->ip6[3];
 #endif
 
-	return (proto^ntohl(addr_fold)^(porth>>IP_VS_SVC_TAB_BITS)^porth)
-		& IP_VS_SVC_TAB_MASK;
+	if(af & IP_VS_CONN_F_DSNAT){
+		addr_fold = 0;
+	} 
+
+	return (proto ^ ntohl(addr_fold)) & IP_VS_SVC_TAB_MASK;
 }
 
+
+
 /*
  *	Returns hash value of fwmark for virtual service lookup
  */
@@ -352,8 +427,7 @@ static int ip_vs_svc_hash(struct ip_vs_service *svc)
 		/*
 		 *  Hash it by <protocol,addr,port> in ip_vs_svc_table
 		 */
-		hash = ip_vs_svc_hashkey(svc->af, svc->protocol, &svc->addr,
-					 svc->port);
+		hash = ip_vs_svc_hashkey(svc->af, svc->protocol, &svc->addr);
 		list_add(&svc->s_list, &ip_vs_svc_table[hash]);
 	} else {
 		/*
@@ -397,6 +471,44 @@ static int ip_vs_svc_unhash(struct ip_vs_service *svc)
 
 
 /*
+ *	Get zone by {addr,netmask} in the ip_vs_zone list.
+ */
+static inline struct ip_vs_zone *
+__ip_vs_zone_get(const union nf_inet_addr *addr,
+		    __be32 netmask)
+{
+	struct ip_vs_zone *zone;
+	
+	list_for_each_entry(zone, &ip_vs_zone, s_list) {
+		if ((zone->addr.ip == addr->ip)
+			&& (zone->netmask == netmask)) {
+			atomic_inc(&zone->usecnt);
+			return zone;
+		}
+	}
+	return NULL;
+}
+
+/*
+ *	Get zone by {addr} in the ip_vs_zone list.
+ */
+struct ip_vs_zone *
+ip_vs_zone_get(const union nf_inet_addr *addr)
+{
+	struct ip_vs_zone *zone;
+	
+	list_for_each_entry(zone, &ip_vs_zone, s_list) {
+		if (((zone->addr.ip ^ addr->ip) & zone->netmask) == 0)
+		{
+			return zone;
+		}
+	}
+	return NULL;
+}
+
+
+
+/*
  *	Get service by {proto,addr,port} in the service table.
  */
 static inline struct ip_vs_service *
@@ -405,18 +517,34 @@ __ip_vs_service_get(int af, __u16 protocol, const union nf_inet_addr *vaddr,
 {
 	unsigned hash;
 	struct ip_vs_service *svc;
+	int dsnat = af & IP_VS_CONN_F_DSNAT;
+	af &= ~IP_VS_CONN_F_DSNAT;
 
-	/* Check for "full" addressed entries */
-	hash = ip_vs_svc_hashkey(af, protocol, vaddr, vport);
 
-	list_for_each_entry(svc, &ip_vs_svc_table[hash], s_list){
-		if ((svc->af == af)
-		    && ip_vs_addr_equal(af, &svc->addr, vaddr)
-		    && (svc->port == vport)
-		    && (svc->protocol == protocol)) {
-			/* HIT */
-			atomic_inc(&svc->usecnt);
-			return svc;
+	/* Check for "full" addressed entries */
+	hash = ip_vs_svc_hashkey(af|dsnat, protocol, vaddr);
+
+	if(dsnat){
+		list_for_each_entry(svc, &ip_vs_svc_table[hash], s_list) {
+			if ((svc->af == af)
+				&& (svc->addr.ip == 0)
+				&& (svc->port == 0)
+				&& (svc->protocol == protocol)) {
+				/* HIT */
+				atomic_inc(&svc->usecnt);
+				return svc;
+			}
+		}
+	}else{
+		list_for_each_entry(svc, &ip_vs_svc_table[hash], s_list) {
+			if ((svc->af == af)
+			    && ip_vs_addr_equal(af, &svc->addr, vaddr)
+			    && (svc->port == vport)
+			    && (svc->protocol == protocol)) {
+				/* HIT */
+				atomic_inc(&svc->usecnt);
+				return svc;
+			}
 		}
 	}
 
@@ -432,6 +560,7 @@ __ip_vs_svc_fwm_get(int af, __u32 fwmark)
 {
 	unsigned hash;
 	struct ip_vs_service *svc;
+	af &= ~IP_VS_CONN_F_DSNAT;
 
 	/* Check for fwmark addressed entries */
 	hash = ip_vs_svc_fwm_hashkey(fwmark);
@@ -447,6 +576,15 @@ __ip_vs_svc_fwm_get(int af, __u32 fwmark)
 	return NULL;
 }
 
+/*
+struct ip_vs_dsnat *ip_vs_zone_get(void)
+{
+	return &ip_vs_zone;
+}
+*/
+
+
+
 struct ip_vs_service *
 ip_vs_service_get(int af, __u32 fwmark, __u16 protocol,
 		  const union nf_inet_addr *vaddr, __be16 vport)
@@ -486,10 +624,10 @@ ip_vs_service_get(int af, __u32 fwmark, __u16 protocol,
 		svc = __ip_vs_service_get(af, protocol, vaddr, 0);
 	}
 
-  out:
+      out:
 	read_unlock(&__ip_vs_svc_lock);
 
-	IP_VS_DBG_BUF(9, "lookup service: fwm %u %s %s:%u %s\n",
+	IP_VS_DBG_BUF(19, "lookup service: fwm %u %s %s:%u %s\n",
 		      fwmark, ip_vs_proto_name(protocol),
 		      IP_VS_DBG_ADDR(af, vaddr), ntohs(vport),
 		      svc ? "hit" : "not hit");
@@ -497,6 +635,43 @@ ip_vs_service_get(int af, __u32 fwmark, __u16 protocol,
 	return svc;
 }
 
+struct ip_vs_service *ip_vs_lookup_vip(int af, __u16 protocol,
+				       const union nf_inet_addr *vaddr)
+{
+	struct ip_vs_service *svc;
+	unsigned hash;
+	int dsnat = af & IP_VS_CONN_F_DSNAT;
+	af &= ~IP_VS_CONN_F_DSNAT; 
+
+	read_lock(&__ip_vs_svc_lock);
+
+	hash = ip_vs_svc_hashkey(af|dsnat, protocol, vaddr);
+	if(dsnat){
+		list_for_each_entry(svc, &ip_vs_svc_table[hash], s_list) {
+			if ((svc->af == af)
+				&& (svc->addr.ip == 0)
+				&& (svc->port == 0) 
+				&& (svc->protocol == protocol)) {  
+				/* HIT */    
+				read_unlock(&__ip_vs_svc_lock);
+				return svc;
+			}
+		}
+	}else{
+		list_for_each_entry(svc, &ip_vs_svc_table[hash], s_list) {
+			if ((svc->af == af)
+			    && ip_vs_addr_equal(af, &svc->addr, vaddr)
+			    && (svc->protocol == protocol)) {
+				/* HIT */
+				read_unlock(&__ip_vs_svc_lock);
+				return svc;
+			}
+		}
+	}
+
+	read_unlock(&__ip_vs_svc_lock);
+	return NULL;
+}
 
 static inline void
 __ip_vs_bind_svc(struct ip_vs_dest *dest, struct ip_vs_service *svc)
@@ -515,7 +690,6 @@ __ip_vs_unbind_svc(struct ip_vs_dest *dest)
 		kfree(svc);
 }
 
-
 /*
  *	Returns hash value for real service
  */
@@ -1146,6 +1320,260 @@ ip_vs_del_dest(struct ip_vs_service *svc, struct ip_vs_dest_user_kern *udest)
 	return 0;
 }
 
+void ip_vs_laddr_hold(struct ip_vs_laddr *laddr)
+{
+	atomic_inc(&laddr->refcnt);
+}
+
+void ip_vs_laddr_put(struct ip_vs_laddr *laddr)
+{
+	if (atomic_dec_and_test(&laddr->refcnt)) {
+		kfree(laddr);
+	}
+}
+
+static int
+ip_vs_new_laddr(struct ip_vs_zone *zone, struct ip_vs_laddr_user_kern *uladdr,
+		struct ip_vs_laddr **laddr_p)
+{
+	struct ip_vs_laddr *laddr;
+
+	laddr = kzalloc(sizeof(struct ip_vs_laddr), GFP_ATOMIC);
+	if (!laddr) {
+		pr_err("%s(): no memory.\n", __func__);
+		return -ENOMEM;
+	}
+
+	ip_vs_addr_copy(AF_INET, &laddr->addr, &uladdr->addr);
+	atomic64_set(&laddr->port_conflict, 0);
+	atomic64_set(&laddr->port, 0);
+	atomic_set(&laddr->refcnt, 0);
+	atomic_set(&laddr->conn_counts, 0);
+
+	*laddr_p = laddr;
+
+	return 0;
+}
+
+static struct ip_vs_laddr *ip_vs_lookup_laddr(struct ip_vs_zone *zone,
+					      const union nf_inet_addr *addr)
+{
+	struct ip_vs_laddr *laddr;
+
+	/*
+	 * Find the local address for the given service
+	 */
+	list_for_each_entry(laddr, &zone->laddr_list, n_list) {
+		if (ip_vs_addr_equal(AF_INET, &laddr->addr, addr)) {
+			/* HIT */
+			return laddr;
+		}
+	}
+
+	return NULL;
+}
+
+static int
+ip_vs_add_laddr(struct ip_vs_zone *zone, struct ip_vs_laddr_user_kern *uladdr)
+{
+	struct ip_vs_laddr *laddr;
+	int ret;
+#ifdef CONFIG_IP_VS_DEBUG
+	union nf_inet_addr netmask = {.ip = zone->netmask};
+#endif	
+
+	IP_VS_DBG_BUF(0, "zone %s/%s add local address %s\n",
+		      IP_VS_DBG_ADDR(AF_INET, &zone->addr), IP_VS_DBG_ADDR(AF_INET, &netmask),
+		      IP_VS_DBG_ADDR(AF_INET, &uladdr->addr));
+
+	/*
+	 * Check if the local address already exists in the list
+	 */
+	laddr = ip_vs_lookup_laddr(zone, &uladdr->addr);
+	if (laddr) {
+		IP_VS_DBG(1, "%s(): local address already exists\n", __func__);
+		return -EEXIST;
+	}
+
+	/*
+	 * Allocate and initialize the dest structure
+	 */
+	ret = ip_vs_new_laddr(zone, uladdr, &laddr);
+	if (ret) {
+		return ret;
+	}
+
+	/*
+	 * Add the local adress entry into the list
+	 */
+	ip_vs_laddr_hold(laddr);
+
+	write_lock_bh(&__ip_vs_zone_lock);
+
+	/*
+	 * Wait until all other svc users go away.
+	 */
+	IP_VS_WAIT_WHILE(atomic_read(&zone->usecnt) > 1);
+
+	list_add_tail(&laddr->n_list, &zone->laddr_list);
+	zone->num_laddrs++;
+
+#ifdef CONFIG_IP_VS_DEBUG
+	/* Dump the destinations */
+	IP_VS_DBG_BUF(0, "		zone %s/%s num %d curr %p \n",
+		      IP_VS_DBG_ADDR(AF_INET, &zone->addr),
+		      IP_VS_DBG_ADDR(AF_INET, &netmask),
+		      zone->num_laddrs, zone->curr_laddr);
+	list_for_each_entry(laddr, &zone->laddr_list, n_list) {
+		IP_VS_DBG_BUF(0, "		laddr %p %s:%d \n",
+			      laddr, IP_VS_DBG_ADDR(AF_INET, &laddr->addr), 0);
+	}
+#endif
+
+	write_unlock_bh(&__ip_vs_zone_lock);
+
+	return 0;
+}
+
+static int
+ip_vs_del_laddr(struct ip_vs_zone *zone, struct ip_vs_laddr_user_kern *uladdr)
+{
+	struct ip_vs_laddr *laddr;
+#ifdef CONFIG_IP_VS_DEBUG	
+	union nf_inet_addr netmask = {.ip = zone->netmask};
+#endif
+
+	IP_VS_DBG_BUF(0, "zone %s/%s del local address %s\n",
+		      IP_VS_DBG_ADDR(AF_INET, &zone->addr),
+		      IP_VS_DBG_ADDR(AF_INET, &netmask),
+		      IP_VS_DBG_ADDR(AF_INET, &uladdr->addr));
+
+	laddr = ip_vs_lookup_laddr(zone, &uladdr->addr);
+
+	if (laddr == NULL) {
+		IP_VS_DBG(1, "%s(): local address not found!\n", __func__);
+		return -ENOENT;
+	}
+
+	write_lock_bh(&__ip_vs_zone_lock);
+
+	/*
+	 *      Wait until all other svc users go away.
+	 */
+	IP_VS_WAIT_WHILE(atomic_read(&zone->usecnt) > 1);
+
+	/* update svc->curr_laddr */
+	if (zone->curr_laddr == &laddr->n_list)
+		zone->curr_laddr = laddr->n_list.next;
+	/*
+	 *      Unlink dest from the service
+	 */
+	list_del(&laddr->n_list);
+	zone->num_laddrs--;
+
+#ifdef CONFIG_IP_VS_DEBUG
+	IP_VS_DBG_BUF(0, "	zone %s/%s num %d curr %p \n",
+		      IP_VS_DBG_ADDR(AF_INET, &zone->addr),
+		      IP_VS_DBG_ADDR(AF_INET, &netmask),
+		      zone->num_laddrs, zone->curr_laddr);
+	list_for_each_entry(laddr, &zone->laddr_list, n_list) {
+		IP_VS_DBG_BUF(0, "		laddr %p %s:%d \n",
+			      laddr, IP_VS_DBG_ADDR(AF_INET, &laddr->addr), 0);
+	}
+#endif
+
+	ip_vs_laddr_put(laddr);
+
+	write_unlock_bh(&__ip_vs_zone_lock);
+
+	return 0;
+}
+
+
+static int
+ip_vs_add_zone(struct ip_vs_zone_user_kern *u,
+		struct ip_vs_zone **zone_p)
+{
+	int ret = 0;
+	struct ip_vs_zone *zone = NULL;
+
+	/* increase the module use count */
+	ip_vs_use_count_inc();
+
+	/* Lookup the scheduler by 'u->sched_name' */
+
+	zone = kzalloc(sizeof(struct ip_vs_zone), GFP_ATOMIC);
+	if (zone == NULL) {
+		IP_VS_DBG(1, "%s(): no memory\n", __func__);
+		ret = -ENOMEM;
+		goto out_err;
+	}
+
+	/* I'm the first user of the service */
+	atomic_set(&zone->usecnt, 1);
+	atomic_set(&zone->refcnt, 0);
+
+
+	zone->addr.ip = u->addr.ip;
+	zone->netmask = u->netmask;
+
+	/* Init the local address stuff */
+	rwlock_init(&zone->laddr_lock);
+	INIT_LIST_HEAD(&zone->laddr_list);
+	zone->num_laddrs = 0;
+	zone->curr_laddr = &zone->laddr_list;
+
+
+	ip_vs_num_zones++;
+	write_lock_bh(&__ip_vs_zone_lock);
+	list_add_tail(&zone->s_list, &ip_vs_zone);
+	atomic_inc(&zone->refcnt);
+	write_unlock_bh(&__ip_vs_zone_lock);
+	
+	*zone_p = zone;
+
+	return 0;
+
+  out_err:
+	if (zone != NULL) {
+		kfree(zone);
+	}
+
+	/* decrease the module use count */
+	ip_vs_use_count_dec();
+
+	return ret;
+}
+
+
+
+/*
+ *	Delete a zone from the zone list
+ */
+static int ip_vs_del_zone(struct ip_vs_zone *zone)
+{
+	struct ip_vs_laddr *laddr, *laddr_next;
+
+	if (zone == NULL)
+		return -ENOENT;
+
+	write_lock_bh(&__ip_vs_zone_lock);
+	list_del(&zone->s_list);
+
+	ip_vs_num_zones--;
+
+	/* Unlink the whole local address list */
+	list_for_each_entry_safe(laddr, laddr_next, &zone->laddr_list, n_list) {
+		list_del(&laddr->n_list);
+		ip_vs_laddr_put(laddr);
+	}
+
+	write_unlock_bh(&__ip_vs_zone_lock);
+
+	return 0;
+}
+
+
 
 /*
  *	Add a service into the service hash table
@@ -1196,6 +1624,7 @@ ip_vs_add_service(struct ip_vs_service_user_kern *u,
 	svc->timeout = u->timeout * HZ;
 	svc->netmask = u->netmask;
 
+
 	INIT_LIST_HEAD(&svc->destinations);
 	rwlock_init(&svc->sched_lock);
 	spin_lock_init(&svc->stats.lock);
@@ -1358,6 +1787,7 @@ static void __ip_vs_del_service(struct ip_vs_service *svc)
 		svc->inc = NULL;
 	}
 
+
 	/*
 	 *    Unlink the whole destination list
 	 */
@@ -1390,7 +1820,7 @@ static void __ip_vs_del_service(struct ip_vs_service *svc)
 static int ip_vs_del_service(struct ip_vs_service *svc)
 {
 	if (svc == NULL)
-		return -EEXIST;
+		return -ENOENT;
 
 	/*
 	 * Unhash it from the service table
@@ -1535,7 +1965,6 @@ proc_do_sync_threshold(ctl_table *table, int write,
 	return rc;
 }
 
-
 /*
  *	IPVS sysctl table (under the /proc/sys/net/ipv4/vs/)
  */
@@ -1550,163 +1979,411 @@ static struct ctl_table vs_vars[] = {
 	},
 #ifdef CONFIG_IP_VS_DEBUG
 	{
-		.procname	= "debug_level",
-		.data		= &sysctl_ip_vs_debug_level,
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec,
-	},
+		.procname	= "debug_level",
+		.data		= &sysctl_ip_vs_debug_level,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec,
+	},
 #endif
 	{
-		.procname	= "am_droprate",
-		.data		= &sysctl_ip_vs_am_droprate,
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec,
-	},
+		.procname	= "am_droprate",
+		.data		= &sysctl_ip_vs_am_droprate,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec,
+	},
 	{
-		.procname	= "drop_entry",
-		.data		= &sysctl_ip_vs_drop_entry,
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_do_defense_mode,
-	},
+		.procname	= "drop_entry",
+		.data		= &sysctl_ip_vs_drop_entry,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_do_defense_mode,
+	},
 	{
-		.procname	= "drop_packet",
-		.data		= &sysctl_ip_vs_drop_packet,
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_do_defense_mode,
-	},
+		.procname	= "drop_packet",
+		.data		= &sysctl_ip_vs_drop_packet,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_do_defense_mode,
+	},
 	{
-		.procname	= "secure_tcp",
-		.data		= &sysctl_ip_vs_secure_tcp,
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_do_defense_mode,
-	},
-#if 0
+		.procname	= "secure_tcp",
+		.data		= &sysctl_ip_vs_secure_tcp,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_do_defense_mode,
+	},
 	{
-		.procname	= "timeout_established",
-		.data	= &vs_timeout_table_dos.timeout[IP_VS_S_ESTABLISHED],
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec_jiffies,
-	},
+		.procname	= "timeout_established",
+		.data	= &sysctl_ip_vs_tcp_timeouts[IP_VS_TCP_S_ESTABLISHED],
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec_jiffies,
+	},
 	{
-		.procname	= "timeout_synsent",
-		.data	= &vs_timeout_table_dos.timeout[IP_VS_S_SYN_SENT],
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec_jiffies,
-	},
+		.procname	= "timeout_synsent",
+		.data	= &sysctl_ip_vs_tcp_timeouts[IP_VS_TCP_S_SYN_SENT],
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec_jiffies,
+	},
 	{
-		.procname	= "timeout_synrecv",
-		.data	= &vs_timeout_table_dos.timeout[IP_VS_S_SYN_RECV],
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec_jiffies,
-	},
+		.procname	= "timeout_synrecv",
+		.data	= &sysctl_ip_vs_tcp_timeouts[IP_VS_TCP_S_SYN_RECV],
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec_jiffies,
+	},
 	{
-		.procname	= "timeout_finwait",
-		.data	= &vs_timeout_table_dos.timeout[IP_VS_S_FIN_WAIT],
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec_jiffies,
-	},
+		.procname	= "timeout_finwait",
+		.data	= &sysctl_ip_vs_tcp_timeouts[IP_VS_TCP_S_FIN_WAIT],
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec_jiffies,
+	},
 	{
-		.procname	= "timeout_timewait",
-		.data	= &vs_timeout_table_dos.timeout[IP_VS_S_TIME_WAIT],
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec_jiffies,
-	},
+		.procname	= "timeout_timewait",
+		.data	= &sysctl_ip_vs_tcp_timeouts[IP_VS_TCP_S_TIME_WAIT],
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec_jiffies,
+	},
 	{
-		.procname	= "timeout_close",
-		.data	= &vs_timeout_table_dos.timeout[IP_VS_S_CLOSE],
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec_jiffies,
-	},
+		.procname	= "timeout_close",
+		.data	= &sysctl_ip_vs_tcp_timeouts[IP_VS_TCP_S_CLOSE],
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec_jiffies,
+	},
 	{
-		.procname	= "timeout_closewait",
-		.data	= &vs_timeout_table_dos.timeout[IP_VS_S_CLOSE_WAIT],
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec_jiffies,
-	},
+		.procname	= "timeout_closewait",
+		.data	= &sysctl_ip_vs_tcp_timeouts[IP_VS_TCP_S_CLOSE_WAIT],
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec_jiffies,
+	},
 	{
-		.procname	= "timeout_lastack",
-		.data	= &vs_timeout_table_dos.timeout[IP_VS_S_LAST_ACK],
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec_jiffies,
-	},
+		.procname	= "timeout_lastack",
+		.data	= &sysctl_ip_vs_tcp_timeouts[IP_VS_TCP_S_LAST_ACK],
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec_jiffies,
+	},
 	{
-		.procname	= "timeout_listen",
-		.data	= &vs_timeout_table_dos.timeout[IP_VS_S_LISTEN],
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec_jiffies,
-	},
+		.procname	= "timeout_listen",
+		.data	= &sysctl_ip_vs_tcp_timeouts[IP_VS_TCP_S_LISTEN],
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec_jiffies,
+	},
 	{
-		.procname	= "timeout_synack",
-		.data	= &vs_timeout_table_dos.timeout[IP_VS_S_SYNACK],
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec_jiffies,
-	},
+		.procname	= "timeout_synack",
+		.data	= &sysctl_ip_vs_tcp_timeouts[IP_VS_TCP_S_SYNACK],
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec_jiffies,
+	},
 	{
-		.procname	= "timeout_udp",
-		.data	= &vs_timeout_table_dos.timeout[IP_VS_S_UDP],
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec_jiffies,
-	},
+		.procname	= "cache_bypass",
+		.data		= &sysctl_ip_vs_cache_bypass,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec,
+	},
 	{
-		.procname	= "timeout_icmp",
-		.data	= &vs_timeout_table_dos.timeout[IP_VS_S_ICMP],
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec_jiffies,
-	},
-#endif
+		.procname	= "expire_nodest_conn",
+		.data		= &sysctl_ip_vs_expire_nodest_conn,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec,
+	},
 	{
-		.procname	= "cache_bypass",
-		.data		= &sysctl_ip_vs_cache_bypass,
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec,
-	},
+		.procname	= "expire_quiescent_template",
+		.data		= &sysctl_ip_vs_expire_quiescent_template,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec,
+	},
 	{
-		.procname	= "expire_nodest_conn",
-		.data		= &sysctl_ip_vs_expire_nodest_conn,
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec,
-	},
+		.procname	= "sync_threshold",
+		.data		= &sysctl_ip_vs_sync_threshold,
+		.maxlen		= sizeof(sysctl_ip_vs_sync_threshold),
+		.mode		= 0644,
+		.proc_handler	= proc_do_sync_threshold,
+	},
+
 	{
-		.procname	= "expire_quiescent_template",
-		.data		= &sysctl_ip_vs_expire_quiescent_template,
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec,
-	},
+		.procname	= "nat_icmp_send",
+		.data		= &sysctl_ip_vs_nat_icmp_send,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= proc_dointvec,
+	},
 	{
-		.procname	= "sync_threshold",
-		.data		= &sysctl_ip_vs_sync_threshold,
-		.maxlen		= sizeof(sysctl_ip_vs_sync_threshold),
-		.mode		= 0644,
-		.proc_handler	= proc_do_sync_threshold,
-	},
+               .procname 	= "fullnat_timestamp_remove_entry",
+               .data 		= &sysctl_ip_vs_timestamp_remove_entry,
+               .maxlen 	= sizeof(int),
+               .mode 		= 0644,
+               .proc_handler 	= &proc_dointvec_minmax,
+               .strategy 	= &sysctl_intvec,
+               .extra1 	= &ip_vs_entry_min,
+               .extra2 	= &ip_vs_entry_max,
+	},
 	{
-		.procname	= "nat_icmp_send",
-		.data		= &sysctl_ip_vs_nat_icmp_send,
-		.maxlen		= sizeof(int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec,
-	},
-	{ .ctl_name = 0 }
+               .procname	 = "fullnat_mss_adjust_entry",
+               .data		 = &sysctl_ip_vs_mss_adjust_entry,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .strategy	 = &sysctl_intvec,
+               .extra1		 = &ip_vs_entry_min,
+               .extra2		 = &ip_vs_entry_max,
+	},
+	{
+               .procname	 = "fullnat_conn_reused_entry",
+               .data		 = &sysctl_ip_vs_conn_reused_entry,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .strategy	 = &sysctl_intvec,
+               .extra1		 = &ip_vs_entry_min,
+               .extra2		 = &ip_vs_entry_max,
+	},
+	{
+               .procname	 = "fullnat_toa_entry",
+               .data		 = &sysctl_ip_vs_toa_entry,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .strategy	 = &sysctl_intvec,
+               .extra1		 = &ip_vs_entry_min,
+               .extra2		 = &ip_vs_entry_max,
+	},
+	{
+               .procname	 = "fullnat_lport_max",
+               .data		 = &sysctl_ip_vs_lport_max,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .strategy	 = &sysctl_intvec,
+               .extra1		 = &ip_vs_port_min,
+               .extra2		 = &ip_vs_port_max,
+	},
+	{
+               .procname	 = "fullnat_lport_min",
+               .data		 = &sysctl_ip_vs_lport_min,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .strategy	 = &sysctl_intvec,
+               .extra1		 = &ip_vs_port_min,
+               .extra2		 = &ip_vs_port_max,
+	},
+	{
+               .procname	 = "fullnat_lport_tries",
+               .data		 = &sysctl_ip_vs_lport_tries,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .strategy	 = &sysctl_intvec,
+               .extra1		 = &ip_vs_port_try_min,
+               .extra2		 = &ip_vs_port_try_max,
+	},
+	/* syn-proxy sysctl variables */
+	{
+               .procname	 = "synproxy_init_mss",
+               .data		 = &sysctl_ip_vs_synproxy_init_mss,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .extra1		 = &ip_vs_synproxy_init_mss_min,
+               .extra2		 = &ip_vs_synproxy_init_mss_max,
+               .strategy	 = &sysctl_intvec,
+	},
+	{
+               .procname	 = "synproxy_sack",
+               .data		 = &sysctl_ip_vs_synproxy_sack,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .extra1		 = &ip_vs_synproxy_switch_min,
+               .extra2		 = &ip_vs_synproxy_switch_max,
+               .strategy	 = &sysctl_intvec,
+	},
+	{
+               .procname	 = "synproxy_wscale",
+               .data		 = &sysctl_ip_vs_synproxy_wscale,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .extra1		 = &ip_vs_synproxy_wscale_min,
+               .extra2		 = &ip_vs_synproxy_wscale_max,
+               .strategy	 = &sysctl_intvec,
+	},
+	{
+               .procname	 = "synproxy_timestamp",
+               .data		 = &sysctl_ip_vs_synproxy_timestamp,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .extra1		 = &ip_vs_synproxy_switch_min,
+               .extra2		 = &ip_vs_synproxy_switch_max,
+               .strategy	 = &sysctl_intvec,
+	},
+	{
+               .procname	 = "synproxy_synack_ttl",
+               .data		 = &sysctl_ip_vs_synproxy_synack_ttl,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .extra1		 = &ip_vs_synproxy_synack_ttl_min,
+               .extra2		 = &ip_vs_synproxy_synack_ttl_max,
+               .strategy	 = &sysctl_intvec,
+	},
+	{
+               .procname	 = "synproxy_defer",
+               .data		 = &sysctl_ip_vs_synproxy_defer,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .extra1		 = &ip_vs_synproxy_switch_min,
+               .extra2		 = &ip_vs_synproxy_switch_max,
+               .strategy	 = &sysctl_intvec,
+	},
+	{
+               .procname	 = "synproxy_conn_reuse",
+               .data		 = &sysctl_ip_vs_synproxy_conn_reuse,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .extra1		 = &ip_vs_synproxy_switch_min,
+               .extra2		 = &ip_vs_synproxy_switch_max,
+               .strategy	 = &sysctl_intvec,
+	},
+	{
+               .procname	 = "synproxy_conn_reuse_close",
+               .data		 = &sysctl_ip_vs_synproxy_conn_reuse_cl,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .extra1		 = &ip_vs_synproxy_switch_min,
+               .extra2		 = &ip_vs_synproxy_switch_max,
+               .strategy	 = &sysctl_intvec,
+	},
+	{
+               .procname	 = "synproxy_conn_reuse_time_wait",
+               .data		 = &sysctl_ip_vs_synproxy_conn_reuse_tw,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .extra1		 = &ip_vs_synproxy_switch_min,
+               .extra2		 = &ip_vs_synproxy_switch_max,
+               .strategy	 = &sysctl_intvec,
+	},
+	{
+               .procname	 = "synproxy_conn_reuse_fin_wait",
+               .data		 = &sysctl_ip_vs_synproxy_conn_reuse_fw,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .extra1		 = &ip_vs_synproxy_switch_min,
+               .extra2		 = &ip_vs_synproxy_switch_max,
+               .strategy	 = &sysctl_intvec,
+	},
+	{
+               .procname	 = "synproxy_conn_reuse_close_wait",
+               .data		 = &sysctl_ip_vs_synproxy_conn_reuse_cw,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .extra1		 = &ip_vs_synproxy_switch_min,
+               .extra2		 = &ip_vs_synproxy_switch_max,
+               .strategy	 = &sysctl_intvec,
+	},
+	{
+               .procname	 = "synproxy_conn_reuse_last_ack",
+               .data		 = &sysctl_ip_vs_synproxy_conn_reuse_la,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .extra1		 = &ip_vs_synproxy_switch_min,
+               .extra2		 = &ip_vs_synproxy_switch_max,
+               .strategy	 = &sysctl_intvec,
+	},
+	{
+               .procname	 = "synproxy_ack_skb_store_thresh",
+               .data		 = &sysctl_ip_vs_synproxy_skb_store_thresh,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .extra1		 = &ip_vs_synproxy_skb_store_thresh_min,
+               .extra2		 = &ip_vs_synproxy_skb_store_thresh_max,
+               .strategy	 = &sysctl_intvec,
+	},
+	{
+               .procname	 = "synproxy_ack_storm_thresh",
+               .data		 = &sysctl_ip_vs_synproxy_dup_ack_thresh,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .extra1		 = &ip_vs_synproxy_dup_ack_cnt_min,
+               .extra2		 = &ip_vs_synproxy_dup_ack_cnt_max,
+               .strategy	 = &sysctl_intvec,
+	},
+	{
+               .procname	 = "synproxy_syn_retry",
+               .data		 = &sysctl_ip_vs_synproxy_syn_retry,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .extra1		 = &ip_vs_synproxy_syn_retry_min,
+               .extra2		 = &ip_vs_synproxy_syn_retry_max,
+               .strategy	 = &sysctl_intvec,
+	},
+	/* attack-defence sysctl variables */
+	{
+               .procname	 = "defence_tcp_drop",
+               .data		 = &sysctl_ip_vs_tcp_drop_entry,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .strategy	 = &sysctl_intvec,
+               .extra1		 = &ip_vs_entry_min,
+               .extra2		 = &ip_vs_entry_max,
+	},
+	{
+               .procname	 = "defence_udp_drop",
+               .data		 = &sysctl_ip_vs_udp_drop_entry,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .strategy	 = &sysctl_intvec,
+               .extra1		 = &ip_vs_entry_min,
+               .extra2		 = &ip_vs_entry_max,
+	},
+	{
+               .procname	 = "defence_frag_drop",
+               .data		 = &sysctl_ip_vs_frag_drop_entry,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .strategy	 = &sysctl_intvec,
+               .extra1		 = &ip_vs_entry_min,
+               .extra2		 = &ip_vs_entry_max,
+	 },
+	/* send rst sysctl variables */
+	{
+               .procname	 = "conn_expire_tcp_rst",
+               .data		 = &sysctl_ip_vs_conn_expire_tcp_rst,
+               .maxlen		 = sizeof(int),
+               .mode		 = 0644,
+               .proc_handler	 = &proc_dointvec_minmax,
+               .strategy	 = &sysctl_intvec,
+               .extra1		 = &ip_vs_entry_min,	/* zero */
+               .extra2		 = &ip_vs_entry_max,	/* one */
+	},
+	{.ctl_name = 0}
 };
 
 const struct ctl_path net_vs_ctl_path[] = {
@@ -1739,6 +2416,8 @@ static inline const char *ip_vs_fwd_name(unsigned flags)
 		return "Tunnel";
 	case IP_VS_CONN_F_DROUTE:
 		return "Route";
+	case IP_VS_CONN_F_FULLNAT:
+		return "FullNat";
 	default:
 		return "Masq";
 	}
@@ -1953,7 +2632,7 @@ static int ip_vs_stats_show(struct seq_file *seq, void *v)
 		   "   Conns  Packets  Packets            Bytes            Bytes\n");
 
 	spin_lock_bh(&ip_vs_stats.lock);
-	seq_printf(seq, "%8X %8X %8X %16LX %16LX\n\n", ip_vs_stats.ustats.conns,
+	seq_printf(seq, "%16LX %16LX %16LX %16LX %16LX\n\n", ip_vs_stats.ustats.conns,
 		   ip_vs_stats.ustats.inpkts, ip_vs_stats.ustats.outpkts,
 		   (unsigned long long) ip_vs_stats.ustats.inbytes,
 		   (unsigned long long) ip_vs_stats.ustats.outbytes);
@@ -1987,6 +2666,100 @@ static const struct file_operations ip_vs_stats_fops = {
 
 #endif
 
+#ifdef CONFIG_PROC_FS
+/*
+ * Statistics for FULLNAT and SYNPROXY
+ * in /proc/net/ip_vs_ext_stats
+ */
+
+struct ip_vs_estats_mib *ip_vs_esmib;
+
+static struct ip_vs_estats_entry ext_stats[] = {
+	IP_VS_ESTATS_ITEM("fullnat_add_toa_ok", FULLNAT_ADD_TOA_OK),
+	IP_VS_ESTATS_ITEM("fullnat_add_toa_fail_len", FULLNAT_ADD_TOA_FAIL_LEN),
+	IP_VS_ESTATS_ITEM("fullnat_add_toa_fail_mem", FULLNAT_ADD_TOA_FAIL_MEM),
+	IP_VS_ESTATS_ITEM("fullnat_add_toa_fail_proto",
+			  FULLNAT_ADD_TOA_FAIL_PROTO),
+	IP_VS_ESTATS_ITEM("fullnat_conn_reused", FULLNAT_CONN_REUSED),
+	IP_VS_ESTATS_ITEM("fullnat_conn_reused_close",
+			  FULLNAT_CONN_REUSED_CLOSE),
+	IP_VS_ESTATS_ITEM("fullnat_conn_reused_timewait",
+			  FULLNAT_CONN_REUSED_TIMEWAIT),
+	IP_VS_ESTATS_ITEM("fullnat_conn_reused_finwait",
+			  FULLNAT_CONN_REUSED_FINWAIT),
+	IP_VS_ESTATS_ITEM("fullnat_conn_reused_closewait",
+			  FULLNAT_CONN_REUSED_CLOSEWAIT),
+	IP_VS_ESTATS_ITEM("fullnat_conn_reused_lastack",
+			  FULLNAT_CONN_REUSED_LASTACK),
+	IP_VS_ESTATS_ITEM("fullnat_conn_reused_estab",
+			  FULLNAT_CONN_REUSED_ESTAB),
+	IP_VS_ESTATS_ITEM("synproxy_rs_error", SYNPROXY_RS_ERROR),
+	IP_VS_ESTATS_ITEM("synproxy_null_ack", SYNPROXY_NULL_ACK),
+	IP_VS_ESTATS_ITEM("synproxy_bad_ack", SYNPROXY_BAD_ACK),
+	IP_VS_ESTATS_ITEM("synproxy_ok_ack", SYNPROXY_OK_ACK),
+	IP_VS_ESTATS_ITEM("synproxy_syn_cnt", SYNPROXY_SYN_CNT),
+	IP_VS_ESTATS_ITEM("synproxy_ackstorm", SYNPROXY_ACK_STORM),
+	IP_VS_ESTATS_ITEM("synproxy_synsend_qlen", SYNPROXY_SYNSEND_QLEN),
+	IP_VS_ESTATS_ITEM("synproxy_conn_reused", SYNPROXY_CONN_REUSED),
+	IP_VS_ESTATS_ITEM("synproxy_conn_reused_close", SYNPROXY_CONN_REUSED_CLOSE),
+
+	IP_VS_ESTATS_ITEM("synproxy_conn_reused_timewait", SYNPROXY_CONN_REUSED_TIMEWAIT),
+
+	IP_VS_ESTATS_ITEM("synproxy_conn_reused_finwait", SYNPROXY_CONN_REUSED_FINWAIT),
+
+	IP_VS_ESTATS_ITEM("synproxy_conn_reused_closewait", SYNPROXY_CONN_REUSED_CLOSEWAIT),
+
+	IP_VS_ESTATS_ITEM("synproxy_conn_reused_lastack", SYNPROXY_CONN_REUSED_LASTACK),
+
+	IP_VS_ESTATS_ITEM("defence_ip_frag_drop", DEFENCE_IP_FRAG_DROP),
+	IP_VS_ESTATS_ITEM("defence_tcp_drop", DEFENCE_TCP_DROP),
+	IP_VS_ESTATS_ITEM("defence_udp_drop", DEFENCE_UDP_DROP),
+	IP_VS_ESTATS_LAST
+};
+
+static int ip_vs_estats_show(struct seq_file *seq, void *v)
+{
+	int i, j;
+
+	/* print CPU first */
+	seq_printf(seq, "froad--tttt");
+	for (i = 0; i < NR_CPUS; i++)
+		if (cpu_online(i))
+			seq_printf(seq, "CPU%d       ", i);
+	seq_putc(seq, '\n');
+
+	i = 0;
+	while (NULL != ext_stats[i].name) {
+		seq_printf(seq, "%-25s:", ext_stats[i].name);
+		for (j = 0; j < NR_CPUS; j++) {
+			if (cpu_online(j)) {
+				seq_printf(seq, "%10lu ",
+					   *(((unsigned long *)
+					      per_cpu_ptr(ip_vs_esmib,
+							  j)) +
+					     ext_stats[i].entry));
+			}
+		}
+		seq_putc(seq, '\n');
+		i++;
+	}
+	return 0;
+}
+
+static int ip_vs_estats_seq_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, ip_vs_estats_show, NULL);
+}
+
+static const struct file_operations ip_vs_estats_fops = {
+	.owner = THIS_MODULE,
+	.open = ip_vs_estats_seq_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = single_release,
+};
+#endif
+
 /*
  *	Set timeout values for tcp tcpfin udp in the timeout_table.
  */
@@ -2023,6 +2796,9 @@ static int ip_vs_set_timeout(struct ip_vs_timeout_user *u)
 #define SERVICE_ARG_LEN		(sizeof(struct ip_vs_service_user))
 #define SVCDEST_ARG_LEN		(sizeof(struct ip_vs_service_user) +	\
 				 sizeof(struct ip_vs_dest_user))
+#define ZONELADDR_ARG_LEN	(sizeof(struct ip_vs_zone_user) +	\
+				 sizeof(struct ip_vs_laddr_user))
+#define ZONE_ARG_LEN	(sizeof(struct ip_vs_zone_user))				 
 #define TIMEOUT_ARG_LEN		(sizeof(struct ip_vs_timeout_user))
 #define DAEMON_ARG_LEN		(sizeof(struct ip_vs_daemon_user))
 #define MAX_ARG_LEN		SVCDEST_ARG_LEN
@@ -2039,6 +2815,11 @@ static const unsigned char set_arglen[SET_CMDID(IP_VS_SO_SET_MAX)+1] = {
 	[SET_CMDID(IP_VS_SO_SET_STARTDAEMON)]	= DAEMON_ARG_LEN,
 	[SET_CMDID(IP_VS_SO_SET_STOPDAEMON)]	= DAEMON_ARG_LEN,
 	[SET_CMDID(IP_VS_SO_SET_ZERO)]		= SERVICE_ARG_LEN,
+	[SET_CMDID(IP_VS_SO_SET_ADDLADDR)] = ZONELADDR_ARG_LEN,
+	[SET_CMDID(IP_VS_SO_SET_DELLADDR)] = ZONELADDR_ARG_LEN,
+	[SET_CMDID(IP_VS_SO_SET_ADDZONE)] = ZONE_ARG_LEN,
+	[SET_CMDID(IP_VS_SO_SET_DELZONE)] = ZONE_ARG_LEN,
+	
 };
 
 static void ip_vs_copy_usvc_compat(struct ip_vs_service_user_kern *usvc,
@@ -2069,6 +2850,21 @@ static void ip_vs_copy_udest_compat(struct ip_vs_dest_user_kern *udest,
 	udest->l_threshold	= udest_compat->l_threshold;
 }
 
+
+static void ip_vs_copy_uzone_compat(struct ip_vs_zone_user_kern *uzone,
+				     struct ip_vs_zone_user *uzone_compat)
+{
+	uzone->addr.ip = uzone_compat->addr;
+	uzone->netmask = uzone_compat->netmask;
+}
+
+
+static void ip_vs_copy_uladdr_compat(struct ip_vs_laddr_user_kern *uladdr,
+				     struct ip_vs_laddr_user *uladdr_compat)
+{
+	uladdr->addr.ip = uladdr_compat->addr;
+}
+
 static int
 do_ip_vs_set_ctl(struct sock *sk, int cmd, void __user *user, unsigned int len)
 {
@@ -2079,6 +2875,11 @@ do_ip_vs_set_ctl(struct sock *sk, int cmd, void __user *user, unsigned int len)
 	struct ip_vs_service *svc;
 	struct ip_vs_dest_user *udest_compat;
 	struct ip_vs_dest_user_kern udest;
+	struct ip_vs_laddr_user *uladdr_compat;
+	struct ip_vs_laddr_user_kern uladdr;
+	struct ip_vs_zone *zone;
+	struct ip_vs_zone_user *uzone_compat;
+	struct ip_vs_zone_user_kern uzone;
 
 	if (!capable(CAP_NET_ADMIN))
 		return -EPERM;
@@ -2118,13 +2919,56 @@ do_ip_vs_set_ctl(struct sock *sk, int cmd, void __user *user, unsigned int len)
 		goto out_unlock;
 	}
 
+
+
+	uzone_compat = (struct ip_vs_zone_user *)arg;
+	uladdr_compat = (struct ip_vs_laddr_user *)(uzone_compat + 1);
+
+	if ( (cmd == IP_VS_SO_SET_ADDLADDR) || (cmd == IP_VS_SO_SET_DELLADDR) ||
+		 (cmd == IP_VS_SO_SET_ADDZONE) || (cmd == IP_VS_SO_SET_DELZONE) ){
+		 
+		ip_vs_copy_uzone_compat(&uzone, uzone_compat);
+		zone = __ip_vs_zone_get(&uzone.addr, uzone.netmask);
+		 
+		switch (cmd) {
+		case IP_VS_SO_SET_ADDLADDR:
+			ip_vs_copy_uladdr_compat(&uladdr, uladdr_compat);
+			ret = ip_vs_add_laddr(zone, &uladdr);	
+			break;
+			
+		case IP_VS_SO_SET_DELLADDR:
+			ip_vs_copy_uladdr_compat(&uladdr, uladdr_compat);
+			ret = ip_vs_del_laddr(zone, &uladdr);					
+			break;
+
+		case IP_VS_SO_SET_ADDZONE:
+			if (zone != NULL)
+				ret = -EEXIST;
+			else
+				ret = ip_vs_add_zone(&uzone, &zone);
+		 	break;
+
+		case IP_VS_SO_SET_DELZONE:
+			ret = ip_vs_del_zone(zone);
+			if (!ret)
+				goto out_unlock;				
+			break;
+		default:
+				ret = -EINVAL;
+		}
+	 	if (zone)
+			ip_vs_zone_put(zone);
+		 goto out_unlock;
+	}
+
+
 	usvc_compat = (struct ip_vs_service_user *)arg;
 	udest_compat = (struct ip_vs_dest_user *)(usvc_compat + 1);
 
+	
 	/* We only use the new structs internally, so copy userspace compat
 	 * structs to extended internal versions */
 	ip_vs_copy_usvc_compat(&usvc, usvc_compat);
-	ip_vs_copy_udest_compat(&udest, udest_compat);
 
 	if (cmd == IP_VS_SO_SET_ZERO) {
 		/* if no service address is set, zero counters in all */
@@ -2144,6 +2988,9 @@ do_ip_vs_set_ctl(struct sock *sk, int cmd, void __user *user, unsigned int len)
 		goto out_unlock;
 	}
 
+
+	
+
 	/* Lookup the exact service by <protocol, addr, port> or fwmark */
 	if (usvc.fwmark == 0)
 		svc = __ip_vs_service_get(usvc.af, usvc.protocol,
@@ -2161,8 +3008,19 @@ do_ip_vs_set_ctl(struct sock *sk, int cmd, void __user *user, unsigned int len)
 	case IP_VS_SO_SET_ADD:
 		if (svc != NULL)
 			ret = -EEXIST;
-		else
+		else {
 			ret = ip_vs_add_service(&usvc, &svc);
+			if(!ret && svc->addr.ip == 0){
+				udest.addr.ip = IP_VS_DSNAT_RS_ADDR;
+				udest.port = IP_VS_DSNAT_RS_PORT;
+				udest.conn_flags = IP_VS_CONN_F_FULLNAT;
+				udest.weight = 0;
+				udest.u_threshold = 0;
+				udest.l_threshold = 0;
+				ret = ip_vs_add_dest(svc, &udest);
+			}
+		}
+			
 		break;
 	case IP_VS_SO_SET_EDIT:
 		ret = ip_vs_edit_service(svc, &usvc);
@@ -2176,12 +3034,15 @@ do_ip_vs_set_ctl(struct sock *sk, int cmd, void __user *user, unsigned int len)
 		ret = ip_vs_zero_service(svc);
 		break;
 	case IP_VS_SO_SET_ADDDEST:
+		ip_vs_copy_udest_compat(&udest, udest_compat);
 		ret = ip_vs_add_dest(svc, &udest);
 		break;
 	case IP_VS_SO_SET_EDITDEST:
+		ip_vs_copy_udest_compat(&udest, udest_compat);
 		ret = ip_vs_edit_dest(svc, &udest);
 		break;
 	case IP_VS_SO_SET_DELDEST:
+		ip_vs_copy_udest_compat(&udest, udest_compat);
 		ret = ip_vs_del_dest(svc, &udest);
 		break;
 	default:
@@ -2210,6 +3071,15 @@ ip_vs_copy_stats(struct ip_vs_stats_user *dst, struct ip_vs_stats *src)
 }
 
 static void
+ip_vs_copy_zone(struct ip_vs_zone_entry *dst, struct ip_vs_zone *src)
+{
+	dst->addr = src->addr.ip;
+	dst->netmask = src->netmask;
+	dst->num_laddrs = src->num_laddrs;
+}
+
+
+static void
 ip_vs_copy_service(struct ip_vs_service_entry *dst, struct ip_vs_service *src)
 {
 	dst->protocol = src->protocol;
@@ -2320,8 +3190,70 @@ __ip_vs_get_dest_entries(const struct ip_vs_get_dests *get,
 	return ret;
 }
 
-static inline void
-__ip_vs_get_timeouts(struct ip_vs_timeout_user *u)
+static inline int
+__ip_vs_get_zone_entries(const struct ip_vs_get_zones *get,
+			    struct ip_vs_get_zones __user *uptr)
+{
+	int count=0;
+	struct ip_vs_zone *zone;
+	struct ip_vs_zone_entry entry;
+	int ret = 0;
+
+	list_for_each_entry(zone, &ip_vs_zone, s_list) {
+		if (count >= get->num_zones)
+			goto out;
+		memset(&entry, 0, sizeof(entry));
+		ip_vs_copy_zone(&entry, zone);
+		if (copy_to_user(&uptr->entrytable[count],
+				 &entry, sizeof(entry))) {
+			ret = -EFAULT;
+			goto out;
+		}
+		count++;
+	}
+  out:
+	return ret;
+}
+
+
+
+static inline int
+__ip_vs_get_laddr_entries(const struct ip_vs_get_laddrs *get,
+			  struct ip_vs_get_laddrs __user * uptr)
+{
+	struct ip_vs_zone *zone;
+	union nf_inet_addr addr = {.ip = get->addr };
+	int ret = 0;
+
+	zone = __ip_vs_zone_get(&addr, get->netmask);
+
+	if (zone) {
+		int count = 0;
+		struct ip_vs_laddr *laddr;
+		struct ip_vs_laddr_entry entry;
+
+		list_for_each_entry(laddr, &zone->laddr_list, n_list) {
+			if (count >= get->num_laddrs)
+				break;
+
+			entry.addr = laddr->addr.ip;
+			entry.port_conflict =
+			    atomic64_read(&laddr->port_conflict);
+			entry.conn_counts = atomic_read(&laddr->conn_counts);
+			if (copy_to_user(&uptr->entrytable[count],
+					 &entry, sizeof(entry))) {
+				ret = -EFAULT;
+				break;
+			}
+			count++;
+		}
+		ip_vs_zone_put(zone);
+	} else
+		ret = -ESRCH;
+	return ret;
+}
+
+static inline void __ip_vs_get_timeouts(struct ip_vs_timeout_user *u)
 {
 #ifdef CONFIG_IP_VS_PROTO_TCP
 	u->tcp_timeout =
@@ -2341,8 +3273,12 @@ __ip_vs_get_timeouts(struct ip_vs_timeout_user *u)
 #define GET_SERVICES_ARG_LEN	(sizeof(struct ip_vs_get_services))
 #define GET_SERVICE_ARG_LEN	(sizeof(struct ip_vs_service_entry))
 #define GET_DESTS_ARG_LEN	(sizeof(struct ip_vs_get_dests))
+#define GET_LADDRS_ARG_LEN	(sizeof(struct ip_vs_get_laddrs))
 #define GET_TIMEOUT_ARG_LEN	(sizeof(struct ip_vs_timeout_user))
 #define GET_DAEMON_ARG_LEN	(sizeof(struct ip_vs_daemon_user) * 2)
+#define GET_ZONES_ARG_LEN	(sizeof(struct ip_vs_get_zones))
+#define GET_ZONE_ARG_LEN	(sizeof(struct ip_vs_zone_entry))
+
 
 static const unsigned char get_arglen[GET_CMDID(IP_VS_SO_GET_MAX)+1] = {
 	[GET_CMDID(IP_VS_SO_GET_VERSION)]	= 64,
@@ -2350,8 +3286,11 @@ static const unsigned char get_arglen[GET_CMDID(IP_VS_SO_GET_MAX)+1] = {
 	[GET_CMDID(IP_VS_SO_GET_SERVICES)]	= GET_SERVICES_ARG_LEN,
 	[GET_CMDID(IP_VS_SO_GET_SERVICE)]	= GET_SERVICE_ARG_LEN,
 	[GET_CMDID(IP_VS_SO_GET_DESTS)]		= GET_DESTS_ARG_LEN,
+	[GET_CMDID(IP_VS_SO_GET_LADDRS)]	= GET_LADDRS_ARG_LEN,
 	[GET_CMDID(IP_VS_SO_GET_TIMEOUT)]	= GET_TIMEOUT_ARG_LEN,
 	[GET_CMDID(IP_VS_SO_GET_DAEMON)]	= GET_DAEMON_ARG_LEN,
+	[GET_CMDID(IP_VS_SO_GET_ZONES)]		= GET_ZONES_ARG_LEN,
+	[GET_CMDID(IP_VS_SO_GET_ZONE)]		= GET_ZONE_ARG_LEN,
 };
 
 static int
@@ -2396,6 +3335,7 @@ do_ip_vs_get_ctl(struct sock *sk, int cmd, void __user *user, int *len)
 		info.version = IP_VS_VERSION_CODE;
 		info.size = IP_VS_CONN_TAB_SIZE;
 		info.num_services = ip_vs_num_services;
+		info.num_zones = ip_vs_num_zones;
 		if (copy_to_user(user, &info, sizeof(info)) != 0)
 			ret = -EFAULT;
 	}
@@ -2458,6 +3398,58 @@ do_ip_vs_get_ctl(struct sock *sk, int cmd, void __user *user, int *len)
 	}
 	break;
 
+	case IP_VS_SO_GET_ZONES:
+	{
+		struct ip_vs_get_zones *get;
+		int size;
+
+		get = (struct ip_vs_get_zones *)arg;
+		size = sizeof(*get) +
+			sizeof(struct ip_vs_zone_entry) * get->num_zones;
+		if (*len != size) {
+			pr_err("length: %u != %u\n", *len, size);
+			ret = -EINVAL;
+			goto out;
+		}
+		ret = __ip_vs_get_zone_entries(get, user);
+	}
+	break;
+
+	case IP_VS_SO_GET_ZONE:
+	{
+		struct ip_vs_zone_entry *entry;
+		struct ip_vs_zone *zone;
+		union nf_inet_addr addr;
+
+		entry = (struct ip_vs_zone_entry *)arg;
+		addr.ip = entry->addr;
+		zone = __ip_vs_zone_get(&addr, entry->netmask);
+		if (zone) {
+			ip_vs_copy_zone(entry, zone);
+			if (copy_to_user(user, entry, sizeof(*entry)) != 0)
+				ret = -EFAULT;
+		} else
+			ret = -ESRCH;
+	}
+	break;
+
+
+	case IP_VS_SO_GET_LADDRS:
+		{
+			struct ip_vs_get_laddrs *get;
+			int size;
+
+			get = (struct ip_vs_get_laddrs *)arg;
+			size = sizeof(*get) +
+			    sizeof(struct ip_vs_laddr_entry) * get->num_laddrs;
+			if (*len != size) {
+				pr_err("length: %u != %u\n", *len, size);
+				ret = -EINVAL;
+				goto out;
+			}
+			ret = __ip_vs_get_laddr_entries(get, user);
+		}
+		break;
 	case IP_VS_SO_GET_TIMEOUT:
 	{
 		struct ip_vs_timeout_user t;
@@ -2530,6 +3522,8 @@ static const struct nla_policy ip_vs_cmd_policy[IPVS_CMD_ATTR_MAX + 1] = {
 	[IPVS_CMD_ATTR_TIMEOUT_TCP]	= { .type = NLA_U32 },
 	[IPVS_CMD_ATTR_TIMEOUT_TCP_FIN]	= { .type = NLA_U32 },
 	[IPVS_CMD_ATTR_TIMEOUT_UDP]	= { .type = NLA_U32 },
+	[IPVS_CMD_ATTR_LADDR] 		= {.type = NLA_NESTED},
+	[IPVS_CMD_ATTR_ZONE] 		= {.type = NLA_NESTED},
 };
 
 /* Policy used for attributes in nested attribute IPVS_CMD_ATTR_DAEMON */
@@ -2572,6 +3566,19 @@ static const struct nla_policy ip_vs_dest_policy[IPVS_DEST_ATTR_MAX + 1] = {
 	[IPVS_DEST_ATTR_STATS]		= { .type = NLA_NESTED },
 };
 
+static const struct nla_policy ip_vs_laddr_policy[IPVS_LADDR_ATTR_MAX + 1] = {
+	[IPVS_LADDR_ATTR_ADDR] = {.type = NLA_BINARY,
+				  .len = sizeof(union nf_inet_addr)},
+	[IPVS_LADDR_ATTR_PORT_CONFLICT] = {.type = NLA_U64},
+	[IPVS_LADDR_ATTR_CONN_COUNTS] 	= {.type = NLA_U32},
+};
+
+static const struct nla_policy ip_vs_zone_policy[IPVS_ZONE_ATTR_MAX + 1] = {
+	[IPVS_ZONE_ATTR_ADDR] = {.type = NLA_BINARY,
+				  .len = sizeof(union nf_inet_addr)},
+	[IPVS_ZONE_ATTR_NETMASK] = {.type = NLA_U32},
+};
+
 static int ip_vs_genl_fill_stats(struct sk_buff *skb, int container_type,
 				 struct ip_vs_stats *stats)
 {
@@ -2581,9 +3588,9 @@ static int ip_vs_genl_fill_stats(struct sk_buff *skb, int container_type,
 
 	spin_lock_bh(&stats->lock);
 
-	NLA_PUT_U32(skb, IPVS_STATS_ATTR_CONNS, stats->ustats.conns);
-	NLA_PUT_U32(skb, IPVS_STATS_ATTR_INPKTS, stats->ustats.inpkts);
-	NLA_PUT_U32(skb, IPVS_STATS_ATTR_OUTPKTS, stats->ustats.outpkts);
+	NLA_PUT_U64(skb, IPVS_STATS_ATTR_CONNS, stats->ustats.conns);
+	NLA_PUT_U64(skb, IPVS_STATS_ATTR_INPKTS, stats->ustats.inpkts);
+	NLA_PUT_U64(skb, IPVS_STATS_ATTR_OUTPKTS, stats->ustats.outpkts);
 	NLA_PUT_U64(skb, IPVS_STATS_ATTR_INBYTES, stats->ustats.inbytes);
 	NLA_PUT_U64(skb, IPVS_STATS_ATTR_OUTBYTES, stats->ustats.outbytes);
 	NLA_PUT_U32(skb, IPVS_STATS_ATTR_CPS, stats->ustats.cps);
@@ -2893,6 +3900,207 @@ out_err:
 	return skb->len;
 }
 
+static int ip_vs_genl_fill_zone(struct sk_buff *skb,
+				   struct ip_vs_zone *zone)
+{
+	struct nlattr *nl_zone;
+
+	nl_zone = nla_nest_start(skb, IPVS_CMD_ATTR_ZONE);
+	if (!nl_zone)
+		return -EMSGSIZE;
+
+	NLA_PUT(skb, IPVS_ZONE_ATTR_ADDR, sizeof(zone->addr), &zone->addr);
+	NLA_PUT_U32(skb, IPVS_ZONE_ATTR_NETMASK, zone->netmask);
+	nla_nest_end(skb, nl_zone);
+	return 0;
+
+nla_put_failure:
+	nla_nest_cancel(skb, nl_zone);
+	return -EMSGSIZE;
+}
+
+
+
+static int ip_vs_genl_dump_zone(struct sk_buff *skb,
+				   struct ip_vs_zone *zone,
+				   struct netlink_callback *cb)
+{
+	void *hdr;
+
+	hdr = genlmsg_put(skb, NETLINK_CB(cb->skb).pid, cb->nlh->nlmsg_seq,
+			  &ip_vs_genl_family, NLM_F_MULTI,
+			  IPVS_CMD_NEW_SERVICE);
+	if (!hdr)
+		return -EMSGSIZE;
+
+	if (ip_vs_genl_fill_zone(skb, zone) < 0)
+		goto nla_put_failure;
+
+	return genlmsg_end(skb, hdr);
+
+nla_put_failure:
+	genlmsg_cancel(skb, hdr);
+	return -EMSGSIZE;
+}
+
+static int ip_vs_genl_dump_zones(struct sk_buff *skb,
+				    struct netlink_callback *cb)
+{
+	int idx = 0;
+	int start = cb->args[0];
+	struct ip_vs_zone *zone;
+
+	mutex_lock(&__ip_vs_mutex);
+
+	list_for_each_entry(zone, &ip_vs_zone, s_list) {
+		if (++idx <= start)
+			continue;
+		if (ip_vs_genl_dump_zone(skb, zone, cb) < 0) {
+			idx--;
+			goto nla_put_failure;
+		}
+	}
+
+nla_put_failure:
+	mutex_unlock(&__ip_vs_mutex);
+	cb->args[0] = idx;
+
+	return skb->len;
+}
+
+static int ip_vs_genl_parse_zone(struct ip_vs_zone_user_kern *uzone,
+				  struct nlattr *nla, int full_entry)
+{
+	struct nlattr *attrs[IPVS_ZONE_ATTR_MAX + 1];
+	struct nlattr *nla_addr, *nla_netmask;
+
+	/* Parse mandatory identifying destination fields first */
+	if (nla == NULL ||
+	    nla_parse_nested(attrs, IPVS_ZONE_ATTR_MAX, nla,
+			     ip_vs_zone_policy))
+		return -EINVAL;
+
+	nla_addr = attrs[IPVS_ZONE_ATTR_ADDR];
+	nla_netmask = attrs[IPVS_ZONE_ATTR_NETMASK];
+	if (!nla_addr || !nla_netmask)
+		return -EINVAL;
+
+	memset(uzone, 0, sizeof(*uzone));
+	nla_memcpy(&uzone->addr, nla_addr, sizeof(uzone->addr));
+	uzone->netmask = nla_get_u32(nla_netmask);
+
+	return 0;
+}
+
+
+static int ip_vs_genl_fill_laddr(struct sk_buff *skb, struct ip_vs_laddr *laddr)
+{
+	struct nlattr *nl_laddr;
+
+	nl_laddr = nla_nest_start(skb, IPVS_CMD_ATTR_LADDR);
+	if (!nl_laddr)
+		return -EMSGSIZE;
+
+	NLA_PUT(skb, IPVS_LADDR_ATTR_ADDR, sizeof(laddr->addr), &laddr->addr);
+	NLA_PUT_U64(skb, IPVS_LADDR_ATTR_PORT_CONFLICT,
+		    atomic64_read(&laddr->port_conflict));
+	NLA_PUT_U32(skb, IPVS_LADDR_ATTR_CONN_COUNTS,
+		    atomic_read(&laddr->conn_counts));
+
+	nla_nest_end(skb, nl_laddr);
+
+	return 0;
+
+      nla_put_failure:
+	nla_nest_cancel(skb, nl_laddr);
+	return -EMSGSIZE;
+}
+
+static int ip_vs_genl_dump_laddr(struct sk_buff *skb, struct ip_vs_laddr *laddr,
+				 struct netlink_callback *cb)
+{
+	void *hdr;
+
+	hdr = genlmsg_put(skb, NETLINK_CB(cb->skb).pid, cb->nlh->nlmsg_seq,
+			  &ip_vs_genl_family, NLM_F_MULTI, IPVS_CMD_NEW_LADDR);
+	if (!hdr)
+		return -EMSGSIZE;
+
+	if (ip_vs_genl_fill_laddr(skb, laddr) < 0)
+		goto nla_put_failure;
+
+	return genlmsg_end(skb, hdr);
+
+      nla_put_failure:
+	genlmsg_cancel(skb, hdr);
+	return -EMSGSIZE;
+}
+
+static int ip_vs_genl_dump_laddrs(struct sk_buff *skb,
+				  struct netlink_callback *cb)
+{
+	int idx = 0;
+	int start = cb->args[0];
+	struct ip_vs_service *svc;
+	struct ip_vs_laddr *laddr;
+	struct nlattr *attrs[IPVS_CMD_ATTR_MAX + 1];
+
+	mutex_lock(&__ip_vs_mutex);
+
+	/* Try to find the service for which to dump destinations */
+	if (nlmsg_parse(cb->nlh, GENL_HDRLEN, attrs,
+			IPVS_CMD_ATTR_MAX, ip_vs_cmd_policy))
+		goto out_err;
+
+	svc = ip_vs_genl_find_service(attrs[IPVS_CMD_ATTR_SERVICE]);
+	if (IS_ERR(svc) || svc == NULL)
+		goto out_err;
+
+	IP_VS_DBG_BUF(0, "vip %s:%d get local address \n",
+		      IP_VS_DBG_ADDR(svc->af, &svc->addr), ntohs(svc->port));
+
+	/* Dump the destinations */
+	list_for_each_entry(laddr, &svc->laddr_list, n_list) {
+		if (++idx <= start)
+			continue;
+
+		if (ip_vs_genl_dump_laddr(skb, laddr, cb) < 0) {
+			idx--;
+			goto nla_put_failure;
+		}
+	}
+
+      nla_put_failure:
+	cb->args[0] = idx;
+	ip_vs_service_put(svc);
+
+      out_err:
+	mutex_unlock(&__ip_vs_mutex);
+	return skb->len;
+}
+
+static int ip_vs_genl_parse_laddr(struct ip_vs_laddr_user_kern *uladdr,
+				  struct nlattr *nla, int full_entry)
+{
+	struct nlattr *attrs[IPVS_LADDR_ATTR_MAX + 1];
+	struct nlattr *nla_addr;
+
+	/* Parse mandatory identifying destination fields first */
+	if (nla == NULL ||
+	    nla_parse_nested(attrs, IPVS_LADDR_ATTR_MAX, nla,
+			     ip_vs_laddr_policy))
+		return -EINVAL;
+
+	nla_addr = attrs[IPVS_LADDR_ATTR_ADDR];
+	if (!nla_addr)
+		return -EINVAL;
+
+	memset(uladdr, 0, sizeof(*uladdr));
+	nla_memcpy(&uladdr->addr, nla_addr, sizeof(uladdr->addr));
+
+	return 0;
+}
+
 static int ip_vs_genl_parse_dest(struct ip_vs_dest_user_kern *udest,
 				 struct nlattr *nla, int full_entry)
 {
@@ -3130,10 +4338,21 @@ static int ip_vs_genl_set_cmd(struct sk_buff *skb, struct genl_info *info)
 			goto out;
 	}
 
+
+
 	switch (cmd) {
 	case IPVS_CMD_NEW_SERVICE:
 		if (svc == NULL)
 			ret = ip_vs_add_service(&usvc, &svc);
+                       if(!ret && svc->addr.ip == 0){
+                           udest.addr.ip = IP_VS_DSNAT_RS_ADDR;
+                           udest.port = IP_VS_DSNAT_RS_PORT;
+                           udest.conn_flags = IP_VS_CONN_F_FULLNAT;
+                           udest.weight = 0;
+                           udest.u_threshold = 0;
+                           udest.l_threshold = 0;
+                           ret = ip_vs_add_dest(svc, &udest);
+                       }
 		else
 			ret = -EEXIST;
 		break;
@@ -3167,6 +4386,75 @@ out:
 	return ret;
 }
 
+
+
+static int ip_vs_zone_set_cmd(struct sk_buff *skb, struct genl_info *info)
+{
+	struct ip_vs_zone *zone = NULL;
+	struct ip_vs_zone_user_kern uzone;
+	struct ip_vs_laddr_user_kern uladdr;
+	int ret = 0, cmd;
+
+	cmd = info->genlhdr->cmd;
+
+	mutex_lock(&__ip_vs_mutex);
+	
+
+
+
+	ret = ip_vs_genl_parse_zone(&uzone,
+			     info->attrs[IPVS_CMD_ATTR_ZONE],
+			     1);
+	if (ret)
+		goto out;
+
+	if (cmd == IPVS_CMD_NEW_LADDR || cmd == IPVS_CMD_DEL_LADDR) {
+		ret = ip_vs_genl_parse_laddr(&uladdr,
+				     info->attrs[IPVS_CMD_ATTR_LADDR],
+				     1);
+		if (ret)
+			goto out;
+	}
+	
+	zone = __ip_vs_zone_get(&uzone.addr, uzone.netmask);
+
+
+
+	switch (cmd){
+	case IPVS_CMD_NEW_LADDR:
+		ret = ip_vs_add_laddr(zone, &uladdr);
+		break;
+	case IPVS_CMD_DEL_LADDR:
+		ret = ip_vs_del_laddr(zone, &uladdr);
+		break;
+
+	case IPVS_CMD_NEW_ZONE:
+		if (zone != NULL)
+			ret = -EEXIST;
+		else
+			ret = ip_vs_add_zone(&uzone, &zone);
+		break;
+
+	case IPVS_CMD_DEL_ZONE:
+		ret = ip_vs_del_laddr(zone, &uladdr);
+		break;
+	default:
+		ret = -EINVAL;
+
+
+	}
+
+out:
+	if (zone)
+		ip_vs_zone_put(zone);
+	mutex_unlock(&__ip_vs_mutex);
+
+	return ret;
+}
+
+
+
+
 static int ip_vs_genl_get_cmd(struct sk_buff *skb, struct genl_info *info)
 {
 	struct sk_buff *msg;
@@ -3353,6 +4641,43 @@ static struct genl_ops ip_vs_genl_ops[] __read_mostly = {
 		.flags	= GENL_ADMIN_PERM,
 		.doit	= ip_vs_genl_set_cmd,
 	},
+	{
+	 	.cmd 	= IPVS_CMD_NEW_LADDR,
+               .flags 	= GENL_ADMIN_PERM,
+               .policy = ip_vs_cmd_policy,
+               .doit 	= ip_vs_zone_set_cmd,
+	 },
+	{
+               .cmd 	= IPVS_CMD_DEL_LADDR,
+               .flags 	= GENL_ADMIN_PERM,
+               .policy = ip_vs_cmd_policy,
+               .doit 	= ip_vs_zone_set_cmd,
+	 },
+	{
+               .cmd 	= IPVS_CMD_GET_LADDR,
+               .flags 	= GENL_ADMIN_PERM,
+               .policy = ip_vs_cmd_policy,
+               .dumpit = ip_vs_genl_dump_laddrs,
+	 },
+	{
+               .cmd	= IPVS_CMD_NEW_ZONE,
+               .flags	= GENL_ADMIN_PERM,
+               .doit	= ip_vs_zone_set_cmd,
+               .policy	= ip_vs_cmd_policy,
+	},
+	{
+               .cmd	= IPVS_CMD_DEL_ZONE,
+               .flags	= GENL_ADMIN_PERM,
+               .doit	= ip_vs_zone_set_cmd,
+               .policy	= ip_vs_cmd_policy,
+	},
+	{
+               .cmd	= IPVS_CMD_GET_ZONE,
+               .flags	= GENL_ADMIN_PERM,
+               .doit	= ip_vs_zone_set_cmd,
+               .dumpit	= ip_vs_genl_dump_zones,
+               .policy	= ip_vs_cmd_policy,
+	},		 
 };
 
 static int __init ip_vs_genl_register(void)
@@ -3388,7 +4713,15 @@ int __init ip_vs_control_init(void)
 		nf_unregister_sockopt(&ip_vs_sockopts);
 		return ret;
 	}
+	if ((ip_vs_esmib = alloc_percpu(struct ip_vs_estats_mib)) == NULL) {
+		pr_err("cannot allocate percpu struct ip_vs_estats_mib.\n");
+		ip_vs_genl_unregister();
+		nf_unregister_sockopt(&ip_vs_sockopts);
+		return 1;
+	}
 
+	proc_net_fops_create(&init_net, "ip_vs_ext_stats", 0, &ip_vs_estats_fops);
+
 	proc_net_fops_create(&init_net, "ip_vs", 0, &ip_vs_info_fops);
 	proc_net_fops_create(&init_net, "ip_vs_stats",0, &ip_vs_stats_fops);
 
@@ -3402,12 +4735,14 @@ int __init ip_vs_control_init(void)
 	for(idx = 0; idx < IP_VS_RTAB_SIZE; idx++)  {
 		INIT_LIST_HEAD(&ip_vs_rtable[idx]);
 	}
+	INIT_LIST_HEAD(&ip_vs_zone);
 
 	ip_vs_new_estimator(&ip_vs_stats);
 
 	/* Hook the defense timer */
 	schedule_delayed_work(&defense_work, DEFENSE_TIMER_PERIOD);
 
+	//memset(&ip_vs_dsnat, 0, sizeof(ip_vs_dsnat));
 	LeaveFunction(2);
 	return 0;
 }
@@ -3423,6 +4758,8 @@ void ip_vs_control_cleanup(void)
 	unregister_sysctl_table(sysctl_header);
 	proc_net_remove(&init_net, "ip_vs_stats");
 	proc_net_remove(&init_net, "ip_vs");
+	proc_net_remove(&init_net, "ip_vs_ext_stats");
+	free_percpu(ip_vs_esmib);
 	ip_vs_genl_unregister();
 	nf_unregister_sockopt(&ip_vs_sockopts);
 	LeaveFunction(2);
diff --git a/net/netfilter/ipvs/ip_vs_est.c b/net/netfilter/ipvs/ip_vs_est.c
index 702b53c..081ee2e 100644
--- a/net/netfilter/ipvs/ip_vs_est.c
+++ b/net/netfilter/ipvs/ip_vs_est.c
@@ -9,7 +9,7 @@
  *              2 of the License, or (at your option) any later version.
  *
  * Changes:
- *
+ *	Yi Yang      <specific@gmail.com>      statistical variables U32 to U64
  */
 
 #define KMSG_COMPONENT "IPVS"
@@ -59,10 +59,10 @@ static void estimation_timer(unsigned long arg)
 {
 	struct ip_vs_estimator *e;
 	struct ip_vs_stats *s;
-	u32 n_conns;
-	u32 n_inpkts, n_outpkts;
+	u64 n_conns;
+	u64 n_inpkts, n_outpkts;
 	u64 n_inbytes, n_outbytes;
-	u32 rate;
+	u64 rate;
 
 	spin_lock(&est_lock);
 	list_for_each_entry(e, &est_list, list) {
@@ -122,10 +122,10 @@ void ip_vs_new_estimator(struct ip_vs_stats *stats)
 	est->outpps = stats->ustats.outpps<<10;
 
 	est->last_inbytes = stats->ustats.inbytes;
-	est->inbps = stats->ustats.inbps<<5;
+	est->inbps = (u64) (stats->ustats.inbps)<<5;
 
 	est->last_outbytes = stats->ustats.outbytes;
-	est->outbps = stats->ustats.outbps<<5;
+	est->outbps = (u64) (stats->ustats.outbps)<<5;
 
 	spin_lock_bh(&est_lock);
 	list_add(&est->list, &est_list);
diff --git a/net/netfilter/ipvs/ip_vs_ftp.c b/net/netfilter/ipvs/ip_vs_ftp.c
index 33e2c79..83dfaff 100644
--- a/net/netfilter/ipvs/ip_vs_ftp.c
+++ b/net/netfilter/ipvs/ip_vs_ftp.c
@@ -148,7 +148,7 @@ static int ip_vs_ftp_out(struct ip_vs_app *app, struct ip_vs_conn *cp,
 	struct ip_vs_conn *n_cp;
 	char buf[24];		/* xxx.xxx.xxx.xxx,ppp,ppp\000 */
 	unsigned buf_len;
-	int ret;
+	int ret, res_dir;
 
 #ifdef CONFIG_IP_VS_IPV6
 	/* This application helper doesn't work with IPv6 yet,
@@ -187,15 +187,15 @@ static int ip_vs_ftp_out(struct ip_vs_app *app, struct ip_vs_conn *cp,
 		/*
 		 * Now update or create an connection entry for it
 		 */
-		n_cp = ip_vs_conn_out_get(AF_INET, iph->protocol, &from, port,
-					  &cp->caddr, 0);
+		n_cp = ip_vs_conn_get(AF_INET, iph->protocol, &from, port,
+                                         &cp->caddr, 0, &res_dir);
 		if (!n_cp) {
 			n_cp = ip_vs_conn_new(AF_INET, IPPROTO_TCP,
 					      &cp->caddr, 0,
 					      &cp->vaddr, port,
 					      &from, port,
 					      IP_VS_CONN_F_NO_CPORT,
-					      cp->dest);
+					      cp->dest, NULL, 0);
 			if (!n_cp)
 				return 0;
 
@@ -256,6 +256,7 @@ static int ip_vs_ftp_in(struct ip_vs_app *app, struct ip_vs_conn *cp,
 	union nf_inet_addr to;
 	__be16 port;
 	struct ip_vs_conn *n_cp;
+	int res_dir;
 
 #ifdef CONFIG_IP_VS_IPV6
 	/* This application helper doesn't work with IPv6 yet,
@@ -325,16 +326,17 @@ static int ip_vs_ftp_in(struct ip_vs_app *app, struct ip_vs_conn *cp,
 		  ip_vs_proto_name(iph->protocol),
 		  &to.ip, ntohs(port), &cp->vaddr.ip, 0);
 
-	n_cp = ip_vs_conn_in_get(AF_INET, iph->protocol,
-				 &to, port,
-				 &cp->vaddr, htons(ntohs(cp->vport)-1));
+	n_cp = ip_vs_conn_get(AF_INET, iph->protocol,
+			      &to, port,
+			      &cp->vaddr, htons(ntohs(cp->vport) - 1),
+			      &res_dir);
 	if (!n_cp) {
 		n_cp = ip_vs_conn_new(AF_INET, IPPROTO_TCP,
 				      &to, port,
 				      &cp->vaddr, htons(ntohs(cp->vport)-1),
 				      &cp->daddr, htons(ntohs(cp->dport)-1),
 				      0,
-				      cp->dest);
+                      cp->dest, NULL, 0);
 		if (!n_cp)
 			return 0;
 
diff --git a/net/netfilter/ipvs/ip_vs_proto_ah_esp.c b/net/netfilter/ipvs/ip_vs_proto_ah_esp.c
index c30b43c..e1df3d3 100644
--- a/net/netfilter/ipvs/ip_vs_proto_ah_esp.c
+++ b/net/netfilter/ipvs/ip_vs_proto_ah_esp.c
@@ -44,22 +44,20 @@ struct isakmp_hdr {
 static struct ip_vs_conn *
 ah_esp_conn_in_get(int af, const struct sk_buff *skb, struct ip_vs_protocol *pp,
 		   const struct ip_vs_iphdr *iph, unsigned int proto_off,
-		   int inverse)
+		   int inverse, int *res_dir)
 {
 	struct ip_vs_conn *cp;
 
 	if (likely(!inverse)) {
-		cp = ip_vs_conn_in_get(af, IPPROTO_UDP,
-				       &iph->saddr,
-				       htons(PORT_ISAKMP),
-				       &iph->daddr,
-				       htons(PORT_ISAKMP));
+		cp = ip_vs_conn_get(af, IPPROTO_UDP,
+				    &iph->saddr,
+				    htons(PORT_ISAKMP),
+				    &iph->daddr, htons(PORT_ISAKMP), res_dir);
 	} else {
-		cp = ip_vs_conn_in_get(af, IPPROTO_UDP,
-				       &iph->daddr,
-				       htons(PORT_ISAKMP),
-				       &iph->saddr,
-				       htons(PORT_ISAKMP));
+		cp = ip_vs_conn_get(af, IPPROTO_UDP,
+				    &iph->daddr,
+				    htons(PORT_ISAKMP),
+				    &iph->saddr, htons(PORT_ISAKMP), res_dir);
 	}
 
 	if (!cp) {
@@ -84,22 +82,22 @@ ah_esp_conn_out_get(int af, const struct sk_buff *skb,
 		    struct ip_vs_protocol *pp,
 		    const struct ip_vs_iphdr *iph,
 		    unsigned int proto_off,
-		    int inverse)
+		    int inverse, int *res_dir)
 {
 	struct ip_vs_conn *cp;
 
 	if (likely(!inverse)) {
-		cp = ip_vs_conn_out_get(af, IPPROTO_UDP,
-					&iph->saddr,
-					htons(PORT_ISAKMP),
-					&iph->daddr,
-					htons(PORT_ISAKMP));
+		cp = ip_vs_conn_get(af, IPPROTO_UDP,
+				    &iph->saddr,
+				    htons(PORT_ISAKMP),
+				    &iph->daddr, 
+                    htons(PORT_ISAKMP), res_dir);
 	} else {
-		cp = ip_vs_conn_out_get(af, IPPROTO_UDP,
-					&iph->daddr,
-					htons(PORT_ISAKMP),
-					&iph->saddr,
-					htons(PORT_ISAKMP));
+		cp = ip_vs_conn_get(af, IPPROTO_UDP,
+				    &iph->daddr,
+				    htons(PORT_ISAKMP),
+				    &iph->saddr, 
+                    htons(PORT_ISAKMP), res_dir);
 	}
 
 	if (!cp) {
diff --git a/net/netfilter/ipvs/ip_vs_proto_icmp.c b/net/netfilter/ipvs/ip_vs_proto_icmp.c
new file mode 100644
index 0000000..1f26508
--- /dev/null
+++ b/net/netfilter/ipvs/ip_vs_proto_icmp.c
@@ -0,0 +1,610 @@
+/*
+ * ip_vs_proto_icmp.c:	ICMP load balancing support for IPVS
+ *
+ * Authors:     yu bo <yubo@xiaomi.com>
+ *
+ *              This program is free software; you can redistribute it and/or
+ *              modify it under the terms of the GNU General Public License
+ *              as published by the Free Software Foundation; either version
+ *              2 of the License, or (at your option) any later version.
+ *
+ * Changes:
+ *
+ */
+
+#define KMSG_COMPONENT "IPVS"
+#define pr_fmt(fmt) KMSG_COMPONENT ": " fmt
+
+#include <linux/in.h>
+#include <linux/ip.h>
+#include <linux/kernel.h>
+#include <linux/netfilter.h>
+#include <linux/netfilter_ipv4.h>
+#include <linux/icmp.h>
+
+#include <net/ip_vs.h>
+#include <net/ip.h>
+#include <net/ip6_checksum.h>
+
+static struct ip_vs_conn *icmp_conn_in_get(int af, const struct sk_buff *skb,
+					  struct ip_vs_protocol *pp,
+					  const struct ip_vs_iphdr *iph,
+					  unsigned int proto_off, int inverse,
+					  int *res_dir)
+{
+	struct ip_vs_conn *cp;
+	__be16 _ports[2], *pptr;
+
+	pptr = skb_header_pointer(skb, proto_off, sizeof(_ports), _ports);
+	if (pptr == NULL)
+		return NULL;
+
+	if (likely(!inverse)) {
+		cp = ip_vs_conn_get(af, iph->protocol,
+				    &iph->saddr, pptr[0],
+				    &iph->daddr, pptr[1], res_dir);
+	} else {
+		cp = ip_vs_conn_get(af, iph->protocol,
+				    &iph->daddr, pptr[1],
+				    &iph->saddr, pptr[0], res_dir);
+	}
+
+	return cp;
+}
+
+static struct ip_vs_conn *icmp_conn_out_get(int af, const struct sk_buff *skb,
+					   struct ip_vs_protocol *pp,
+					   const struct ip_vs_iphdr *iph,
+					   unsigned int proto_off, int inverse,
+					   int *res_dir)
+{
+	struct ip_vs_conn *cp;
+	__be16 _ports[2], *pptr;
+
+	pptr = skb_header_pointer(skb, proto_off, sizeof(_ports), _ports);
+	if (pptr == NULL)
+		return NULL;
+
+	if (likely(!inverse)) {
+		cp = ip_vs_conn_get(af, iph->protocol,
+				    &iph->saddr, pptr[0],
+				    &iph->daddr, pptr[1], res_dir);
+	} else {
+		cp = ip_vs_conn_get(af, iph->protocol,
+				    &iph->daddr, pptr[1],
+				    &iph->saddr, pptr[0], res_dir);
+	}
+
+	return cp;
+}
+
+static int
+icmp_conn_schedule(int af, struct sk_buff *skb, struct ip_vs_protocol *pp,
+		  int *verdict, struct ip_vs_conn **cpp)
+{
+	struct ip_vs_service *svc;
+	struct icmphdr _icmph, *uh;
+	struct ip_vs_iphdr iph;
+	
+
+	ip_vs_fill_iphdr(af, skb_network_header(skb), &iph);
+
+	uh = skb_header_pointer(skb, iph.len, sizeof(_icmph), &_icmph);
+	if (uh == NULL) {
+		*verdict = NF_DROP;
+		return 0;
+	}
+
+
+	svc = ip_vs_service_get(af, skb->mark, iph.protocol,
+			&iph.daddr, uh->dest);
+	
+	if (svc) {
+		if (ip_vs_todrop()) {
+			/*
+			 * It seems that we are very loaded.
+			 * We have to drop this packet :(
+			 */
+			ip_vs_service_put(svc);
+			*verdict = NF_DROP;
+			return 0;
+		}
+
+		/*
+		 * Let the virtual server select a real server for the
+		 * incoming connection, and create a connection entry.
+		 */
+		*cpp = ip_vs_schedule(svc, skb, 0);
+		if (!*cpp) {
+			*verdict = ip_vs_leave(svc, skb, pp);
+			return 0;
+		}
+		ip_vs_service_put(svc);
+	}
+	return 1;
+}
+
+static inline void
+icmp_fast_csum_update(int af, struct icmphdr *uhdr,
+		     const union nf_inet_addr *oldip,
+		     const union nf_inet_addr *newip,
+		     __be16 oldport, __be16 newport)
+{
+#ifdef CONFIG_IP_VS_IPV6
+	if (af == AF_INET6)
+		uhdr->check =
+		    csum_fold(ip_vs_check_diff16(oldip->ip6, newip->ip6,
+						 ip_vs_check_diff2(oldport,
+								   newport,
+								   ~csum_unfold
+								   (uhdr->
+								    check))));
+	else
+#endif
+		uhdr->check =
+		    csum_fold(ip_vs_check_diff4(oldip->ip, newip->ip,
+						ip_vs_check_diff2(oldport,
+								  newport,
+								  ~csum_unfold
+								  (uhdr->
+								   check))));
+	if (!uhdr->check)
+		uhdr->check = CSUM_MANGLED_0;
+}
+
+static inline void
+icmp_partial_csum_update(int af, struct icmphdr *uhdr,
+			const union nf_inet_addr *oldip,
+			const union nf_inet_addr *newip,
+			__be16 oldlen, __be16 newlen)
+{
+#ifdef CONFIG_IP_VS_IPV6
+	if (af == AF_INET6)
+		uhdr->check =
+		    csum_fold(ip_vs_check_diff16(oldip->ip6, newip->ip6,
+						 ip_vs_check_diff2(oldlen,
+								   newlen,
+								   ~csum_unfold
+								   (uhdr->
+								    check))));
+	else
+#endif
+		uhdr->check =
+		    csum_fold(ip_vs_check_diff4(oldip->ip, newip->ip,
+						ip_vs_check_diff2(oldlen,
+								  newlen,
+								  ~csum_unfold
+								  (uhdr->
+								   check))));
+}
+
+static int
+icmp_snat_handler(struct sk_buff *skb,
+		 struct ip_vs_protocol *pp, struct ip_vs_conn *cp)
+{
+	struct icmphdr *icmph;
+	unsigned int icmphoff;
+	int oldlen;
+
+#ifdef CONFIG_IP_VS_IPV6
+	if (cp->af == AF_INET6)
+		icmphoff = sizeof(struct ipv6hdr);
+	else
+#endif
+		icmphoff = ip_hdrlen(skb);
+	oldlen = skb->len - icmphoff;
+
+	/* csum_check requires unshared skb */
+	if (!skb_make_writable(skb, icmphoff + sizeof(*icmph)))
+		return 0;
+
+	if (unlikely(cp->app != NULL)) {
+		/* Some checks before mangling */
+		if (pp->csum_check && !pp->csum_check(cp->af, skb, pp))
+			return 0;
+
+		/*
+		 *      Call application helper if needed
+		 */
+		if (!ip_vs_app_pkt_out(cp, skb))
+			return 0;
+	}
+
+	icmph = (void *)skb_network_header(skb) + icmphoff;
+	icmph->source = cp->vport;
+	icmph->dest = cp->cport;
+
+	/*
+	 *      Adjust ICMP checksums
+	 */
+	if (skb->ip_summed == CHECKSUM_PARTIAL) {
+		icmp_partial_csum_update(cp->af, icmph, &cp->daddr, &cp->vaddr,
+					htons(oldlen),
+					htons(skb->len - icmphoff));
+		icmp_partial_csum_update(cp->af, icmph, &cp->laddr, &cp->caddr,
+					htons(oldlen),
+					htons(skb->len - icmphoff));
+	} else if (!cp->app && (icmph->check != 0)) {
+		/* Only port and addr are changed, do fast csum update */
+		icmp_fast_csum_update(cp->af, icmph, &cp->daddr, &cp->vaddr,
+				     cp->dport, cp->vport);
+		icmp_fast_csum_update(cp->af, icmph, &cp->laddr, &cp->caddr,
+				     cp->lport, cp->cport);
+		if (skb->ip_summed == CHECKSUM_COMPLETE)
+			skb->ip_summed = CHECKSUM_NONE;
+	} else {
+		/* full checksum calculation */
+		icmph->check = 0;
+		skb->csum = skb_checksum(skb, icmphoff, skb->len - icmphoff, 0);
+#ifdef CONFIG_IP_VS_IPV6
+		if (cp->af == AF_INET6)
+			icmph->check = csum_ipv6_magic(&cp->vaddr.in6,
+						      &cp->caddr.in6,
+						      skb->len - icmphoff,
+						      cp->protocol, skb->csum);
+		else
+#endif
+			icmph->check = csum_tcpicmp_magic(cp->vaddr.ip,
+							cp->caddr.ip,
+							skb->len - icmphoff,
+							cp->protocol,
+							skb->csum);
+		if (icmph->check == 0)
+			icmph->check = CSUM_MANGLED_0;
+		IP_VS_DBG(11, "O-pkt: %s O-csum=%d (+%zd)\n",
+			  pp->name, icmph->check,
+			  (char *)&(icmph->check) - (char *)icmph);
+	}
+	return 1;
+}
+
+static int
+icmp_dnat_handler(struct sk_buff *skb,
+		 struct ip_vs_protocol *pp, struct ip_vs_conn *cp)
+{
+	struct icmphdr *icmph;
+	unsigned int icmphoff;
+	int oldlen;
+
+#ifdef CONFIG_IP_VS_IPV6
+	if (cp->af == AF_INET6)
+		icmphoff = sizeof(struct ipv6hdr);
+	else
+#endif
+		icmphoff = ip_hdrlen(skb);
+	oldlen = skb->len - icmphoff;
+
+	/* csum_check requires unshared skb */
+	if (!skb_make_writable(skb, icmphoff + sizeof(*icmph)))
+		return 0;
+
+	if (unlikely(cp->app != NULL)) {
+		/* Some checks before mangling */
+		if (pp->csum_check && !pp->csum_check(cp->af, skb, pp))
+			return 0;
+
+		/*
+		 *      Attempt ip_vs_app call.
+		 *      It will fix ip_vs_conn
+		 */
+		if (!ip_vs_app_pkt_in(cp, skb))
+			return 0;
+	}
+
+	icmph = (void *)skb_network_header(skb) + icmphoff;
+	icmph->source = cp->lport;
+	icmph->dest = cp->dport;
+
+	/*
+	 *      Adjust ICMP checksums
+	 */
+	if (skb->ip_summed == CHECKSUM_PARTIAL) {
+		icmp_partial_csum_update(cp->af, icmph, &cp->vaddr, &cp->daddr,
+					htons(oldlen),
+					htons(skb->len - icmphoff));
+		icmp_partial_csum_update(cp->af, icmph, &cp->caddr, &cp->laddr,
+					htons(oldlen),
+					htons(skb->len - icmphoff));
+	} else if (!cp->app && (icmph->check != 0)) {
+		/* Only port and addr are changed, do fast csum update */
+		icmp_fast_csum_update(cp->af, icmph, &cp->vaddr, &cp->daddr,
+				     cp->vport, cp->dport);
+		icmp_fast_csum_update(cp->af, icmph, &cp->caddr, &cp->laddr,
+				     cp->cport, cp->lport);
+		if (skb->ip_summed == CHECKSUM_COMPLETE)
+			skb->ip_summed = CHECKSUM_NONE;
+	} else {
+		/* full checksum calculation */
+		icmph->check = 0;
+		skb->csum = skb_checksum(skb, icmphoff, skb->len - icmphoff, 0);
+#ifdef CONFIG_IP_VS_IPV6
+		if (cp->af == AF_INET6)
+			icmph->check = csum_ipv6_magic(&cp->caddr.in6,
+						      &cp->daddr.in6,
+						      skb->len - icmphoff,
+						      cp->protocol, skb->csum);
+		else
+#endif
+			icmph->check = csum_tcpicmp_magic(cp->caddr.ip,
+							cp->daddr.ip,
+							skb->len - icmphoff,
+							cp->protocol,
+							skb->csum);
+		if (icmph->check == 0)
+			icmph->check = CSUM_MANGLED_0;
+		skb->ip_summed = CHECKSUM_UNNECESSARY;
+	}
+	return 1;
+}
+
+static int
+icmp_csum_check(int af, struct sk_buff *skb, struct ip_vs_protocol *pp)
+{
+	struct icmphdr _icmph, *uh;
+	unsigned int icmphoff;
+
+#ifdef CONFIG_IP_VS_IPV6
+	if (af == AF_INET6)
+		icmphoff = sizeof(struct ipv6hdr);
+	else
+#endif
+		icmphoff = ip_hdrlen(skb);
+
+	uh = skb_header_pointer(skb, icmphoff, sizeof(_icmph), &_icmph);
+	if (uh == NULL)
+		return 0;
+
+	if (uh->check != 0) {
+		switch (skb->ip_summed) {
+		case CHECKSUM_NONE:
+			skb->csum = skb_checksum(skb, icmphoff,
+						 skb->len - icmphoff, 0);
+		case CHECKSUM_COMPLETE:
+#ifdef CONFIG_IP_VS_IPV6
+			if (af == AF_INET6) {
+				if (csum_ipv6_magic(&ipv6_hdr(skb)->saddr,
+						    &ipv6_hdr(skb)->daddr,
+						    skb->len - icmphoff,
+						    ipv6_hdr(skb)->nexthdr,
+						    skb->csum)) {
+					IP_VS_DBG_RL_PKT(0, pp, skb, 0,
+							 "Failed checksum for");
+					return 0;
+				}
+			} else
+#endif
+			if (csum_tcpicmp_magic(ip_hdr(skb)->saddr,
+						      ip_hdr(skb)->
+						      daddr,
+						      skb->len -
+						      icmphoff,
+						      ip_hdr(skb)->
+						      protocol, skb->csum)) {
+				IP_VS_DBG_RL_PKT(0, pp, skb, 0,
+						 "Failed checksum for");
+				return 0;
+			}
+			break;
+		default:
+			/* No need to checksum. */
+			break;
+		}
+	}
+	return 1;
+}
+
+/*
+ *	Note: the caller guarantees that only one of register_app,
+ *	unregister_app or app_conn_bind is called each time.
+ */
+
+#define	ICMP_APP_TAB_BITS	4
+#define	ICMP_APP_TAB_SIZE	(1 << ICMP_APP_TAB_BITS)
+#define	ICMP_APP_TAB_MASK	(ICMP_APP_TAB_SIZE - 1)
+
+static struct list_head icmp_apps[ICMP_APP_TAB_SIZE];
+static DEFINE_SPINLOCK(icmp_app_lock);
+
+static inline __u16 icmp_app_hashkey(__be16 port)
+{
+	return (((__force u16) port >> ICMP_APP_TAB_BITS) ^ (__force u16) port)
+	    & ICMP_APP_TAB_MASK;
+}
+
+static int icmp_register_app(struct ip_vs_app *inc)
+{
+	struct ip_vs_app *i;
+	__u16 hash;
+	__be16 port = inc->port;
+	int ret = 0;
+
+	hash = icmp_app_hashkey(port);
+
+	spin_lock_bh(&icmp_app_lock);
+	list_for_each_entry(i, &icmp_apps[hash], p_list) {
+		if (i->port == port) {
+			ret = -EEXIST;
+			goto out;
+		}
+	}
+	list_add(&inc->p_list, &icmp_apps[hash]);
+	atomic_inc(&ip_vs_protocol_icmp.appcnt);
+
+      out:
+	spin_unlock_bh(&icmp_app_lock);
+	return ret;
+}
+
+static void icmp_unregister_app(struct ip_vs_app *inc)
+{
+	spin_lock_bh(&icmp_app_lock);
+	atomic_dec(&ip_vs_protocol_icmp.appcnt);
+	list_del(&inc->p_list);
+	spin_unlock_bh(&icmp_app_lock);
+}
+
+static int icmp_app_conn_bind(struct ip_vs_conn *cp)
+{
+	int hash;
+	struct ip_vs_app *inc;
+	int result = 0;
+
+	/* Default binding: bind app only for NAT */
+	if (IP_VS_FWD_METHOD(cp) != IP_VS_CONN_F_MASQ)
+		return 0;
+
+	/* Lookup application incarnations and bind the right one */
+	hash = icmp_app_hashkey(cp->vport);
+
+	spin_lock(&icmp_app_lock);
+	list_for_each_entry(inc, &icmp_apps[hash], p_list) {
+		if (inc->port == cp->vport) {
+			if (unlikely(!ip_vs_app_inc_get(inc)))
+				break;
+			spin_unlock(&icmp_app_lock);
+
+			IP_VS_DBG_BUF(9, "%s(): Binding conn %s:%u->"
+				      "%s:%u to app %s on port %u\n",
+				      __func__,
+				      IP_VS_DBG_ADDR(cp->af, &cp->caddr),
+				      ntohs(cp->cport),
+				      IP_VS_DBG_ADDR(cp->af, &cp->vaddr),
+				      ntohs(cp->vport),
+				      inc->name, ntohs(inc->port));
+
+			cp->app = inc;
+			if (inc->init_conn)
+				result = inc->init_conn(inc, cp);
+			goto out;
+		}
+	}
+	spin_unlock(&icmp_app_lock);
+
+      out:
+	return result;
+}
+
+static int icmp_timeouts[IP_VS_ICMP_S_LAST + 1] = {
+	[IP_VS_ICMP_S_NORMAL] = 5 * 60 * HZ,
+	[IP_VS_ICMP_S_LAST] = 2 * HZ,
+};
+
+static const char *const icmp_state_name_table[IP_VS_ICMP_S_LAST + 1] = {
+	[IP_VS_ICMP_S_NORMAL] = "ICMP",
+	[IP_VS_ICMP_S_LAST] = "BUG!",
+};
+
+static int icmp_set_state_timeout(struct ip_vs_protocol *pp, char *sname, int to)
+{
+	return ip_vs_set_state_timeout(pp->timeout_table, IP_VS_ICMP_S_LAST,
+				       icmp_state_name_table, sname, to);
+}
+
+static const char *icmp_state_name(int state)
+{
+	if (state >= IP_VS_ICMP_S_LAST)
+		return "ERR!";
+	return icmp_state_name_table[state] ? icmp_state_name_table[state] : "?";
+}
+
+static int
+icmp_state_transition(struct ip_vs_conn *cp, int direction,
+		     const struct sk_buff *skb, struct ip_vs_protocol *pp)
+{
+	cp->timeout = pp->timeout_table[IP_VS_ICMP_S_NORMAL];
+	return 1;
+}
+
+static void icmp_init(struct ip_vs_protocol *pp)
+{
+	IP_VS_INIT_HASH_TABLE(icmp_apps);
+	pp->timeout_table = icmp_timeouts;
+}
+
+static void icmp_exit(struct ip_vs_protocol *pp)
+{
+}
+
+
+
+
+static void
+ip_vs_icmp_debug_packet_v4(struct ip_vs_protocol *pp, const struct sk_buff *skb,
+		       int offset, const char *msg)
+{
+	char buf[256];
+	struct iphdr *iph;
+	struct icmphdr _icmph, *ic;
+
+
+	iph = ip_hdr(skb);
+	offset = ihl = iph->ihl * 4;
+	ic = skb_header_pointer(skb, offset, sizeof(_icmph), &_icmph);
+	if (ic == NULL)
+		sprintf(buf, "%s TRUNCATED", pp->name);
+	else
+		sprintf(buf, "%s ICMP (%d,%d) %pI4->%pI4", ic->type, ntohs(icmp_id(ic)), 
+			&iph->saddr, &iph->daddr);
+
+	pr_debug("%s: %s\n", msg, buf);
+}
+
+#ifdef CONFIG_IP_VS_IPV6
+static void
+ip_vs_icmp_debug_packet_v6(struct ip_vs_protocol *pp, const struct sk_buff *skb,
+		       int offset, const char *msg)
+{
+	char buf[256];
+	struct ipv6hdr *iph;
+	struct icmp6hdr _icmph, *ic;
+
+	iph = ipv6_hdr(skb);
+	offset = sizeof(struct ipv6hdr);
+	ic = skb_header_pointer(skb, offset, sizeof(_icmph), &_icmph);
+	if (ic == NULL)
+		sprintf(buf, "%s TRUNCATED", pp->name);
+	else
+		sprintf(buf, "%s ICMPv6 (%d,%d) %pI6->%pI6", pp->name, ic->icmp6_type,
+			ntohs(icmpv6_id(ic)), &iph->saddr, &iph->daddr);
+	pr_debug("%s: %s\n", msg, buf);
+}
+#endif
+
+
+
+
+static void
+ip_vs_icmp_debug_packet(struct ip_vs_protocol *pp, const struct sk_buff *skb,
+		    int offset, const char *msg)
+{
+#ifdef CONFIG_IP_VS_IPV6
+	if (skb->protocol == htons(ETH_P_IPV6))
+		ip_vs_icmp_debug_packet_v6(pp, skb, offset, msg);
+	else
+#endif
+		ip_vs_icmp_debug_packet_v4(pp, skb, offset, msg);
+}
+
+
+struct ip_vs_protocol ip_vs_protocol_icmp = {
+	.name = "ICMP",
+	.protocol = IPPROTO_ICMP,
+	.num_states = IP_VS_ICMP_S_LAST,
+	.dont_defrag = 0,
+	.init = icmp_init,
+	.exit = icmp_exit,
+	.conn_schedule = icmp_conn_schedule,
+	.conn_in_get = icmp_conn_in_get,
+	.conn_out_get = icmp_conn_out_get,
+	.snat_handler = icmp_snat_handler,
+	.dnat_handler = icmp_dnat_handler,
+	.csum_check = icmp_csum_check,
+	.state_transition = icmp_state_transition,
+	.state_name = icmp_state_name,
+	.register_app = icmp_register_app,
+	.unregister_app = icmp_unregister_app,
+	.app_conn_bind = icmp_app_conn_bind,
+	.debug_packet = ip_vs_icmp_debug_packet,
+	.timeout_change = NULL,
+	.set_state_timeout = icmp_set_state_timeout,
+};
diff --git a/net/netfilter/ipvs/ip_vs_proto_sctp.c b/net/netfilter/ipvs/ip_vs_proto_sctp.c
old mode 100644
new mode 100755
index 2f982a4..4b85c7a
--- a/net/netfilter/ipvs/ip_vs_proto_sctp.c
+++ b/net/netfilter/ipvs/ip_vs_proto_sctp.c
@@ -44,7 +44,7 @@ sctp_conn_schedule(int af, struct sk_buff *skb, struct ip_vs_protocol *pp,
 		 * Let the virtual server select a real server for the
 		 * incoming connection, and create a connection entry.
 		 */
-		*cpp = ip_vs_schedule(svc, skb);
+		*cpp = ip_vs_schedule(svc, skb, 0);
 		if (!*cpp) {
 			*verdict = ip_vs_leave(svc, skb, pp);
 			return 0;
diff --git a/net/netfilter/ipvs/ip_vs_proto_tcp.c b/net/netfilter/ipvs/ip_vs_proto_tcp.c
old mode 100644
new mode 100755
index 282d24d..5ee2482
--- a/net/netfilter/ipvs/ip_vs_proto_tcp.c
+++ b/net/netfilter/ipvs/ip_vs_proto_tcp.c
@@ -10,7 +10,11 @@
  *              2 of the License, or (at your option) any later version.
  *
  * Changes:
+ *	Yi Yang      <specific@gmail.com>
+ *	Jiajun Chen  <mofan.cjj@taobao.com>
+ *	Jiaming Wu   <pukong.wjm@taobao.com>	support FULLNAT and SYNPROXY
  *
+ *   	Yu Bo        <yubo@xiaomi.com>
  */
 
 #define KMSG_COMPONENT "IPVS"
@@ -21,11 +25,18 @@
 #include <linux/tcp.h>                  /* for tcphdr */
 #include <net/ip.h>
 #include <net/tcp.h>                    /* for csum_tcpudp_magic */
-#include <net/ip6_checksum.h>
 #include <linux/netfilter.h>
 #include <linux/netfilter_ipv4.h>
+#include <net/secure_seq.h>
+
+#ifdef CONFIG_IP_VS_IPV6
+#include <net/ipv6.h>
+#include <net/ip6_checksum.h>
+#endif
+
 
 #include <net/ip_vs.h>
+#include <net/ip_vs_synproxy.h>
 
 static int
 tcp_conn_schedule(int af, struct sk_buff *skb, struct ip_vs_protocol *pp,
@@ -43,7 +54,37 @@ tcp_conn_schedule(int af, struct sk_buff *skb, struct ip_vs_protocol *pp,
 		return 0;
 	}
 
-	if (th->syn &&
+
+	/*
+	 * Syn-proxy step 2 logic: receive client's
+	 * 3-handshake Ack packet
+	 */
+	if (ip_vs_synproxy_ack_rcv(af, skb, th, pp, cpp, &iph, verdict) == 0) {
+		return 0;
+	}
+
+
+	if( af & IP_VS_CONN_F_DSNAT ){
+		if (th->syn &&
+			(svc = ip_vs_service_get(af,
+			skb->mark, iph.protocol, &iph.daddr,th->dest))) {
+			if (ip_vs_todrop()) {
+				ip_vs_service_put(svc);
+				*verdict = NF_DROP;
+				return 0;
+			}
+			*cpp = ip_vs_schedule(svc, skb, 0);
+			if (!*cpp) {
+				*verdict = ip_vs_leave(svc, skb, pp);
+				return 0;
+			}
+			ip_vs_service_put(svc);
+		}
+		return 1;
+	}
+
+
+	if (th->syn && !th->ack && !th->fin && !th->rst &&
 	    (svc = ip_vs_service_get(af, skb->mark, iph.protocol, &iph.daddr,
 				     th->dest))) {
 		if (ip_vs_todrop()) {
@@ -60,12 +101,21 @@ tcp_conn_schedule(int af, struct sk_buff *skb, struct ip_vs_protocol *pp,
 		 * Let the virtual server select a real server for the
 		 * incoming connection, and create a connection entry.
 		 */
-		*cpp = ip_vs_schedule(svc, skb);
+		*cpp = ip_vs_schedule(svc, skb, 0);
 		if (!*cpp) {
 			*verdict = ip_vs_leave(svc, skb, pp);
 			return 0;
 		}
 		ip_vs_service_put(svc);
+		return 1;
+	}
+
+	/* drop tcp packet which send to vip and !vport */
+	if (sysctl_ip_vs_tcp_drop_entry &&
+	    (svc = ip_vs_lookup_vip(af, iph.protocol, &iph.daddr))) {
+		IP_VS_INC_ESTATS(ip_vs_esmib, DEFENCE_TCP_DROP);
+		*verdict = NF_DROP;
+		return 0;
 	}
 	return 1;
 }
@@ -80,15 +130,21 @@ tcp_fast_csum_update(int af, struct tcphdr *tcph,
 #ifdef CONFIG_IP_VS_IPV6
 	if (af == AF_INET6)
 		tcph->check =
-			csum_fold(ip_vs_check_diff16(oldip->ip6, newip->ip6,
-					 ip_vs_check_diff2(oldport, newport,
-						~csum_unfold(tcph->check))));
+			csum_fold(ip_vs_check_diff16(oldip->ip6, newip->ip6,
+					 ip_vs_check_diff2(oldport, newport,
+						~csum_unfold(tcph->check))));
+
+
+
 	else
 #endif
-	tcph->check =
-		csum_fold(ip_vs_check_diff4(oldip->ip, newip->ip,
-				 ip_vs_check_diff2(oldport, newport,
-						~csum_unfold(tcph->check))));
+	tcph->check =
+		csum_fold(ip_vs_check_diff4(oldip->ip, newip->ip,
+				 ip_vs_check_diff2(oldport, newport,
+						~csum_unfold(tcph->check))));
+
+
+
 }
 
 
@@ -101,17 +157,158 @@ tcp_partial_csum_update(int af, struct tcphdr *tcph,
 #ifdef CONFIG_IP_VS_IPV6
 	if (af == AF_INET6)
 		tcph->check =
-			csum_fold(ip_vs_check_diff16(oldip->ip6, newip->ip6,
-					 ip_vs_check_diff2(oldlen, newlen,
-						~csum_unfold(tcph->check))));
+			csum_fold(ip_vs_check_diff16(oldip->ip6, newip->ip6,
+					 ip_vs_check_diff2(oldlen, newlen,
+						~csum_unfold(tcph->check))));
+
+
+
 	else
 #endif
-	tcph->check =
-		csum_fold(ip_vs_check_diff4(oldip->ip, newip->ip,
-				ip_vs_check_diff2(oldlen, newlen,
-						~csum_unfold(tcph->check))));
+	tcph->check =
+		csum_fold(ip_vs_check_diff4(oldip->ip, newip->ip,
+				ip_vs_check_diff2(oldlen, newlen,
+						~csum_unfold(tcph->check))));
+
+
+
+}
+
+/* adjust tcp opt mss, sub TCPOLEN_CIP */
+static void tcp_opt_adjust_mss(struct tcphdr *tcph)
+{
+	unsigned char *ptr;
+	int length;
+
+	if (sysctl_ip_vs_mss_adjust_entry == 0)
+		return;
+
+	ptr = (unsigned char *)(tcph + 1);
+	length = (tcph->doff * 4) - sizeof(struct tcphdr);
+
+	while (length > 0) {
+		int opcode = *ptr++;
+		int opsize;
+
+		switch (opcode) {
+		case TCPOPT_EOL:
+			return;
+		case TCPOPT_NOP:	/* Ref: RFC 793 section 3.1 */
+			length--;
+			continue;
+		default:
+			opsize = *ptr++;
+			if (opsize < 2)	/* "silly options" */
+				return;
+			if (opsize > length)
+				return;	/* don't parse partial options */
+			if ((opcode == TCPOPT_MSS) && (opsize == TCPOLEN_MSS)) {
+				__u16 in_mss = ntohs(*(__u16 *) ptr);
+				in_mss -= TCPOLEN_ADDR;
+				*((__u16 *) ptr) = htons(in_mss);	/* set mss, 16bit */
+				return;
+			}
+
+			ptr += opsize - 2;
+			length -= opsize;
+		}
+	}
 }
 
+/* save tcp sequense for fullnat/nat, INside to OUTside */
+static void
+tcp_save_out_seq(struct sk_buff *skb, struct ip_vs_conn *cp,
+		 struct tcphdr *th, int ihl)
+{
+	if (unlikely(th == NULL) || unlikely(cp == NULL) ||
+	    unlikely(skb == NULL))
+		return;
+
+	if (sysctl_ip_vs_conn_expire_tcp_rst && !th->rst) {
+
+		/* seq out of order. just skip */
+		if (before(ntohl(th->ack_seq), ntohl(cp->rs_ack_seq)) &&
+							(cp->rs_ack_seq != 0))
+			return;
+
+		if (th->syn && th->ack)
+			cp->rs_end_seq = htonl(ntohl(th->seq) + 1);
+		else
+			cp->rs_end_seq = htonl(ntohl(th->seq) + skb->len
+					       - ihl - (th->doff << 2));
+		cp->rs_ack_seq = th->ack_seq;
+		IP_VS_DBG_RL("packet from RS, seq:%u ack_seq:%u.",
+			     ntohl(th->seq), ntohl(th->ack_seq));
+		IP_VS_DBG_RL("port:%u->%u", ntohs(th->source), ntohs(th->dest));
+	}
+}
+
+/*
+ * 1. adjust tcp ack/sack sequence for FULL-NAT, INside to OUTside
+ * 2. adjust tcp sequence for SYNPROXY, OUTside to INside
+ */
+static int tcp_out_adjust_seq(struct ip_vs_conn *cp, struct tcphdr *tcph)
+{
+	__u8 i;
+	__u8 *ptr;
+	int length;
+
+	/*
+	 * Syn-proxy seq change, include tcp hdr and
+	 * check ack storm.
+	 */
+	if (ip_vs_synproxy_snat_handler(tcph, cp) == 0) {
+		return 0;
+	}
+
+	/*
+	 * FULLNAT ack-seq change
+	 */
+
+	/* adjust ack sequence */
+	tcph->ack_seq = htonl(ntohl(tcph->ack_seq) - cp->fnat_seq.delta);
+
+	/* adjust sack sequence */
+	ptr = (__u8 *) (tcph + 1);
+	length = (tcph->doff * 4) - sizeof(struct tcphdr);
+
+	while (length > 0) {
+		int opcode = *ptr++;
+		int opsize;
+
+		switch (opcode) {
+		case TCPOPT_EOL:
+			return 1;
+		case TCPOPT_NOP:	/* Ref: RFC 793 section 3.1 */
+			length--;
+			continue;
+		default:
+			opsize = *ptr++;
+			if (opsize < 2)	/* "silly options" */
+				return 1;
+			if (opsize > length)
+				return 1;	/* don't parse partial options */
+			if ((opcode == TCPOPT_SACK) &&
+			    (opsize >=
+			     (TCPOLEN_SACK_BASE + TCPOLEN_SACK_PERBLOCK))
+			    && !((opsize - TCPOLEN_SACK_BASE) %
+				 TCPOLEN_SACK_PERBLOCK)) {
+				for (i = 0; i < opsize - TCPOLEN_SACK_BASE;
+				     i += 4) {
+					*((__u32 *) ptr + i) =
+					    htonl(ntohl(*((__u32 *) ptr + i)) -
+						  cp->fnat_seq.delta);
+				}
+				return 1;
+			}
+
+			ptr += opsize - 2;
+			length -= opsize;
+		}
+	}
+
+	return 1;
+}
 
 static int
 tcp_snat_handler(struct sk_buff *skb,
@@ -144,8 +341,17 @@ tcp_snat_handler(struct sk_buff *skb,
 	}
 
 	tcph = (void *)skb_network_header(skb) + tcphoff;
+	tcp_save_out_seq(skb, cp, tcph, tcphoff);
 	tcph->source = cp->vport;
 
+	/*
+	 * Syn-proxy seq change, include tcp hdr and
+	 * check ack storm.
+	 */
+	if (ip_vs_synproxy_snat_handler(tcph, cp) == 0) {
+		return 0;
+	}
+
 	/* Adjust TCP checksums */
 	if (skb->ip_summed == CHECKSUM_PARTIAL) {
 		tcp_partial_csum_update(cp->af, tcph, &cp->daddr, &cp->vaddr,
@@ -182,6 +388,294 @@ tcp_snat_handler(struct sk_buff *skb,
 	return 1;
 }
 
+static int
+tcp_fnat_out_handler(struct sk_buff *skb,
+		     struct ip_vs_protocol *pp, struct ip_vs_conn *cp)
+{
+	struct tcphdr *tcph;
+	unsigned int tcphoff;
+	int oldlen;
+
+#ifdef CONFIG_IP_VS_IPV6
+	if (cp->af == AF_INET6)
+		tcphoff = sizeof(struct ipv6hdr);
+	else
+#endif
+		tcphoff = ip_hdrlen(skb);
+	oldlen = skb->len - tcphoff;
+
+	/* csum_check requires unshared skb */
+	if (!skb_make_writable(skb, tcphoff + sizeof(*tcph)))
+		return 0;
+
+	if (unlikely(cp->app != NULL)) {
+		/* Some checks before mangling */
+		if (pp->csum_check && !pp->csum_check(cp->af, skb, pp))
+			return 0;
+
+		/* Call application helper if needed */
+		if (!ip_vs_app_pkt_out(cp, skb))
+			return 0;
+	}
+
+	tcph = (void *)skb_network_header(skb) + tcphoff;
+	tcp_save_out_seq(skb, cp, tcph, tcphoff);
+	tcph->source = cp->vport;
+	tcph->dest = cp->cport;
+
+	/*
+	 * adjust tcp opt mss in rs->client syn_ack packet
+	 */
+	if (tcph->syn && tcph->ack) {
+		tcp_opt_adjust_mss(tcph);
+	}
+
+	/* adjust tcp ack/sack sequence */
+	if (tcp_out_adjust_seq(cp, tcph) == 0) {
+		return 0;
+	}
+
+	/* full checksum calculation */
+	tcph->check = 0;
+	skb->csum = skb_checksum(skb, tcphoff, skb->len - tcphoff, 0);
+#ifdef CONFIG_IP_VS_IPV6
+	if (cp->af == AF_INET6)
+		tcph->check = csum_ipv6_magic(&cp->vaddr.in6,
+					      &cp->caddr.in6,
+					      skb->len - tcphoff,
+					      cp->protocol, skb->csum);
+	else
+#endif
+		tcph->check = csum_tcpudp_magic(cp->vaddr.ip,
+						cp->caddr.ip,
+						skb->len - tcphoff,
+						cp->protocol, skb->csum);
+
+	IP_VS_DBG(11, "O-pkt: %s O-csum=%d (+%zd)\n",
+		  pp->name, tcph->check, (char *)&(tcph->check) - (char *)tcph);
+
+	return 1;
+}
+
+/*
+ * remove tcp timestamp opt in one packet, just set it to TCPOPT_NOP
+ * reference to tcp_parse_options in tcp_input.c
+ */
+static void tcp_opt_remove_timestamp(struct tcphdr *tcph)
+{
+	unsigned char *ptr;
+	int length;
+	int i;
+
+	if (sysctl_ip_vs_timestamp_remove_entry == 0)
+		return;
+
+	ptr = (unsigned char *)(tcph + 1);
+	length = (tcph->doff * 4) - sizeof(struct tcphdr);
+
+	while (length > 0) {
+		int opcode = *ptr++;
+		int opsize;
+
+		switch (opcode) {
+		case TCPOPT_EOL:
+			return;
+		case TCPOPT_NOP:	/* Ref: RFC 793 section 3.1 */
+			length--;
+			continue;
+		default:
+			opsize = *ptr++;
+			if (opsize < 2)	/* "silly options" */
+				return;
+			if (opsize > length)
+				return;	/* don't parse partial options */
+			if ((opcode == TCPOPT_TIMESTAMP)
+			    && (opsize == TCPOLEN_TIMESTAMP)) {
+				for (i = 0; i < TCPOLEN_TIMESTAMP; i++) {
+					*(ptr - 2 + i) = TCPOPT_NOP;	/* TCPOPT_NOP replace timestamp opt */
+				}
+				return;
+			}
+
+			ptr += opsize - 2;
+			length -= opsize;
+		}
+	}
+}
+
+/*
+ * 1. recompute tcp sequence, OUTside to INside;
+ * 2. init first data sequence;
+ */
+static void
+tcp_in_init_seq(struct ip_vs_conn *cp, struct sk_buff *skb, struct tcphdr *tcph)
+{
+	struct ip_vs_seq *fseq = &(cp->fnat_seq);
+	__u32 seq = ntohl(tcph->seq);
+	int conn_reused_entry;
+
+	/* init first data seq and reset toa flag */
+	fseq->fdata_seq = seq + 1;
+	cp->flags &= ~IP_VS_CONN_F_CIP_INSERTED;
+
+	/* init syn seq, lvs2rs */
+	conn_reused_entry = (sysctl_ip_vs_conn_reused_entry == 1)
+	    && (fseq->init_seq != 0)
+	    && ((cp->state == IP_VS_TCP_S_SYN_RECV)
+		|| (cp->state == IP_VS_TCP_S_SYN_SENT));
+	if ((fseq->init_seq == 0) || conn_reused_entry) {
+#ifdef CONFIG_IP_VS_IPV6
+		if (cp->af == AF_INET6)
+			fseq->init_seq =
+			    secure_tcpv6_sequence_number(cp->laddr.ip6,
+							 cp->daddr.ip6,
+							 cp->lport, cp->dport);
+		else
+#endif
+			fseq->init_seq =
+			    secure_tcp_sequence_number(cp->laddr.ip,
+						       cp->daddr.ip, cp->lport,
+						       cp->dport);
+		fseq->delta = fseq->init_seq - seq;
+
+		if (conn_reused_entry) {
+			IP_VS_INC_ESTATS(ip_vs_esmib, FULLNAT_CONN_REUSED);
+			switch (cp->old_state) {
+			case IP_VS_TCP_S_CLOSE:
+				IP_VS_INC_ESTATS(ip_vs_esmib,
+						 FULLNAT_CONN_REUSED_CLOSE);
+				break;
+			case IP_VS_TCP_S_TIME_WAIT:
+				IP_VS_INC_ESTATS(ip_vs_esmib,
+						 FULLNAT_CONN_REUSED_TIMEWAIT);
+				break;
+			case IP_VS_TCP_S_FIN_WAIT:
+				IP_VS_INC_ESTATS(ip_vs_esmib,
+						 FULLNAT_CONN_REUSED_FINWAIT);
+				break;
+			case IP_VS_TCP_S_CLOSE_WAIT:
+				IP_VS_INC_ESTATS(ip_vs_esmib,
+						 FULLNAT_CONN_REUSED_CLOSEWAIT);
+				break;
+			case IP_VS_TCP_S_LAST_ACK:
+				IP_VS_INC_ESTATS(ip_vs_esmib,
+						 FULLNAT_CONN_REUSED_LASTACK);
+				break;
+			case IP_VS_TCP_S_ESTABLISHED:
+				IP_VS_INC_ESTATS(ip_vs_esmib,
+						 FULLNAT_CONN_REUSED_ESTAB);
+				break;
+			}
+		}
+	}
+}
+
+/* adjust tcp sequence, OUTside to INside */
+static void tcp_in_adjust_seq(struct ip_vs_conn *cp, struct tcphdr *tcph)
+{
+	/* adjust seq for FULLNAT */
+	tcph->seq = htonl(ntohl(tcph->seq) + cp->fnat_seq.delta);
+
+	/* adjust ack_seq for SYNPROXY, include tcp hdr and sack opt */
+	ip_vs_synproxy_dnat_handler(tcph, &cp->syn_proxy_seq);
+}
+
+/*
+ * add client address in tcp option
+ * alloc a new skb, and free the old skb
+ * return new skb
+ */
+static struct sk_buff *tcp_opt_add_toa(struct ip_vs_conn *cp,
+				       struct sk_buff *old_skb,
+				       struct tcphdr **tcph)
+{
+	__u32 mtu;
+	struct sk_buff *new_skb = NULL;
+	struct ip_vs_tcpo_addr *toa;
+	struct ip_vs_seq *fseq = &(cp->fnat_seq);
+	__u32 seq = ntohl((*tcph)->seq);
+	unsigned int tcphoff;
+	struct tcphdr *th;
+	__u8 *p, *q;
+
+	/* now only process IPV4 */
+	if (cp->af != AF_INET) {
+		IP_VS_INC_ESTATS(ip_vs_esmib, FULLNAT_ADD_TOA_FAIL_PROTO);
+		return old_skb;
+	}
+
+	/* stop insert tcp option address here */
+	if (after(seq, fseq->fdata_seq)) {
+		cp->flags |= IP_VS_CONN_F_CIP_INSERTED;
+		return old_skb;
+	}
+
+	/* skb length checking */
+	mtu = dst_mtu((struct dst_entry *)old_skb->_skb_dst);
+	if (old_skb->len > (mtu - sizeof(struct ip_vs_tcpo_addr))) {
+		IP_VS_INC_ESTATS(ip_vs_esmib, FULLNAT_ADD_TOA_FAIL_LEN);
+		return old_skb;
+	}
+
+	/* copy all skb, plus ttm space , new skb is linear */
+	new_skb = skb_copy_expand(old_skb,
+				  skb_headroom(old_skb),
+				  skb_tailroom(old_skb) +
+				  sizeof(struct ip_vs_tcpo_addr), GFP_ATOMIC);
+	if (new_skb == NULL) {
+		IP_VS_INC_ESTATS(ip_vs_esmib, FULLNAT_ADD_TOA_FAIL_MEM);
+		return old_skb;
+	}
+
+	/* free old skb */
+	kfree_skb(old_skb);
+
+	/*
+	 * add client ip
+	 */
+	tcphoff = ip_hdrlen(new_skb);
+	/* get new tcp header */
+	*tcph = th =
+	    (struct tcphdr *)((void *)skb_network_header(new_skb) + tcphoff);
+
+	/* ptr to old opts */
+	p = skb_tail_pointer(new_skb) - 1;
+	q = p + sizeof(struct ip_vs_tcpo_addr);
+
+	/* move data down, offset is sizeof(struct ip_vs_tcpo_addr) */
+	while (p >= ((__u8 *) th + sizeof(struct tcphdr))) {
+		*q = *p;
+		p--;
+		q--;
+	}
+
+	/* move tail to new postion */
+	new_skb->tail += sizeof(struct ip_vs_tcpo_addr);
+
+	/* put client ip opt , ptr point to opts */
+	toa = (struct ip_vs_tcpo_addr *)(th + 1);
+	toa->opcode = TCPOPT_ADDR;
+	toa->opsize = TCPOLEN_ADDR;
+	toa->port = cp->cport;
+	toa->addr = cp->caddr.ip;
+
+	/* reset tcp header length */
+	th->doff += sizeof(struct ip_vs_tcpo_addr) / 4;
+	/* reset ip header totoal length */
+	ip_hdr(new_skb)->tot_len =
+	    htons(ntohs(ip_hdr(new_skb)->tot_len) +
+		  sizeof(struct ip_vs_tcpo_addr));
+	/* reset skb length */
+	new_skb->len += sizeof(struct ip_vs_tcpo_addr);
+
+	/* re-calculate tcp csum in tcp_fnat_in_handler */
+	/* re-calculate ip csum */
+	ip_send_check(ip_hdr(new_skb));
+
+	IP_VS_INC_ESTATS(ip_vs_esmib, FULLNAT_ADD_TOA_OK);
+
+	return new_skb;
+}
 
 static int
 tcp_dnat_handler(struct sk_buff *skb,
@@ -220,6 +714,11 @@ tcp_dnat_handler(struct sk_buff *skb,
 	tcph->dest = cp->dport;
 
 	/*
+	 * Syn-proxy ack_seq change, include tcp hdr and sack opt.
+	 */
+	ip_vs_synproxy_dnat_handler(tcph, &cp->syn_proxy_seq);
+
+	/*
 	 *	Adjust TCP checksums
 	 */
 	if (skb->ip_summed == CHECKSUM_PARTIAL) {
@@ -254,6 +753,328 @@ tcp_dnat_handler(struct sk_buff *skb,
 	return 1;
 }
 
+static int
+tcp_fnat_in_handler(struct sk_buff **skb_p,
+		    struct ip_vs_protocol *pp, struct ip_vs_conn *cp)
+{
+	struct tcphdr *tcph;
+	unsigned int tcphoff;
+	int oldlen;
+	struct sk_buff *skb = *skb_p;
+
+#ifdef CONFIG_IP_VS_IPV6
+	if (cp->af == AF_INET6)
+		tcphoff = sizeof(struct ipv6hdr);
+	else
+#endif
+		tcphoff = ip_hdrlen(skb);
+	oldlen = skb->len - tcphoff;
+
+	/* csum_check requires unshared skb */
+	if (!skb_make_writable(skb, tcphoff + sizeof(*tcph)))
+		return 0;
+
+	if (unlikely(cp->app != NULL)) {
+		/* Some checks before mangling */
+		if (pp->csum_check && !pp->csum_check(cp->af, skb, pp))
+			return 0;
+
+		/*
+		 *      Attempt ip_vs_app call.
+		 *      It will fix ip_vs_conn and iph ack_seq stuff
+		 */
+		if (!ip_vs_app_pkt_in(cp, skb))
+			return 0;
+	}
+
+	tcph = (void *)skb_network_header(skb) + tcphoff;
+	tcph->source = cp->lport;
+	tcph->dest = cp->dport;
+
+	/*
+	 * for syn packet
+	 * 1. remove tcp timestamp opt,
+	 *    because local address with diffrent client have the diffrent timestamp;
+	 * 2. recompute tcp sequence
+	 */
+	if (tcph->syn & !tcph->ack) {
+		tcp_opt_remove_timestamp(tcph);
+		tcp_in_init_seq(cp, skb, tcph);
+	}
+
+	/* TOA: add client ip */
+	if ((sysctl_ip_vs_toa_entry == 1)
+	    && !(cp->flags & IP_VS_CONN_F_CIP_INSERTED)
+	    && !tcph->rst && !tcph->fin) {
+		skb = *skb_p = tcp_opt_add_toa(cp, skb, &tcph);
+	}
+
+	/*
+	 * adjust tcp sequence, becase
+	 * 1. FULLNAT: local address with diffrent client have the diffrent sequence
+	 * 2. SYNPROXY: dont know rs->client synack sequence
+	 */
+	tcp_in_adjust_seq(cp, tcph);
+
+	/* full checksum calculation */
+	tcph->check = 0;
+	skb->csum = skb_checksum(skb, tcphoff, skb->len - tcphoff, 0);
+#ifdef CONFIG_IP_VS_IPV6
+	if (cp->af == AF_INET6)
+		tcph->check = csum_ipv6_magic(&cp->laddr.in6,
+					      &cp->daddr.in6,
+					      skb->len - tcphoff,
+					      cp->protocol, skb->csum);
+	else
+#endif
+		tcph->check = csum_tcpudp_magic(cp->laddr.ip,
+						cp->daddr.ip,
+						skb->len - tcphoff,
+						cp->protocol, skb->csum);
+	skb->ip_summed = CHECKSUM_UNNECESSARY;
+
+	return 1;
+}
+
+/* send reset packet to RS */
+static void tcp_send_rst_in(struct ip_vs_protocol *pp, struct ip_vs_conn *cp)
+{
+	struct sk_buff *skb = NULL;
+	struct sk_buff *tmp_skb = NULL;
+	struct tcphdr *th;
+	unsigned int tcphoff;
+
+	skb = alloc_skb(MAX_TCP_HEADER, GFP_ATOMIC);
+	if (unlikely(skb == NULL)) {
+		IP_VS_ERR_RL("alloc skb failed when send rs RST packet\n");
+		return;
+	}
+
+	skb_reserve(skb, MAX_TCP_HEADER);
+	th = (struct tcphdr *)skb_push(skb, sizeof(struct tcphdr));
+	skb_reset_transport_header(skb);
+	skb->csum = 0;
+
+	/* set tcp head */
+	memset(th, 0, sizeof(struct tcphdr));
+	th->source = cp->cport;
+	th->dest = cp->vport;
+
+	/* set the reset seq of tcp head */
+	if ((cp->state == IP_VS_TCP_S_SYN_SENT) &&
+			((tmp_skb = skb_dequeue(&cp->ack_skb)) != NULL)) {
+		struct tcphdr *tcph;
+#ifdef CONFIG_IP_VS_IPV6
+		if (cp->af == AF_INET6)
+			tcphoff = sizeof(struct ipv6hdr);
+		else
+#endif
+			tcphoff = ip_hdrlen(tmp_skb);
+		tcph = (void *)skb_network_header(tmp_skb) + tcphoff;
+
+		th->seq = tcph->seq;
+		/* put back. Just for sending reset packet to client */
+		skb_queue_head(&cp->ack_skb, tmp_skb);
+	} else if (cp->state == IP_VS_TCP_S_ESTABLISHED) {
+		th->seq = cp->rs_ack_seq;
+		/* Be careful! fullnat */
+		if (cp->flags & IP_VS_CONN_F_FULLNAT)
+			th->seq = htonl(ntohl(th->seq) - cp->fnat_seq.delta);
+	} else {
+		kfree_skb(skb);
+		IP_VS_DBG_RL("IPVS: Is SYN_SENT or ESTABLISHED ?");
+		return;
+	}
+
+	IP_VS_DBG_RL("IPVS: rst to rs seq: %u", htonl(th->seq));
+	th->ack_seq = 0;
+	th->doff = sizeof(struct tcphdr) >> 2;
+	th->rst = 1;
+
+	/*
+	 * Set ip hdr
+	 * Attention: set source and dest addr to ack skb's.
+	 * we rely on packet_xmit func to do NATs thing.
+	 */
+#ifdef CONFIG_IP_VS_IPV6
+	if (cp->af == AF_INET6) {
+		struct ipv6hdr *iph =
+		    (struct ipv6hdr *)skb_push(skb, sizeof(struct iphdr));
+
+		tcphoff = sizeof(struct ipv6hdr);
+		skb_reset_network_header(skb);
+		memcpy(&iph->saddr, &cp->caddr.in6, sizeof(struct in6_addr));
+		memcpy(&iph->daddr, &cp->vaddr.in6, sizeof(struct in6_addr));
+
+		iph->version = 6;
+		iph->nexthdr = NEXTHDR_TCP;
+		iph->hop_limit = IPV6_DEFAULT_HOPLIMIT;
+
+		th->check = 0;
+		skb->csum = skb_checksum(skb, tcphoff, skb->len - tcphoff, 0);
+		th->check = csum_ipv6_magic(&iph->saddr, &iph->daddr,
+					    skb->len - tcphoff,
+					    IPPROTO_TCP, skb->csum);
+	} else
+#endif
+	{
+		struct iphdr *iph =
+		    (struct iphdr *)skb_push(skb, sizeof(struct iphdr));
+
+		tcphoff = sizeof(struct iphdr);
+		skb_reset_network_header(skb);
+		iph->version = 4;
+		iph->ihl = 5;
+		iph->tot_len = htons(skb->len);
+		iph->frag_off = htons(IP_DF);
+		iph->ttl = IPDEFTTL;
+		iph->protocol = IPPROTO_TCP;
+		iph->saddr = cp->caddr.ip;
+		iph->daddr = cp->vaddr.ip;
+
+		ip_send_check(iph);
+
+		th->check = 0;
+		skb->csum = skb_checksum(skb, tcphoff, skb->len - tcphoff, 0);
+		th->check = csum_tcpudp_magic(iph->saddr, iph->daddr,
+					      skb->len - tcphoff,
+					      IPPROTO_TCP, skb->csum);
+	}
+
+	cp->packet_xmit(skb, cp, pp);
+}
+
+/* send reset packet to client */
+static void tcp_send_rst_out(struct ip_vs_protocol *pp, struct ip_vs_conn *cp)
+{
+	struct sk_buff *skb = NULL;
+	struct sk_buff *tmp_skb = NULL;
+	struct tcphdr *th;
+	unsigned int tcphoff;
+
+	skb = alloc_skb(MAX_TCP_HEADER, GFP_ATOMIC);
+	if (unlikely(skb == NULL)) {
+		IP_VS_ERR_RL("alloc skb failed when send client RST packet\n");
+		return;
+	}
+
+	skb_reserve(skb, MAX_TCP_HEADER);
+	th = (struct tcphdr *)skb_push(skb, sizeof(struct tcphdr));
+	skb_reset_transport_header(skb);
+	skb->csum = 0;
+
+	/* set tcp head */
+	memset(th, 0, sizeof(struct tcphdr));
+	th->source = cp->dport;
+	if (cp->flags & IP_VS_CONN_F_FULLNAT)
+		th->dest = cp->lport;
+	else
+		th->dest = cp->cport;
+
+	/* set the reset seq of tcp head*/
+	if ((cp->state == IP_VS_TCP_S_SYN_SENT) &&
+			((tmp_skb = skb_dequeue(&cp->ack_skb)) != NULL)) {
+		struct tcphdr *tcph;
+#ifdef CONFIG_IP_VS_IPV6
+		if (cp->af == AF_INET6)
+			tcphoff = sizeof(struct ipv6hdr);
+		else
+#endif
+			tcphoff = ip_hdrlen(tmp_skb);
+		tcph = (void *)skb_network_header(tmp_skb) + tcphoff;
+		/* Perhaps delta is 0 */
+		th->seq = htonl(ntohl(tcph->ack_seq) - cp->syn_proxy_seq.delta);
+		/* put back. Just for sending reset packet to RS */
+		skb_queue_head(&cp->ack_skb, tmp_skb);
+	} else if (cp->state == IP_VS_TCP_S_ESTABLISHED) {
+		th->seq = cp->rs_end_seq;
+	} else {
+		kfree_skb(skb);
+		IP_VS_DBG_RL("IPVS: Is in SYN_SENT or ESTABLISHED ?");
+		return;
+	}
+
+	IP_VS_DBG_RL("IPVS: rst to client seq: %u", htonl(th->seq));
+	th->ack_seq = 0;
+	th->doff = sizeof(struct tcphdr) >> 2;
+	th->rst = 1;
+
+	/*
+	 * Set ip hdr
+	 * Attention: set source and dest addr to ack skb's.
+	 * we rely on response_xmit func to do NATs thing.
+	 */
+#ifdef CONFIG_IP_VS_IPV6
+	if (cp->af == AF_INET6) {
+		struct ipv6hdr *iph =
+		    (struct ipv6hdr *)skb_push(skb, sizeof(struct iphdr));
+
+		tcphoff = sizeof(struct ipv6hdr);
+		skb_reset_network_header(skb);
+		memcpy(&iph->saddr, &cp->daddr.in6, sizeof(struct in6_addr));
+		memcpy(&iph->daddr, &cp->laddr.in6, sizeof(struct in6_addr));
+
+		iph->version = 6;
+		iph->nexthdr = NEXTHDR_TCP;
+		iph->hop_limit = IPV6_DEFAULT_HOPLIMIT;
+
+		th->check = 0;
+		skb->csum = skb_checksum(skb, tcphoff, skb->len - tcphoff, 0);
+		th->check = csum_ipv6_magic(&iph->saddr, &iph->daddr,
+					    skb->len - tcphoff,
+					    IPPROTO_TCP, skb->csum);
+
+		if (cp->flags & IP_VS_CONN_F_FULLNAT)
+			ip_vs_fnat_response_xmit_v6(skb, pp, cp,
+						    sizeof(struct ipv6hdr));
+		else
+			ip_vs_normal_response_xmit_v6(skb, pp, cp,
+						      sizeof(struct ipv6hdr));
+	} else
+#endif
+	{
+		struct iphdr *iph =
+		    (struct iphdr *)skb_push(skb, sizeof(struct iphdr));
+
+		tcphoff = sizeof(struct iphdr);
+		skb_reset_network_header(skb);
+		iph->version = 4;
+		iph->ihl = 5;
+		iph->tot_len = htons(skb->len);
+		iph->frag_off = htons(IP_DF);
+		iph->ttl = IPDEFTTL;
+		iph->protocol = IPPROTO_TCP;
+		iph->saddr = cp->daddr.ip;
+		iph->daddr = cp->laddr.ip;
+
+		ip_send_check(iph);
+
+		th->check = 0;
+		skb->csum = skb_checksum(skb, tcphoff, skb->len - tcphoff, 0);
+		th->check = csum_tcpudp_magic(iph->saddr, iph->daddr,
+					      skb->len - tcphoff,
+					      IPPROTO_TCP, skb->csum);
+
+		if (cp->flags & IP_VS_CONN_F_FULLNAT)
+			ip_vs_fnat_response_xmit(skb, pp, cp, iph->ihl << 2);
+		else
+			ip_vs_normal_response_xmit(skb, pp, cp, iph->ihl << 2);
+	}
+}
+
+static void
+tcp_conn_expire_handler(struct ip_vs_protocol *pp, struct ip_vs_conn *cp)
+{
+	/* support fullnat and nat */
+	if (sysctl_ip_vs_conn_expire_tcp_rst &&
+	    (cp->flags & (IP_VS_CONN_F_FULLNAT | IP_VS_CONN_F_MASQ))) {
+	    IP_VS_DBG(11, "tcp_conn_expire_handler cp->state[%d]\n",cp->state);
+		/* send reset packet to RS */
+		tcp_send_rst_in(pp, cp);
+		/* send reset packet to client */
+		tcp_send_rst_out(pp, cp);
+	}
+}
 
 static int
 tcp_csum_check(int af, struct sk_buff *skb, struct ip_vs_protocol *pp)
@@ -316,7 +1137,7 @@ static const int tcp_state_off[IP_VS_DIR_LAST] = {
 /*
  *	Timeout table[state]
  */
-static int tcp_timeouts[IP_VS_TCP_S_LAST+1] = {
+int sysctl_ip_vs_tcp_timeouts[IP_VS_TCP_S_LAST+1] = {
 	[IP_VS_TCP_S_NONE]		=	2*HZ,
 	[IP_VS_TCP_S_ESTABLISHED]	=	15*60*HZ,
 	[IP_VS_TCP_S_SYN_SENT]		=	2*60*HZ,
@@ -381,7 +1202,7 @@ static struct tcp_states_t tcp_states [] = {
 /*        sNO, sES, sSS, sSR, sFW, sTW, sCL, sCW, sLA, sLI, sSA	*/
 /*syn*/ {{sSS, sES, sSS, sSR, sSS, sSS, sSS, sSS, sSS, sLI, sSR }},
 /*fin*/ {{sTW, sFW, sSS, sTW, sFW, sTW, sCL, sTW, sLA, sLI, sTW }},
-/*ack*/ {{sES, sES, sSS, sES, sFW, sTW, sCL, sCW, sLA, sES, sES }},
+/*ack*/ {{sES, sES, sES, sES, sFW, sTW, sCL, sCW, sLA, sES, sES }},
 /*rst*/ {{sCL, sCL, sSS, sCL, sCL, sTW, sCL, sCL, sCL, sCL, sCL }},
 
 /*	INPUT-ONLY */
@@ -513,6 +1334,7 @@ set_tcp_state(struct ip_vs_protocol *pp, struct ip_vs_conn *cp,
 		}
 	}
 
+	cp->old_state = cp->state;	// old_state called when connection reused
 	cp->timeout = pp->timeout_table[cp->state = new_state];
 }
 
@@ -655,7 +1477,7 @@ void ip_vs_tcp_conn_listen(struct ip_vs_conn *cp)
 static void ip_vs_tcp_init(struct ip_vs_protocol *pp)
 {
 	IP_VS_INIT_HASH_TABLE(tcp_apps);
-	pp->timeout_table = tcp_timeouts;
+	pp->timeout_table = sysctl_ip_vs_tcp_timeouts;
 }
 
 
@@ -679,6 +1501,8 @@ struct ip_vs_protocol ip_vs_protocol_tcp = {
 	.conn_out_get =		ip_vs_conn_out_get_proto,
 	.snat_handler =		tcp_snat_handler,
 	.dnat_handler =		tcp_dnat_handler,
+	.fnat_in_handler =  	tcp_fnat_in_handler,
+	.fnat_out_handler = 	tcp_fnat_out_handler,
 	.csum_check =		tcp_csum_check,
 	.state_name =		tcp_state_name,
 	.state_transition =	tcp_state_transition,
@@ -686,4 +1510,5 @@ struct ip_vs_protocol ip_vs_protocol_tcp = {
 	.debug_packet =		ip_vs_tcpudp_debug_packet,
 	.timeout_change =	tcp_timeout_change,
 	.set_state_timeout =	tcp_set_state_timeout,
+	.conn_expire_handler = 	tcp_conn_expire_handler,
 };
diff --git a/net/netfilter/ipvs/ip_vs_proto_udp.c b/net/netfilter/ipvs/ip_vs_proto_udp.c
old mode 100644
new mode 100755
index 8553231..e4d3029
--- a/net/netfilter/ipvs/ip_vs_proto_udp.c
+++ b/net/netfilter/ipvs/ip_vs_proto_udp.c
@@ -60,7 +60,7 @@ udp_conn_schedule(int af, struct sk_buff *skb, struct ip_vs_protocol *pp,
 		 * Let the virtual server select a real server for the
 		 * incoming connection, and create a connection entry.
 		 */
-		*cpp = ip_vs_schedule(svc, skb);
+		*cpp = ip_vs_schedule(svc, skb, 0);
 		if (!*cpp) {
 			*verdict = ip_vs_leave(svc, skb, pp);
 			return 0;
@@ -148,6 +148,7 @@ udp_snat_handler(struct sk_buff *skb,
 
 	udph = (void *)skb_network_header(skb) + udphoff;
 	udph->source = cp->vport;
+	udph->dest = cp->cport;
 
 	/*
 	 *	Adjust UDP checksums
@@ -156,10 +157,15 @@ udp_snat_handler(struct sk_buff *skb,
 		udp_partial_csum_update(cp->af, udph, &cp->daddr, &cp->vaddr,
 					htons(oldlen),
 					htons(skb->len - udphoff));
+		udp_partial_csum_update(cp->af, udph, &cp->laddr, &cp->caddr,
+					htons(oldlen),
+					htons(skb->len - udphoff));
 	} else if (!cp->app && (udph->check != 0)) {
 		/* Only port and addr are changed, do fast csum update */
 		udp_fast_csum_update(cp->af, udph, &cp->daddr, &cp->vaddr,
 				     cp->dport, cp->vport);
+		udp_fast_csum_update(cp->af, udph, &cp->laddr, &cp->caddr,
+				     cp->lport, cp->cport);
 		if (skb->ip_summed == CHECKSUM_COMPLETE)
 			skb->ip_summed = CHECKSUM_NONE;
 	} else {
@@ -189,6 +195,74 @@ udp_snat_handler(struct sk_buff *skb,
 }
 
 
+
+static int
+udp_fnat_out_handler(struct sk_buff *skb,
+		 struct ip_vs_protocol *pp, struct ip_vs_conn *cp)
+{
+	struct udphdr *udph;
+	unsigned int udphoff;
+	int oldlen;
+
+	EnterFunction(10);
+	
+#ifdef CONFIG_IP_VS_IPV6
+	if (cp->af == AF_INET6)
+		udphoff = sizeof(struct ipv6hdr);
+	else
+#endif
+		udphoff = ip_hdrlen(skb);
+	oldlen = skb->len - udphoff;
+
+	/* csum_check requires unshared skb */
+	if (!skb_make_writable(skb, udphoff + sizeof(*udph)))
+		return 0;
+
+	if (unlikely(cp->app != NULL)) {
+		/* Some checks before mangling */
+		if (pp->csum_check && !pp->csum_check(cp->af, skb, pp))
+			return 0;
+
+		/*
+		 *      Call application helper if needed
+		 */
+		if (!ip_vs_app_pkt_out(cp, skb))
+			return 0;
+	}
+
+	udph = (void *)skb_network_header(skb) + udphoff;
+	udph->source = cp->vport;
+	udph->dest = cp->cport;
+
+
+	/* full checksum calculation */
+	udph->check = 0;
+	skb->csum = skb_checksum(skb, udphoff, skb->len - udphoff, 0);
+#ifdef CONFIG_IP_VS_IPV6
+	if (cp->af == AF_INET6)
+		udph->check = csum_ipv6_magic(&cp->vaddr.in6,
+					      &cp->caddr.in6,
+					      skb->len - udphoff,
+					      cp->protocol, skb->csum);
+	else
+#endif
+		udph->check = csum_tcpudp_magic(cp->vaddr.ip,
+						cp->caddr.ip,
+						skb->len - udphoff,
+						cp->protocol,
+						skb->csum);
+	if (udph->check == 0)
+		udph->check = CSUM_MANGLED_0;
+	IP_VS_DBG(11, "O-pkt: %s O-csum=%d (+%zd)\n",
+		  pp->name, udph->check,
+		  (char *)&(udph->check) - (char *)udph);
+	LeaveFunction(10);
+	return 1;
+}
+
+
+
+
 static int
 udp_dnat_handler(struct sk_buff *skb,
 		 struct ip_vs_protocol *pp, struct ip_vs_conn *cp)
@@ -223,19 +297,25 @@ udp_dnat_handler(struct sk_buff *skb,
 	}
 
 	udph = (void *)skb_network_header(skb) + udphoff;
+	udph->source = cp->lport;
 	udph->dest = cp->dport;
 
 	/*
 	 *	Adjust UDP checksums
 	 */
 	if (skb->ip_summed == CHECKSUM_PARTIAL) {
-		udp_partial_csum_update(cp->af, udph, &cp->daddr, &cp->vaddr,
+		udp_partial_csum_update(cp->af, udph, &cp->vaddr, &cp->daddr,
+					htons(oldlen),
+					htons(skb->len - udphoff));
+		udp_partial_csum_update(cp->af, udph, &cp->caddr, &cp->laddr,
 					htons(oldlen),
 					htons(skb->len - udphoff));
 	} else if (!cp->app && (udph->check != 0)) {
 		/* Only port and addr are changed, do fast csum update */
 		udp_fast_csum_update(cp->af, udph, &cp->vaddr, &cp->daddr,
 				     cp->vport, cp->dport);
+		udp_fast_csum_update(cp->af, udph, &cp->caddr, &cp->laddr,
+				     cp->cport, cp->lport);
 		if (skb->ip_summed == CHECKSUM_COMPLETE)
 			skb->ip_summed = CHECKSUM_NONE;
 	} else {
@@ -262,6 +342,71 @@ udp_dnat_handler(struct sk_buff *skb,
 	return 1;
 }
 
+static int
+udp_fnat_in_handler(struct sk_buff **skb_p,
+		 struct ip_vs_protocol *pp, struct ip_vs_conn *cp)
+{
+	struct udphdr *udph;
+	unsigned int udphoff;
+	int oldlen;
+	struct sk_buff *skb = *skb_p;
+
+	EnterFunction(10);
+	
+#ifdef CONFIG_IP_VS_IPV6
+	if (cp->af == AF_INET6)
+		udphoff = sizeof(struct ipv6hdr);
+	else
+#endif
+		udphoff = ip_hdrlen(skb);
+	oldlen = skb->len - udphoff;
+
+	/* csum_check requires unshared skb */
+	if (!skb_make_writable(skb, udphoff + sizeof(*udph)))
+		return 0;
+
+	if (unlikely(cp->app != NULL)) {
+		/* Some checks before mangling */
+		if (pp->csum_check && !pp->csum_check(cp->af, skb, pp))
+			return 0;
+
+		/*
+		 *      Attempt ip_vs_app call.
+		 *      It will fix ip_vs_conn
+		 */
+		if (!ip_vs_app_pkt_in(cp, skb))
+			return 0;
+	}
+
+	udph = (void *)skb_network_header(skb) + udphoff;
+	udph->source = cp->lport;
+	udph->dest = cp->dport;
+
+
+		/* full checksum calculation */
+	udph->check = 0;
+	skb->csum = skb_checksum(skb, udphoff, skb->len - udphoff, 0);
+#ifdef CONFIG_IP_VS_IPV6
+	if (cp->af == AF_INET6)
+		udph->check = csum_ipv6_magic(&cp->laddr.in6,
+					      &cp->daddr.in6,
+					      skb->len - udphoff,
+					      cp->protocol, skb->csum);
+	else
+#endif
+		udph->check = csum_tcpudp_magic(cp->laddr.ip,
+						cp->daddr.ip,
+						skb->len - udphoff,
+						cp->protocol,
+						skb->csum);
+	if (udph->check == 0)
+		udph->check = CSUM_MANGLED_0;
+	skb->ip_summed = CHECKSUM_UNNECESSARY;
+	LeaveFunction(10);
+	return 1;
+}
+
+
 
 static int
 udp_csum_check(int af, struct sk_buff *skb, struct ip_vs_protocol *pp)
@@ -472,6 +617,8 @@ struct ip_vs_protocol ip_vs_protocol_udp = {
 	.conn_out_get =		ip_vs_conn_out_get_proto,
 	.snat_handler =		udp_snat_handler,
 	.dnat_handler =		udp_dnat_handler,
+	.fnat_in_handler =  	udp_fnat_in_handler,
+	.fnat_out_handler = 	udp_fnat_out_handler,
 	.csum_check =		udp_csum_check,
 	.state_transition =	udp_state_transition,
 	.state_name =		udp_state_name,
diff --git a/net/netfilter/ipvs/ip_vs_sync.c b/net/netfilter/ipvs/ip_vs_sync.c
index 8fb0ae6..4ef1944 100644
--- a/net/netfilter/ipvs/ip_vs_sync.c
+++ b/net/netfilter/ipvs/ip_vs_sync.c
@@ -303,6 +303,7 @@ static void ip_vs_process_message(const char *buffer, const size_t buflen)
 	struct ip_vs_dest *dest;
 	char *p;
 	int i;
+	int res_dir;
 
 	if (buflen < sizeof(struct ip_vs_sync_mesg)) {
 		IP_VS_ERR_RL("sync message header too short\n");
@@ -371,11 +372,11 @@ static void ip_vs_process_message(const char *buffer, const size_t buflen)
 		}
 
 		if (!(flags & IP_VS_CONN_F_TEMPLATE))
-			cp = ip_vs_conn_in_get(AF_INET, s->protocol,
+			cp = ip_vs_conn_get(AF_INET, s->protocol,
 					       (union nf_inet_addr *)&s->caddr,
 					       s->cport,
 					       (union nf_inet_addr *)&s->vaddr,
-					       s->vport);
+						   s->vport, &res_dir);
 		else
 			cp = ip_vs_ct_in_get(AF_INET, s->protocol,
 					     (union nf_inet_addr *)&s->caddr,
@@ -413,7 +414,7 @@ static void ip_vs_process_message(const char *buffer, const size_t buflen)
 					    s->vport,
 					    (union nf_inet_addr *)&s->daddr,
 					    s->dport,
-					    flags, dest);
+					    flags, dest, NULL, 0);
 			if (dest)
 				atomic_dec(&dest->refcnt);
 			if (!cp) {
diff --git a/net/netfilter/ipvs/ip_vs_synproxy.c b/net/netfilter/ipvs/ip_vs_synproxy.c
new file mode 100644
index 0000000..e8afe4a
--- /dev/null
+++ b/net/netfilter/ipvs/ip_vs_synproxy.c
@@ -0,0 +1,1108 @@
+/*
+ * ip_vs_synproxy.c:   SYNPROXY for defence synflood attack, based on tcp syncookies
+ *
+ * Authors:     
+ * 		Jian Chen  <jian.chen1225@gmail.com>
+ * 		Yan Tian   <tianyan.7c00@gmail.com>
+ * 		Wen Li     <steel.mental@gmail.com>
+ * 		Jiaming Wu <pukong.wjm@taobao.com>
+ *
+ *              This program is free software; you can redistribute it and/or
+ *              modify it under the terms of the GNU General Public License
+ *              as published by the Free Software Foundation; either version
+ *              2 of the License, or (at your option) any later version.
+ *
+ * Changes:
+ */
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/tcp.h>
+#include <linux/if_arp.h>
+
+#include <net/ip.h>
+#include <net/tcp.h>
+#include <net/udp.h>
+#include <net/icmp.h>		/* for icmp_send */
+#include <net/route.h>
+
+#include <linux/netfilter.h>
+#include <linux/netfilter_ipv4.h>
+
+#ifdef CONFIG_IP_VS_IPV6
+#include <net/ipv6.h>
+#include <linux/netfilter_ipv6.h>
+#endif
+
+#include <net/ip_vs.h>
+#include <net/ip_vs_synproxy.h>
+
+static inline void
+syn_proxy_seq_csum_update(struct tcphdr *tcph, __u32 old_seq, __u32 new_seq)
+{
+	tcph->check = csum_fold(ip_vs_check_diff4(old_seq, new_seq,
+						  ~csum_unfold(tcph->check)));
+}
+
+/*
+ * Replace tcp options in tcp header, called by syn_proxy_reuse_skb()
+ *
+ */
+static void
+syn_proxy_parse_set_opts(struct sk_buff *skb, struct tcphdr *th,
+			 struct ip_vs_synproxy_opt *opt)
+{
+	/* mss in received packet */
+	__u16 in_mss;
+	__u32 *tmp;
+	unsigned char *ptr;
+	int length = (th->doff * 4) - sizeof(struct tcphdr);
+	/*tcp_sk(sk)->user_mss. set from proc */
+	__u16 user_mss = sysctl_ip_vs_synproxy_init_mss;
+
+	memset(opt, '\0', sizeof(struct ip_vs_synproxy_opt));
+	opt->mss_clamp = 536;
+	ptr = (unsigned char *)(th + 1);
+
+	while (length > 0) {
+		unsigned char *tmp_opcode = ptr;
+		int opcode = *ptr++;
+		int opsize;
+
+		switch (opcode) {
+		case TCPOPT_EOL:
+			return;
+		case TCPOPT_NOP:
+			length--;
+			continue;
+		default:
+			opsize = *ptr++;
+			if (opsize < 2)	/* "silly options" */
+				return;
+			if (opsize > length)
+				return;	/* don't parse partial options */
+			switch (opcode) {
+			case TCPOPT_MSS:
+				if (opsize == TCPOLEN_MSS) {
+					in_mss = ntohs(*(__u16 *) ptr);
+					if (in_mss) {
+						if (user_mss < in_mss) {
+							in_mss = user_mss;
+						}
+						opt->mss_clamp = in_mss;
+					}
+					*(__u16 *) ptr = htons(opt->mss_clamp);
+				}
+				break;
+			case TCPOPT_WINDOW:
+				if (opsize == TCPOLEN_WINDOW) {
+					if (sysctl_ip_vs_synproxy_wscale) {
+						opt->wscale_ok = 1;
+						opt->snd_wscale = *(__u8 *) ptr;
+						if (opt->snd_wscale >
+						    IP_VS_SYNPROXY_WSCALE_MAX) {
+							IP_VS_DBG(6,
+								  "tcp_parse_options: Illegal window "
+								  "scaling value %d > %d received.",
+								  opt->
+								  snd_wscale,
+								  IP_VS_SYNPROXY_WSCALE_MAX);
+							opt->snd_wscale =
+							    IP_VS_SYNPROXY_WSCALE_MAX;
+						}
+						*(__u8 *) ptr = (__u8)
+						    sysctl_ip_vs_synproxy_wscale;
+					} else {
+						memset(tmp_opcode, TCPOPT_NOP,
+						       TCPOLEN_WINDOW);
+					}
+				}
+				break;
+			case TCPOPT_TIMESTAMP:
+				if (opsize == TCPOLEN_TIMESTAMP) {
+					if (sysctl_ip_vs_synproxy_timestamp) {
+						opt->tstamp_ok = 1;
+						tmp = (__u32 *) ptr;
+						*(tmp + 1) = *tmp;
+						*tmp = htonl(tcp_time_stamp);
+					} else {
+						memset(tmp_opcode, TCPOPT_NOP,
+						       TCPOLEN_TIMESTAMP);
+					}
+				}
+				break;
+			case TCPOPT_SACK_PERM:
+				if (opsize == TCPOLEN_SACK_PERM) {
+					if (sysctl_ip_vs_synproxy_sack) {
+						opt->sack_ok = 1;
+					} else {
+						memset(tmp_opcode, TCPOPT_NOP,
+						       TCPOLEN_SACK_PERM);
+					}
+				}
+				break;
+			}
+			ptr += opsize - 2;
+			length -= opsize;
+		}
+	}
+}
+
+/*
+ * Reuse skb for syn proxy, called by syn_proxy_syn_rcv().
+ * do following things:
+ * 1) set tcp options;
+ * 2) compute seq with cookie func.
+ * 3) set tcp seq and ack_seq;
+ * 4) exchange ip addr and tcp port;
+ * 5) compute iphdr and tcp check.
+ *
+ */
+static void
+syn_proxy_reuse_skb(int af, struct sk_buff *skb, struct ip_vs_synproxy_opt *opt)
+{
+	__u32 isn;
+	unsigned short tmpport;
+	unsigned int tcphoff;
+	struct tcphdr *th;
+	af &= ~IP_VS_CONN_F_DSNAT;
+
+#ifdef CONFIG_IP_VS_IPV6
+	if (af == AF_INET6)
+		tcphoff = sizeof(struct ipv6hdr);
+	else
+#endif
+		tcphoff = ip_hdrlen(skb);
+
+	th = (void *)skb_network_header(skb) + tcphoff;
+
+	/* deal with tcp options */
+	syn_proxy_parse_set_opts(skb, th, opt);
+
+	/* get cookie */
+	skb_set_transport_header(skb, tcphoff);
+	isn = ip_vs_synproxy_cookie_v4_init_sequence(skb, opt);
+
+	/* Set syn-ack flag
+	 * the tcp opt in syn/ack packet : 00010010 = 0x12
+	 */
+	((u_int8_t *) th)[13] = 0x12;
+
+	/* Exchange ports */
+	tmpport = th->dest;
+	th->dest = th->source;
+	th->source = tmpport;
+
+	/* Set seq(cookie) and ack_seq */
+	th->ack_seq = htonl(ntohl(th->seq) + 1);
+	th->seq = htonl(isn);
+
+	/* Exchange addresses and compute checksums */
+#ifdef CONFIG_IP_VS_IPV6
+	if (af == AF_INET6) {
+		struct ipv6hdr *iph = ipv6_hdr(skb);
+		struct in6_addr tmpAddr;
+
+		memcpy(&tmpAddr, &iph->saddr, sizeof(struct in6_addr));
+		memcpy(&iph->saddr, &iph->daddr, sizeof(struct in6_addr));
+		memcpy(&iph->daddr, &tmpAddr, sizeof(struct in6_addr));
+
+		iph->hop_limit = sysctl_ip_vs_synproxy_synack_ttl;
+
+		th->check = 0;
+		skb->csum = skb_checksum(skb, tcphoff, skb->len - tcphoff, 0);
+		th->check = csum_ipv6_magic(&iph->saddr, &iph->daddr,
+					    skb->len - tcphoff,
+					    IPPROTO_TCP, skb->csum);
+	} else
+#endif
+	{
+		struct iphdr *iph = ip_hdr(skb);
+		__be32 tmpAddr;
+
+		tmpAddr = iph->saddr;
+		iph->saddr = iph->daddr;
+		iph->daddr = tmpAddr;
+
+		iph->ttl = sysctl_ip_vs_synproxy_synack_ttl;
+		iph->tos = 0;
+
+		ip_send_check(iph);
+
+		th->check = 0;
+		skb->csum = skb_checksum(skb, tcphoff, skb->len - tcphoff, 0);
+		th->check = csum_tcpudp_magic(iph->saddr, iph->daddr,
+					      skb->len - tcphoff,
+					      IPPROTO_TCP, skb->csum);
+	}
+}
+
+/*
+ *  syn-proxy step 1 logic:
+ *  Check if synproxy is enabled for this skb, and
+ *  send Syn/Ack back.
+ *
+ *  Synproxy is enabled when:
+ *  1) skb is a Syn packet.
+ *  2) And the service is synproxy-enable.
+ *  3) And ip_vs_todrop return false.
+ *
+ *  @return 0 means the caller should return at once and use
+ *   verdict as return value, return 1 for nothing.
+ */
+int
+ip_vs_synproxy_syn_rcv(int af, struct sk_buff *skb,
+		       struct ip_vs_iphdr *iph, int *verdict)
+{
+	struct ip_vs_service *svc = NULL;
+	struct tcphdr _tcph, *th;
+	struct ip_vs_synproxy_opt tcp_opt;
+
+	
+
+	th = skb_header_pointer(skb, iph->len, sizeof(_tcph), &_tcph);
+	if (unlikely(th == NULL)) {
+		goto syn_rcv_out;
+	}
+
+	if (th->syn && !th->ack && !th->rst && !th->fin &&
+	    (svc =
+	     ip_vs_service_get(af, skb->mark, iph->protocol, &iph->daddr,
+			       th->dest))
+	    && (svc->flags & IP_VS_CONN_F_SYNPROXY)) {
+		// release service here, because don't use it any all.
+		ip_vs_service_put(svc);
+
+		if (ip_vs_todrop()) {
+			/*
+			 * It seems that we are very loaded.
+			 * We have to drop this packet :(
+			 */
+			goto syn_rcv_out;
+		}
+	} else {
+		/*
+		 * release service.
+		 */
+		if (svc != NULL) {
+			ip_vs_service_put(svc);
+		}
+		return 1;
+	}
+
+	EnterFunction(11);
+	
+	/* update statistics */
+	IP_VS_INC_ESTATS(ip_vs_esmib, SYNPROXY_SYN_CNT);
+
+	/* Try to reuse skb if possible */
+	if (unlikely(skb_shared(skb) || skb_cloned(skb))) {
+		struct sk_buff *new_skb = skb_copy(skb, GFP_ATOMIC);
+		if (unlikely(new_skb == NULL)) {
+			goto syn_rcv_out;
+		}
+		/* Drop old skb */
+		kfree_skb(skb);
+		skb = new_skb;
+	}
+
+	/* reuse skb here: deal with tcp options, exchage ip, port. */
+	syn_proxy_reuse_skb(af, skb, &tcp_opt);
+
+	skb->pkt_type = PACKET_OUTGOING;
+
+	/* Send the packet out */
+	if (likely(skb->dev->type == ARPHRD_ETHER)) {
+		unsigned char t_hwaddr[ETH_ALEN];
+
+		/* Move the data pointer to point to the link layer header */
+		struct ethhdr *eth = (struct ethhdr *)skb_mac_header(skb);
+		skb->data = (unsigned char *)skb_mac_header(skb);
+		skb->len += ETH_HLEN;	//sizeof(skb->mac.ethernet);
+
+		memcpy(t_hwaddr, (eth->h_dest), ETH_ALEN);
+		memcpy((eth->h_dest), (eth->h_source), ETH_ALEN);
+		memcpy((eth->h_source), t_hwaddr, ETH_ALEN);
+	}
+
+	dev_queue_xmit(skb);
+	*verdict = NF_STOLEN;
+	return 0;
+      syn_rcv_out:
+	/* Drop the packet when all things are right also,
+	 * then we needn't to kfree_skb() */
+	*verdict = NF_DROP;
+	return 0;
+}
+
+/*
+ * Check if skb has user data.
+ * Attention: decrease iph len also.
+ */
+static inline int
+syn_proxy_ack_has_data(struct sk_buff *skb, struct ip_vs_iphdr *iph,
+		       struct tcphdr *th)
+{
+	IP_VS_DBG(6, "tot_len = %u, iph_len = %u, tcph_len = %u\n",
+		  skb->len, iph->len, th->doff * 4);
+	return (skb->len - iph->len - th->doff * 4) != 0;
+}
+
+static inline void
+syn_proxy_syn_build_options(__be32 * ptr, struct ip_vs_synproxy_opt *opt)
+{
+	*ptr++ =
+	    htonl((TCPOPT_MSS << 24) | (TCPOLEN_MSS << 16) | opt->mss_clamp);
+	if (opt->tstamp_ok) {
+		if (opt->sack_ok)
+			*ptr++ = htonl((TCPOPT_SACK_PERM << 24) |
+				       (TCPOLEN_SACK_PERM << 16) |
+				       (TCPOPT_TIMESTAMP << 8) |
+				       TCPOLEN_TIMESTAMP);
+		else
+			*ptr++ = htonl((TCPOPT_NOP << 24) |
+				       (TCPOPT_NOP << 16) |
+				       (TCPOPT_TIMESTAMP << 8) |
+				       TCPOLEN_TIMESTAMP);
+		*ptr++ = htonl(tcp_time_stamp);	/* TSVAL */
+		*ptr++ = 0;	/* TSECR */
+	} else if (opt->sack_ok)
+		*ptr++ = htonl((TCPOPT_NOP << 24) |
+			       (TCPOPT_NOP << 16) |
+			       (TCPOPT_SACK_PERM << 8) | TCPOLEN_SACK_PERM);
+	if (opt->wscale_ok)
+		*ptr++ = htonl((TCPOPT_NOP << 24) |
+			       (TCPOPT_WINDOW << 16) |
+			       (TCPOLEN_WINDOW << 8) | (opt->snd_wscale));
+}
+
+/*
+ * Create syn packet and send it to rs.
+ * ATTENTION: we also store syn skb in cp if syn retransimition
+ * is tured on.
+ */
+static int
+syn_proxy_send_rs_syn(int af, const struct tcphdr *th,
+		      struct ip_vs_conn *cp, struct sk_buff *skb,
+		      struct ip_vs_protocol *pp, struct ip_vs_synproxy_opt *opt)
+{
+	struct sk_buff *syn_skb;
+	int tcp_hdr_size;
+	__u8 tcp_flags = TCPCB_FLAG_SYN;
+	unsigned int tcphoff;
+	struct tcphdr *new_th;
+
+	if (!cp->packet_xmit) {
+		IP_VS_ERR_RL("warning: packet_xmit is null");
+		return 0;
+	}
+
+	syn_skb = alloc_skb(MAX_TCP_HEADER + 15, GFP_ATOMIC);
+	if (unlikely(syn_skb == NULL)) {
+		IP_VS_ERR_RL("alloc skb failed when send rs syn packet\n");
+		return 0;
+	}
+
+	/* Reserve space for headers */
+	skb_reserve(syn_skb, MAX_TCP_HEADER);
+	tcp_hdr_size = (sizeof(struct tcphdr) + TCPOLEN_MSS +
+			(opt->tstamp_ok ? TCPOLEN_TSTAMP_ALIGNED : 0) +
+			(opt->wscale_ok ? TCPOLEN_WSCALE_ALIGNED : 0) +
+			/* SACK_PERM is in the place of NOP NOP of TS */
+			((opt->sack_ok
+			  && !opt->tstamp_ok) ? TCPOLEN_SACKPERM_ALIGNED : 0));
+
+	new_th = (struct tcphdr *)skb_push(syn_skb, tcp_hdr_size);
+	/* Compose tcp header */
+	skb_reset_transport_header(syn_skb);
+	syn_skb->csum = 0;
+
+	/* Set tcp hdr */
+	new_th->source = th->source;
+	new_th->dest = cp->dest->port;
+	new_th->seq = htonl(ntohl(th->seq) - 1);
+	new_th->ack_seq = 0;
+	*(((__u16 *) new_th) + 6) =
+	    htons(((tcp_hdr_size >> 2) << 12) | tcp_flags);
+	/* FIX_ME: what window should we use */
+	new_th->window = htons(5000);
+	new_th->check = 0;
+	new_th->urg_ptr = 0;
+	new_th->urg = 0;
+	new_th->ece = 0;
+	new_th->cwr = 0;
+
+	syn_proxy_syn_build_options((__be32 *) (new_th + 1), opt);
+
+	/*
+	 * Set ip hdr
+	 * Attention: set source and dest addr to ack skb's.
+	 * we rely on packet_xmit func to do NATs thing.
+	 */
+#ifdef CONFIG_IP_VS_IPV6
+	if (af == AF_INET6) {
+		struct ipv6hdr *ack_iph = ipv6_hdr(skb);
+		struct ipv6hdr *iph =
+		    (struct ipv6hdr *)skb_push(syn_skb, sizeof(struct iphdr));
+
+		tcphoff = sizeof(struct ipv6hdr);
+		skb_reset_network_header(syn_skb);
+		memcpy(&iph->saddr, &ack_iph->saddr, sizeof(struct in6_addr));
+		memcpy(&iph->daddr, &ack_iph->daddr, sizeof(struct in6_addr));
+
+		iph->hop_limit = IPV6_DEFAULT_HOPLIMIT;
+
+		new_th->check = 0;
+		syn_skb->csum =
+		    skb_checksum(syn_skb, tcphoff, syn_skb->len - tcphoff, 0);
+		new_th->check =
+		    csum_ipv6_magic(&iph->saddr, &iph->daddr,
+				    syn_skb->len - tcphoff, IPPROTO_TCP,
+				    syn_skb->csum);
+	} else
+#endif
+	{
+		struct iphdr *ack_iph = ip_hdr(skb);
+		u32 rtos = RT_TOS(ack_iph->tos);
+		struct iphdr *iph =
+		    (struct iphdr *)skb_push(syn_skb, sizeof(struct iphdr));
+
+		tcphoff = sizeof(struct iphdr);
+		skb_reset_network_header(syn_skb);
+		*((__u16 *) iph) = htons((4 << 12) | (5 << 8) | (rtos & 0xff));
+		iph->tot_len = htons(syn_skb->len);
+		iph->frag_off = htons(IP_DF);
+		/* FIX_ME: what ttl shoule we use */
+		iph->ttl = IPDEFTTL;
+		iph->protocol = IPPROTO_TCP;
+		iph->saddr = ack_iph->saddr;
+		iph->daddr = ack_iph->daddr;
+
+		ip_send_check(iph);
+
+		new_th->check = 0;
+		syn_skb->csum =
+		    skb_checksum(syn_skb, tcphoff, syn_skb->len - tcphoff, 0);
+		new_th->check =
+		    csum_tcpudp_magic(iph->saddr, iph->daddr,
+				      syn_skb->len - tcphoff, IPPROTO_TCP,
+				      syn_skb->csum);
+	}
+
+	/* Save syn_skb if syn retransmission is on  */
+	if (sysctl_ip_vs_synproxy_syn_retry > 0) {
+		cp->syn_skb = skb_copy(syn_skb, GFP_ATOMIC);
+		atomic_set(&cp->syn_retry_max, sysctl_ip_vs_synproxy_syn_retry);
+	}
+
+	/* If xmit failed, syn_skb will be freed correctly. */
+	cp->packet_xmit(syn_skb, cp, pp);
+
+	return 1;
+}
+
+/*
+ * Syn-proxy step 2 logic
+ * Receive client's 3-handshakes  Ack packet, do cookie check
+ * and then send syn to rs after creating a session.
+ *
+ */
+int
+ip_vs_synproxy_ack_rcv(int af, struct sk_buff *skb, struct tcphdr *th,
+		       struct ip_vs_protocol *pp, struct ip_vs_conn **cpp,
+		       struct ip_vs_iphdr *iph, int *verdict)
+{
+	struct ip_vs_synproxy_opt opt;
+	struct ip_vs_service *svc;
+	int res_cookie_check;
+	int dsnat;
+	dsnat = af & IP_VS_CONN_F_DSNAT;
+	af &= ~IP_VS_CONN_F_DSNAT;
+
+	
+	/*
+	 * Don't check svc syn-proxy flag, as it may
+	 * be changed after syn-proxy step 1.
+	 */
+	if (!th->syn && th->ack && !th->rst && !th->fin &&
+	    (svc =
+	     ip_vs_service_get(af|dsnat, skb->mark, iph->protocol, &iph->daddr,
+			       th->dest))) {
+		if (ip_vs_todrop()) {
+			/*
+			 * It seems that we are very loaded.
+			 * We have to drop this packet :(
+			 */
+			ip_vs_service_put(svc);
+			*verdict = NF_DROP;
+			return 0;
+		}
+		
+		EnterFunction(11);
+		
+		if (sysctl_ip_vs_synproxy_defer &&
+		    !syn_proxy_ack_has_data(skb, iph, th)) {
+			/* update statistics */
+			IP_VS_INC_ESTATS(ip_vs_esmib, SYNPROXY_NULL_ACK);
+			/*
+			 * When expecting ack packet with payload,
+			 * we get a pure ack, so have to drop it.
+			 */
+			ip_vs_service_put(svc);
+			*verdict = NF_DROP;
+			return 0;
+		}
+
+		/*
+		 * Import: set tcp hdr before cookie check, as it
+		 * will be used in cookie_check funcs.
+		 */
+		skb_set_transport_header(skb, iph->len);
+#ifdef CONFIG_IP_VS_IPV6
+		if (af == AF_INET6) {
+			res_cookie_check = ip_vs_synproxy_v6_cookie_check(skb,
+									  ntohl
+									  (th->
+									   ack_seq)
+									  - 1,
+									  &opt);
+		} else
+#endif
+		{
+			res_cookie_check = ip_vs_synproxy_v4_cookie_check(skb,
+									  ntohl
+									  (th->
+									   ack_seq)
+									  - 1,
+									  &opt);
+		}
+
+		if (!res_cookie_check) {
+			/* update statistics */
+			IP_VS_INC_ESTATS(ip_vs_esmib, SYNPROXY_BAD_ACK);
+			/*
+			 * Cookie check fail, drop it.
+			 */
+			IP_VS_DBG(6, "syn_cookie check failed seq=%u\n",
+				  ntohl(th->ack_seq) - 1);
+			ip_vs_service_put(svc);
+			*verdict = NF_DROP;
+			return 0;
+		}
+
+		/* update statistics */
+		IP_VS_INC_ESTATS(ip_vs_esmib, SYNPROXY_OK_ACK);
+
+		/*
+		 * Let the virtual server select a real server for the
+		 * incoming connection, and create a connection entry.
+		 */
+		*cpp = ip_vs_schedule(svc, skb, 1);
+		if (!*cpp) {
+			IP_VS_DBG(6, "ip_vs_schedule failed\n");
+			*verdict = ip_vs_leave(svc, skb, pp);
+			return 0;
+		}
+
+		/*
+		 * Release service, we don't need it any more.
+		 */
+		ip_vs_service_put(svc);
+
+		/*
+		 * Do anything but print a error msg when fail.
+		 * Because session will be correctly freed in ip_vs_conn_expire.
+		 */
+		if (!syn_proxy_send_rs_syn(af, th, *cpp, skb, pp, &opt)) {
+			IP_VS_ERR_RL("syn_proxy_send_rs_syn failed!\n");
+		}
+
+		/*
+		 * Active sesion timer, and dec refcnt.
+		 * Also stole the skb, and let caller return immediately.
+		 */
+		ip_vs_conn_put(*cpp);
+		*verdict = NF_STOLEN;
+		return 0;
+	}
+
+	return 1;
+}
+
+/*
+ * Update out-in sack seqs, and also correct th->check
+ */
+static inline void
+syn_proxy_filter_opt_outin(struct tcphdr *th, struct ip_vs_seq *sp_seq)
+{
+	unsigned char *ptr;
+	int length = (th->doff * 4) - sizeof(struct tcphdr);
+	__be32 *tmp;
+	__u32 old_ack_seq;
+
+	if (!length)
+		return;
+
+	ptr = (unsigned char *)(th + 1);
+
+	/* Fast path for timestamp-only option */
+	if (length == TCPOLEN_TSTAMP_ALIGNED * 4
+	    && *(__be32 *) ptr == __constant_htonl((TCPOPT_NOP << 24)
+						   | (TCPOPT_NOP << 16)
+						   | (TCPOPT_TIMESTAMP << 8) |
+						   TCPOLEN_TIMESTAMP))
+		return;
+
+	while (length > 0) {
+		int opcode = *ptr++;
+		int opsize, i;
+
+		switch (opcode) {
+		case TCPOPT_EOL:
+			return;
+		case TCPOPT_NOP:	/* Ref: RFC 793 section 3.1 */
+			length--;
+			continue;
+		default:
+			opsize = *ptr++;
+			if (opsize < 2)	/* "silly options" */
+				return;
+			if (opsize > length)
+				break;	/* don't parse partial options */
+
+			if (opcode == TCPOPT_SACK
+			    && opsize >= (TCPOLEN_SACK_BASE
+					  + TCPOLEN_SACK_PERBLOCK)
+			    && !((opsize - TCPOLEN_SACK_BASE) %
+				 TCPOLEN_SACK_PERBLOCK)) {
+				for (i = 0; i < (opsize - TCPOLEN_SACK_BASE);
+				     i += TCPOLEN_SACK_PERBLOCK) {
+					tmp = (__be32 *) (ptr + i);
+					old_ack_seq = ntohl(*tmp);
+					*tmp = htonl((__u32)
+						     (old_ack_seq -
+						      sp_seq->delta));
+					syn_proxy_seq_csum_update(th,
+								  htonl
+								  (old_ack_seq),
+								  *tmp);
+					IP_VS_DBG(6,
+						  "syn_proxy_filter_opt_outin: sack_left_seq %u => %u, delta = %u \n",
+						  old_ack_seq, ntohl(*tmp),
+						  sp_seq->delta);
+					tmp++;
+					old_ack_seq = ntohl(*tmp);
+					*tmp = htonl((__u32)
+						     (old_ack_seq -
+						      sp_seq->delta));
+					syn_proxy_seq_csum_update(th,
+								  htonl
+								  (old_ack_seq),
+								  *tmp);
+					IP_VS_DBG(6,
+						  "syn_proxy_filter_opt_outin: sack_right_seq %u => %u, delta = %u \n",
+						  old_ack_seq, ntohl(*tmp),
+						  sp_seq->delta);
+				}
+				return;
+			}
+			ptr += opsize - 2;
+			length -= opsize;
+		}
+	}
+}
+
+/*
+ * Update out-in ack_seqs: include th->ack_seq, sack opt
+ * and also correct tcph->check.
+ */
+void ip_vs_synproxy_dnat_handler(struct tcphdr *tcph, struct ip_vs_seq *sp_seq)
+{
+	__u32 old_ack_seq;
+
+	if (sp_seq->delta != 0) {
+		old_ack_seq = ntohl(tcph->ack_seq);
+		tcph->ack_seq = htonl((__u32) (old_ack_seq - sp_seq->delta));
+		syn_proxy_seq_csum_update(tcph, htonl(old_ack_seq),
+					  tcph->ack_seq);
+		syn_proxy_filter_opt_outin(tcph, sp_seq);
+		IP_VS_DBG(6,
+			  "tcp_dnat_handler: tcph->ack_seq %u => %u, delta = %u \n",
+			  old_ack_seq, htonl(tcph->ack_seq), sp_seq->delta);
+	}
+}
+
+/*
+ * Syn-proxy step 3 logic: receive syn-ack from rs
+ * Update syn_proxy_seq.delta and send stored ack skbs
+ * to rs.
+ */
+int
+ip_vs_synproxy_synack_rcv(struct sk_buff *skb, struct ip_vs_conn *cp,
+			  struct ip_vs_protocol *pp, int ihl, int *verdict)
+{
+	struct tcphdr _tcph, *th;
+	struct sk_buff_head save_skb;
+	struct sk_buff *tmp_skb = NULL;
+	struct ip_vs_dest *dest = cp->dest;
+
+	EnterFunction(11);
+	
+	th = skb_header_pointer(skb, ihl, sizeof(_tcph), &_tcph);
+	if (th == NULL) {
+		*verdict = NF_DROP;
+		return 0;
+	}
+
+	IP_VS_DBG(6, "in syn_proxy_synack_rcv, "
+		  "seq = %u ack_seq = %u %c%c%c cp->is_synproxy = %u cp->state = %u\n",
+		  ntohl(th->seq),
+		  ntohl(th->ack_seq),
+		  (th->syn) ? 'S' : '-',
+		  (th->ack) ? 'A' : '-',
+		  (th->rst) ? 'R' : '-',
+		  cp->flags & IP_VS_CONN_F_SYNPROXY, cp->state);
+
+	skb_queue_head_init(&save_skb);
+	spin_lock(&cp->lock);
+	if ((th->syn) && (th->ack) && (!th->rst) &&
+	    (cp->flags & IP_VS_CONN_F_SYNPROXY) &&
+	    cp->state == IP_VS_TCP_S_SYN_SENT) {
+		cp->syn_proxy_seq.delta =
+		    htonl(cp->syn_proxy_seq.init_seq) - htonl(th->seq);
+		cp->timeout = pp->timeout_table[cp->state =
+						IP_VS_TCP_S_ESTABLISHED];
+		if (dest) {
+			atomic_inc(&dest->activeconns);
+			atomic_dec(&dest->inactconns);
+			cp->flags &= ~IP_VS_CONN_F_INACTIVE;
+		}
+
+		/* save tcp sequense for fullnat/nat, INside to OUTside */
+		if (sysctl_ip_vs_conn_expire_tcp_rst == 1) {
+			cp->rs_end_seq = htonl(ntohl(th->seq) + 1);
+			cp->rs_ack_seq = th->ack_seq;
+			IP_VS_DBG_RL("packet from RS, seq:%u ack_seq:%u.",
+				     ntohl(th->seq), ntohl(th->ack_seq));
+			IP_VS_DBG_RL("port:%u->%u", ntohs(th->source),
+				     ntohs(th->dest));
+		}
+
+		/* First: free stored syn skb */
+		if ((tmp_skb = xchg(&cp->syn_skb, NULL)) != NULL) {
+			kfree_skb(tmp_skb);
+			tmp_skb = NULL;
+		}
+
+		if (skb_queue_len(&cp->ack_skb) <= 0) {
+			/*
+			 * FIXME: maybe a bug here, print err msg and go.
+			 * Attention: cp->state has been changed and we
+			 * should still DROP the Syn/Ack skb.
+			 */
+			IP_VS_ERR_RL
+			    ("Got ack_skb NULL pointer in syn_proxy_synack_rcv\n");
+			spin_unlock(&cp->lock);
+			*verdict = NF_DROP;
+			return 0;
+		}
+
+		while ((tmp_skb = skb_dequeue(&cp->ack_skb)) != NULL) {
+			skb_queue_tail(&save_skb, tmp_skb);
+		}
+
+		/*
+		 * Release the lock, because we don't
+		 * touch session any more.
+		 */
+		spin_unlock(&cp->lock);
+
+		while ((tmp_skb = skb_dequeue(&save_skb)) != NULL) {
+			/* If xmit failed, syn_skb will be freed correctly. */
+			cp->packet_xmit(tmp_skb, cp, pp);
+		}
+
+		*verdict = NF_DROP;
+		return 0;
+	} else if ((th->rst) &&
+		   (cp->flags & IP_VS_CONN_F_SYNPROXY) &&
+		   cp->state == IP_VS_TCP_S_SYN_SENT) {
+		__u32 temp_seq;
+		temp_seq = ntohl(th->seq);
+		IP_VS_DBG(6, "get rst from rs, seq = %u ack_seq= %u\n",
+			  ntohl(th->seq), ntohl(th->ack_seq));
+		/* coute the delta of seq */
+		cp->syn_proxy_seq.delta =
+		    ntohl(cp->syn_proxy_seq.init_seq) - ntohl(th->seq);
+		cp->timeout = pp->timeout_table[cp->state = IP_VS_TCP_S_CLOSE];
+		spin_unlock(&cp->lock);
+		th->seq = htonl(ntohl(th->seq) + 1);
+		syn_proxy_seq_csum_update(th, htonl(temp_seq), th->seq);
+
+		return 1;
+	}
+	spin_unlock(&cp->lock);
+
+	return 1;
+}
+
+static inline void
+__syn_proxy_reuse_conn(struct ip_vs_conn *cp,
+		       struct sk_buff *ack_skb,
+		       struct tcphdr *th, struct ip_vs_protocol *pp)
+{
+	struct sk_buff *tmp_skb = NULL;
+
+	/* Free stored ack packet */
+	while ((tmp_skb = skb_dequeue(&cp->ack_skb)) != NULL) {
+		kfree_skb(tmp_skb);
+		tmp_skb = NULL;
+	}
+
+	/* Free stored syn skb */
+	if ((tmp_skb = xchg(&cp->syn_skb, NULL)) != NULL) {
+		kfree_skb(tmp_skb);
+		tmp_skb = NULL;
+	}
+
+	/* Store new ack_skb */
+	skb_queue_head_init(&cp->ack_skb);
+	skb_queue_tail(&cp->ack_skb, ack_skb);
+
+	/* Save ack_seq - 1 */
+	cp->syn_proxy_seq.init_seq = htonl((__u32) ((htonl(th->ack_seq) - 1)));
+	/* don't change delta here, so original flow can still be valid */
+
+	/* Clean dup ack cnt */
+	atomic_set(&cp->dup_ack_cnt, 0);
+
+	/* Set timeout value */
+	cp->timeout = pp->timeout_table[cp->state = IP_VS_TCP_S_SYN_SENT];
+}
+
+/*
+ * Syn-proxy session reuse function.
+ * Update syn_proxy_seq struct and clean syn-proxy related
+ * members.
+ */
+int
+ip_vs_synproxy_reuse_conn(int af, struct sk_buff *skb,
+			  struct ip_vs_conn *cp,
+			  struct ip_vs_protocol *pp,
+			  struct ip_vs_iphdr *iph, int *verdict)
+{
+	struct tcphdr _tcph, *th = NULL;
+	struct ip_vs_synproxy_opt opt;
+	int res_cookie_check;
+	u32 tcp_conn_reuse_states = 0;
+	af &= ~IP_VS_CONN_F_DSNAT;
+
+	th = skb_header_pointer(skb, iph->len, sizeof(_tcph), &_tcph);
+	if (unlikely(NULL == th)) {
+		IP_VS_ERR_RL("skb has a invalid tcp header\n");
+		*verdict = NF_DROP;
+		return 0;
+	}
+
+	tcp_conn_reuse_states =
+	    ((sysctl_ip_vs_synproxy_conn_reuse_cl << IP_VS_TCP_S_CLOSE) |
+	     (sysctl_ip_vs_synproxy_conn_reuse_tw << IP_VS_TCP_S_TIME_WAIT) |
+	     (sysctl_ip_vs_synproxy_conn_reuse_fw << IP_VS_TCP_S_FIN_WAIT) |
+	     (sysctl_ip_vs_synproxy_conn_reuse_cw << IP_VS_TCP_S_CLOSE_WAIT) |
+	     (sysctl_ip_vs_synproxy_conn_reuse_la << IP_VS_TCP_S_LAST_ACK));
+
+	if (((1 << (cp->state)) & tcp_conn_reuse_states) &&
+	    (cp->flags & IP_VS_CONN_F_SYNPROXY) &&
+	    (!th->syn && th->ack && !th->rst && !th->fin) &&
+	    (cp->syn_proxy_seq.init_seq !=
+	     htonl((__u32) ((ntohl(th->ack_seq) - 1))))) {
+		/*
+		 * Import: set tcp hdr before cookie check, as it
+		 * will be used in cookie_check funcs.
+		 */
+		skb_set_transport_header(skb, iph->len);
+#ifdef CONFIG_IP_VS_IPV6
+		if (af == AF_INET6) {
+			res_cookie_check = ip_vs_synproxy_v6_cookie_check(skb,
+									  ntohl
+									  (th->
+									   ack_seq)
+									  - 1,
+									  &opt);
+		} else
+#endif
+		{
+			res_cookie_check = ip_vs_synproxy_v4_cookie_check(skb,
+									  ntohl
+									  (th->
+									   ack_seq)
+									  - 1,
+									  &opt);
+		}
+
+		if (!res_cookie_check) {
+			/* update statistics */
+			IP_VS_INC_ESTATS(ip_vs_esmib, SYNPROXY_BAD_ACK);
+			/*
+			 * Cookie check fail, let it go.
+			 */
+			return 1;
+		}
+
+		/* update statistics */
+		IP_VS_INC_ESTATS(ip_vs_esmib, SYNPROXY_OK_ACK);
+		IP_VS_INC_ESTATS(ip_vs_esmib, SYNPROXY_CONN_REUSED);
+		switch (cp->old_state) {
+		case IP_VS_TCP_S_CLOSE:
+			IP_VS_INC_ESTATS(ip_vs_esmib,
+					 SYNPROXY_CONN_REUSED_CLOSE);
+			break;
+		case IP_VS_TCP_S_TIME_WAIT:
+			IP_VS_INC_ESTATS(ip_vs_esmib,
+					 SYNPROXY_CONN_REUSED_TIMEWAIT);
+			break;
+		case IP_VS_TCP_S_FIN_WAIT:
+			IP_VS_INC_ESTATS(ip_vs_esmib,
+					 SYNPROXY_CONN_REUSED_FINWAIT);
+			break;
+		case IP_VS_TCP_S_CLOSE_WAIT:
+			IP_VS_INC_ESTATS(ip_vs_esmib,
+					 SYNPROXY_CONN_REUSED_CLOSEWAIT);
+			break;
+		case IP_VS_TCP_S_LAST_ACK:
+			IP_VS_INC_ESTATS(ip_vs_esmib,
+					 SYNPROXY_CONN_REUSED_LASTACK);
+			break;
+		}
+
+		spin_lock(&cp->lock);
+		__syn_proxy_reuse_conn(cp, skb, th, pp);
+		spin_unlock(&cp->lock);
+
+		if (unlikely(!syn_proxy_send_rs_syn(af, th, cp, skb, pp, &opt))) {
+			IP_VS_ERR_RL
+			    ("syn_proxy_send_rs_syn failed when reuse conn!\n");
+			/* release conn immediately */
+			spin_lock(&cp->lock);
+			cp->timeout = 0;
+			spin_unlock(&cp->lock);
+		}
+
+		*verdict = NF_STOLEN;
+		return 0;
+	}
+
+	return 1;
+}
+
+/*
+ * Check and stop ack storm.
+ * Return 0 if ack storm is found.
+ */
+static int syn_proxy_is_ack_storm(struct tcphdr *tcph, struct ip_vs_conn *cp)
+{
+	/* only for syn-proxy sessions */
+	if (!(cp->flags & IP_VS_CONN_F_SYNPROXY) || !tcph->ack)
+		return 1;
+
+	if (unlikely(sysctl_ip_vs_synproxy_dup_ack_thresh == 0))
+		return 1;
+
+	if (unlikely(tcph->seq == cp->last_seq &&
+		     tcph->ack_seq == cp->last_ack_seq)) {
+		atomic_inc(&cp->dup_ack_cnt);
+		if (atomic_read(&cp->dup_ack_cnt) >=
+		    sysctl_ip_vs_synproxy_dup_ack_thresh) {
+			atomic_set(&cp->dup_ack_cnt,
+				   sysctl_ip_vs_synproxy_dup_ack_thresh);
+			/* update statistics */
+			IP_VS_INC_ESTATS(ip_vs_esmib, SYNPROXY_ACK_STORM);
+			return 0;
+		}
+
+		return 1;
+	}
+
+	cp->last_seq = tcph->seq;
+	cp->last_ack_seq = tcph->ack_seq;
+	atomic_set(&cp->dup_ack_cnt, 0);
+
+	return 1;
+}
+
+/*
+ * Syn-proxy snat handler:
+ * 1) check and stop ack storm.
+ * 2)Update in-out seqs: include th->seq
+ * and also correct tcph->check.
+ *
+ * Return 0 if ack storm is found and stoped.
+ */
+int ip_vs_synproxy_snat_handler(struct tcphdr *tcph, struct ip_vs_conn *cp)
+{
+	__u32 old_seq;
+
+	if (syn_proxy_is_ack_storm(tcph, cp) == 0) {
+		return 0;
+	}
+
+	if (cp->syn_proxy_seq.delta != 0) {
+		old_seq = ntohl(tcph->seq);
+		tcph->seq = htonl((__u32) (old_seq + cp->syn_proxy_seq.delta));
+		syn_proxy_seq_csum_update(tcph, htonl(old_seq), tcph->seq);
+		IP_VS_DBG(6,
+			  "tcp_snat_handler: tcph->seq %u => %u, delta = %u \n",
+			  old_seq, htonl(tcph->seq), cp->syn_proxy_seq.delta);
+	}
+
+	return 1;
+}
+
+int
+ip_vs_synproxy_filter_ack(struct sk_buff *skb, struct ip_vs_conn *cp,
+			  struct ip_vs_protocol *pp,
+			  struct ip_vs_iphdr *iph, int *verdict)
+{
+	struct tcphdr _tcph, *th;
+
+	th = skb_header_pointer(skb, iph->len, sizeof(_tcph), &_tcph);
+
+	if (unlikely(NULL == th)) {
+		IP_VS_ERR_RL("skb has a invalid tcp header\n");
+		*verdict = NF_DROP;
+		return 0;
+	}
+
+	spin_lock(&cp->lock);
+	if ((cp->flags & IP_VS_CONN_F_SYNPROXY) &&
+	    cp->state == IP_VS_TCP_S_SYN_SENT) {
+		/*
+		 * Not a ack packet, drop it.
+		 */
+		if (!th->ack) {
+			spin_unlock(&cp->lock);
+			*verdict = NF_DROP;
+			return 0;
+		}
+
+		if (sysctl_ip_vs_synproxy_skb_store_thresh <
+		    skb_queue_len(&cp->ack_skb)) {
+			spin_unlock(&cp->lock);
+			/* update statistics */
+			IP_VS_INC_ESTATS(ip_vs_esmib, SYNPROXY_SYNSEND_QLEN);
+			*verdict = NF_DROP;
+			return 0;
+		}
+
+		/*
+		 * Still some space left, store it.
+		 */
+		skb_queue_tail(&cp->ack_skb, skb);
+		spin_unlock(&cp->lock);
+		*verdict = NF_STOLEN;
+		return 0;
+	}
+
+	spin_unlock(&cp->lock);
+	return 1;
+}
diff --git a/net/netfilter/ipvs/ip_vs_xmit.c b/net/netfilter/ipvs/ip_vs_xmit.c
old mode 100644
new mode 100755
index 30b3189..e892928
--- a/net/netfilter/ipvs/ip_vs_xmit.c
+++ b/net/netfilter/ipvs/ip_vs_xmit.c
@@ -10,6 +10,11 @@
  *              2 of the License, or (at your option) any later version.
  *
  * Changes:
+ *	Yi Yang      <specific@gmail.com>
+ *	Shunmin Zhu  <jianghe.zsm@taobao.com>
+ *	Jiaming Wu   <pukong.wjm@taobao.com>  support FULLNAT
+ *
+ *	Yu Bo        <yubo@xiaomi.com>
  *
  */
 
@@ -28,6 +33,7 @@
 #include <linux/icmpv6.h>
 #include <linux/netfilter.h>
 #include <linux/netfilter_ipv4.h>
+#include <linux/netfilter_ipv6.h>
 
 #include <net/ip_vs.h>
 
@@ -70,7 +76,7 @@ __ip_vs_get_out_rt(struct ip_vs_conn *cp, u32 rtos)
 	struct rtable *rt;			/* Route to the other host */
 	struct ip_vs_dest *dest = cp->dest;
 
-	if (dest) {
+	if (dest && dest->addr.ip != IP_VS_DSNAT_RS_ADDR) {
 		spin_lock(&dest->dst_lock);
 		if (!(rt = (struct rtable *)
 		      __ip_vs_dst_check(dest, rtos, 0))) {
@@ -115,6 +121,27 @@ __ip_vs_get_out_rt(struct ip_vs_conn *cp, u32 rtos)
 	return rt;
 }
 
+struct rtable *ip_vs_get_rt(union nf_inet_addr *addr, u32 rtos)
+{
+	struct rtable *rt;	/* Route to the other host */
+
+	struct flowi fl = {
+		.oif = 0,
+		.nl_u = {
+			 .ip4_u = {
+				   .daddr = addr->ip,
+				   .saddr = 0,
+				   .tos = rtos,}},
+	};
+
+	if (ip_route_output_key(&init_net, &rt, &fl)) {
+		IP_VS_DBG_RL("ip_route_output error, dest: %pI4\n", &addr->ip);
+		return NULL;
+	}
+
+	return rt;
+}
+
 #ifdef CONFIG_IP_VS_IPV6
 static struct rt6_info *
 __ip_vs_get_out_rt_v6(struct ip_vs_conn *cp)
@@ -176,9 +203,35 @@ __ip_vs_get_out_rt_v6(struct ip_vs_conn *cp)
 
 	return rt;
 }
-#endif
 
 
+struct rt6_info *ip_vs_get_rt_v6(union nf_inet_addr *addr)
+{
+	struct rt6_info *rt;	/* Route to the other host */
+
+	struct flowi fl = {
+		.oif = 0,
+		.nl_u = {
+			 .ip6_u = {
+				   .daddr = addr->in6,
+				   .saddr = {
+					     .s6_addr32 = {0, 0, 0, 0},
+					     },
+				   },
+			 },
+	};
+
+	rt = (struct rt6_info *)ip6_route_output(&init_net, NULL, &fl);
+	if (!rt) {
+		IP_VS_DBG_RL("ip6_route_output error, dest: %pI6\n",
+			     &addr->in6);
+		return NULL;
+	}
+
+	return rt;
+}
+#endif
+
 /*
  *	Release dest->dst_cache before a dest is removed
  */
@@ -200,6 +253,477 @@ do {							\
 		(rt)->u.dst.dev, dst_output);		\
 } while (0)
 
+/*
+ * Packet has been made sufficiently writable in caller
+ * - inout: 1=in->out, 0=out->in
+ */
+static void ip_vs_nat_icmp(struct sk_buff *skb, struct ip_vs_protocol *pp,
+			   struct ip_vs_conn *cp, int inout)
+{
+	struct iphdr *iph = ip_hdr(skb);
+	unsigned int icmp_offset = iph->ihl * 4;
+	struct icmphdr *icmph = (struct icmphdr *)(skb_network_header(skb) +
+						   icmp_offset);
+	struct iphdr *ciph = (struct iphdr *)(icmph + 1);
+	__u32 fullnat = (IP_VS_FWD_METHOD(cp) == IP_VS_CONN_F_FULLNAT);
+	__u32 dsnat = (IP_VS_FWD_METHOD(cp) == IP_VS_CONN_F_DSNAT);
+
+	if (fullnat | dsnat) {
+		if (inout) {
+			iph->daddr = cp->caddr.ip;
+			ciph->saddr = cp->caddr.ip;
+		} else {
+			iph->saddr = cp->laddr.ip;
+			ciph->daddr = cp->laddr.ip;
+		}
+	}
+
+	if (inout) {
+		iph->saddr = cp->vaddr.ip;
+		ip_send_check(iph);
+		ciph->daddr = cp->vaddr.ip;
+		ip_send_check(ciph);
+	} else {
+		iph->daddr = cp->daddr.ip;
+		ip_send_check(iph);
+		ciph->saddr = cp->daddr.ip;
+		ip_send_check(ciph);
+	}
+
+	/* the TCP/UDP port */
+	if (IPPROTO_TCP == ciph->protocol || IPPROTO_UDP == ciph->protocol) {
+		__be16 *ports = (void *)ciph + ciph->ihl * 4;
+
+		if (fullnat | dsnat) {
+			if (inout)
+				ports[0] = cp->cport;
+			else
+				ports[1] = cp->lport;
+		}
+
+		if (inout)
+			ports[1] = cp->vport;
+		else
+			ports[0] = cp->dport;
+	}
+
+	/* And finally the ICMP checksum */
+	icmph->checksum = 0;
+	icmph->checksum = ip_vs_checksum_complete(skb, icmp_offset);
+	skb->ip_summed = CHECKSUM_UNNECESSARY;
+
+	if (inout)
+		IP_VS_DBG_PKT(11, pp, skb, (void *)ciph - (void *)iph,
+			      "Forwarding altered outgoing ICMP");
+	else
+		IP_VS_DBG_PKT(11, pp, skb, (void *)ciph - (void *)iph,
+			      "Forwarding altered incoming ICMP");
+}
+
+#ifdef CONFIG_IP_VS_IPV6
+static void ip_vs_nat_icmp_v6(struct sk_buff *skb, struct ip_vs_protocol *pp,
+			      struct ip_vs_conn *cp, int inout)
+{
+	struct ipv6hdr *iph = ipv6_hdr(skb);
+	unsigned int icmp_offset = sizeof(struct ipv6hdr);
+	struct icmp6hdr *icmph = (struct icmp6hdr *)(skb_network_header(skb) +
+						     icmp_offset);
+	struct ipv6hdr *ciph = (struct ipv6hdr *)(icmph + 1);
+	__u32 fullnat = (IP_VS_FWD_METHOD(cp) == IP_VS_CONN_F_FULLNAT);
+
+	if (fullnat) {
+		if (inout) {
+			iph->daddr = cp->caddr.in6;
+			ciph->saddr = cp->caddr.in6;
+		} else {
+			iph->saddr = cp->laddr.in6;
+			ciph->daddr = cp->laddr.in6;
+		}
+	}
+
+	if (inout) {
+		iph->saddr = cp->vaddr.in6;
+		ciph->daddr = cp->vaddr.in6;
+	} else {
+		iph->daddr = cp->daddr.in6;
+		ciph->saddr = cp->daddr.in6;
+	}
+
+	/* the TCP/UDP port */
+	if (IPPROTO_TCP == ciph->nexthdr || IPPROTO_UDP == ciph->nexthdr) {
+		__be16 *ports = (void *)ciph + sizeof(struct ipv6hdr);
+
+		if (fullnat) {
+			if (inout)
+				ports[0] = cp->cport;
+			else
+				ports[1] = cp->lport;
+		}
+
+		if (inout)
+			ports[1] = cp->vport;
+		else
+			ports[0] = cp->dport;
+	}
+
+	/* And finally the ICMP checksum */
+	icmph->icmp6_cksum = 0;
+	/* TODO IPv6: is this correct for ICMPv6? */
+	ip_vs_checksum_complete(skb, icmp_offset);
+	skb->ip_summed = CHECKSUM_UNNECESSARY;
+
+	if (inout)
+		IP_VS_DBG_PKT(11, pp, skb, (void *)ciph - (void *)iph,
+			      "Forwarding altered outgoing ICMPv6");
+	else
+		IP_VS_DBG_PKT(11, pp, skb, (void *)ciph - (void *)iph,
+			      "Forwarding altered incoming ICMPv6");
+}
+#endif
+
+/* Response transmit icmp to client
+ * Used for NAT/LOCAL.
+ */
+int
+ip_vs_normal_response_icmp_xmit(struct sk_buff *skb, struct ip_vs_protocol *pp,
+				struct ip_vs_conn *cp, int offset)
+{
+	unsigned int verdict = NF_DROP;
+
+	if (!skb_make_writable(skb, offset))
+		goto out;
+
+	ip_vs_nat_icmp(skb, pp, cp, 1);
+
+	skb->ipvs_property = 1;
+	verdict = NF_ACCEPT;
+
+      out:
+	return verdict;
+}
+
+#ifdef CONFIG_IP_VS_IPV6
+
+int
+ip_vs_normal_response_icmp_xmit_v6(struct sk_buff *skb,
+				   struct ip_vs_protocol *pp,
+				   struct ip_vs_conn *cp, int offset)
+{
+	unsigned int verdict = NF_DROP;
+
+	if (!skb_make_writable(skb, offset))
+		goto out;
+
+	ip_vs_nat_icmp_v6(skb, pp, cp, 1);
+
+	skb->ipvs_property = 1;
+	verdict = NF_ACCEPT;
+
+      out:
+	return verdict;
+}
+
+#endif
+
+/* Response transmit icmp to client
+ * Used for NAT / local client / FULLNAT.
+ */
+int
+ip_vs_fnat_response_icmp_xmit(struct sk_buff *skb, struct ip_vs_protocol *pp,
+			      struct ip_vs_conn *cp, int offset)
+{
+	struct rtable *rt;	/* Route to the other host */
+	int mtu;
+	struct iphdr *iph = ip_hdr(skb);
+
+	/* lookup route table */
+	if (!(rt = ip_vs_get_rt(&cp->caddr, RT_TOS(iph->tos))))
+		goto tx_error_icmp;
+
+	/* MTU checking */
+	mtu = dst_mtu(&rt->u.dst);
+	if ((skb->len > mtu) && (iph->frag_off & htons(IP_DF))) {
+		ip_rt_put(rt);
+		IP_VS_DBG_RL_PKT(0, pp, skb, 0,
+				 "fnat_response_icmp(): frag needed for");
+		goto tx_error;
+	}
+
+	/* copy-on-write the packet before mangling it */
+	if (!skb_make_writable(skb, offset))
+		goto tx_error_put;
+
+	if (skb_cow(skb, rt->u.dst.dev->hard_header_len))
+		goto tx_error_put;
+
+	/* drop old route */
+	skb_dst_drop(skb);
+	skb_dst_set(skb, &rt->u.dst);
+
+	ip_vs_nat_icmp(skb, pp, cp, 1);
+
+	/* Another hack: avoid icmp_send in ip_fragment */
+	skb->local_df = 1;
+
+	IP_VS_XMIT(PF_INET, skb, rt);
+
+	return NF_STOLEN;
+
+      tx_error_icmp:
+	dst_link_failure(skb);
+      tx_error:
+	kfree_skb(skb);
+	return NF_STOLEN;
+      tx_error_put:
+	ip_rt_put(rt);
+	goto tx_error;
+}
+
+#ifdef CONFIG_IP_VS_IPV6
+
+int
+ip_vs_fnat_response_icmp_xmit_v6(struct sk_buff *skb, struct ip_vs_protocol *pp,
+				 struct ip_vs_conn *cp, int offset)
+{
+	struct rt6_info *rt;	/* Route to the other host */
+	int mtu;
+
+	/* lookup route table */
+	if (!(rt = ip_vs_get_rt_v6(&cp->caddr)))
+		goto tx_error_icmp;
+
+	/* MTU checking */
+	mtu = dst_mtu(&rt->u.dst);
+	if (skb->len > mtu) {
+		dst_release(&rt->u.dst);
+		IP_VS_DBG_RL("%s(): frag needed\n", __func__);
+		goto tx_error;
+	}
+
+	/* copy-on-write the packet before mangling it */
+	if (!skb_make_writable(skb, offset))
+		goto tx_error_put;
+
+	if (skb_cow(skb, rt->u.dst.dev->hard_header_len))
+		goto tx_error_put;
+
+	/* drop old route */
+	skb_dst_drop(skb);
+	skb_dst_set(skb, &rt->u.dst);
+
+	ip_vs_nat_icmp_v6(skb, pp, cp, 1);
+
+	/* Another hack: avoid icmp_send in ip_fragment */
+	skb->local_df = 1;
+
+	IP_VS_XMIT(PF_INET6, skb, rt);
+
+	return NF_STOLEN;
+
+      tx_error_icmp:
+	dst_link_failure(skb);
+      tx_error:
+	kfree_skb(skb);
+	return NF_STOLEN;
+      tx_error_put:
+	dst_release(&rt->u.dst);
+	goto tx_error;
+}
+
+#endif
+
+/* Response transmit to client
+ * Used for NAT/Local.
+ */
+int
+ip_vs_normal_response_xmit(struct sk_buff *skb, struct ip_vs_protocol *pp,
+			   struct ip_vs_conn *cp, int ihl)
+{
+	/* copy-on-write the packet before mangling it */
+	if (!skb_make_writable(skb, ihl))
+		goto drop;
+
+	/* mangle the packet */
+	if (pp->snat_handler && !pp->snat_handler(skb, pp, cp))
+		goto drop;
+
+	ip_hdr(skb)->saddr = cp->vaddr.ip;
+	ip_send_check(ip_hdr(skb));
+
+	/* For policy routing, packets originating from this
+	 * machine itself may be routed differently to packets
+	 * passing through.  We want this packet to be routed as
+	 * if it came from this machine itself.  So re-compute
+	 * the routing information.
+	 */
+	if (ip_route_me_harder(skb, RTN_LOCAL) != 0)
+		goto drop;
+
+	skb->ipvs_property = 1;
+
+	return NF_ACCEPT;
+
+      drop:
+	kfree_skb(skb);
+	return NF_STOLEN;
+}
+
+#ifdef CONFIG_IP_VS_IPV6
+
+int
+ip_vs_normal_response_xmit_v6(struct sk_buff *skb, struct ip_vs_protocol *pp,
+			      struct ip_vs_conn *cp, int ihl)
+{
+	/* copy-on-write the packet before mangling it */
+	if (!skb_make_writable(skb, ihl))
+		goto drop;
+
+	/* mangle the packet */
+	if (pp->snat_handler && !pp->snat_handler(skb, pp, cp))
+		goto drop;
+
+	ipv6_hdr(skb)->saddr = cp->vaddr.in6;
+
+	/* For policy routing, packets originating from this
+	 * machine itself may be routed differently to packets
+	 * passing through.  We want this packet to be routed as
+	 * if it came from this machine itself.  So re-compute
+	 * the routing information.
+	 */
+	if (ip6_route_me_harder(skb) != 0)
+		goto drop;
+
+	skb->ipvs_property = 1;
+
+	return NF_ACCEPT;
+
+      drop:
+	kfree_skb(skb);
+	return NF_STOLEN;
+}
+
+#endif
+
+/* Response transmit to client
+ * Used for FULLNAT.
+ */
+int
+ip_vs_fnat_response_xmit(struct sk_buff *skb, struct ip_vs_protocol *pp,
+			 struct ip_vs_conn *cp, int ihl)
+{
+	struct rtable *rt;	/* Route to the other host */
+	int mtu;
+	struct iphdr *iph = ip_hdr(skb);
+
+	/* lookup route table */
+	if (!(rt = ip_vs_get_rt(&cp->caddr, RT_TOS(iph->tos))))
+		goto tx_error_icmp;
+
+	/* MTU checking */
+	mtu = dst_mtu(&rt->u.dst);
+	if ((skb->len > mtu) && (iph->frag_off & htons(IP_DF))) {
+		ip_rt_put(rt);
+		icmp_send(skb, ICMP_DEST_UNREACH, ICMP_FRAG_NEEDED, htonl(mtu));
+		IP_VS_DBG_RL_PKT(0, pp, skb, 0,
+				 "handle_fnat_response(): frag needed for");
+		goto tx_error;
+	}
+
+	/* copy-on-write the packet before mangling it */
+	if (!skb_make_writable(skb, ihl))
+		goto tx_error_put;
+
+	if (skb_cow(skb, rt->u.dst.dev->hard_header_len))
+		goto tx_error_put;
+
+	/* drop old route */
+	skb_dst_drop(skb);
+	skb_dst_set(skb, &rt->u.dst);
+
+	/* mangle the packet */
+	if (pp->fnat_out_handler && !pp->fnat_out_handler(skb, pp, cp))
+		goto tx_error;
+
+	ip_hdr(skb)->saddr = cp->vaddr.ip;
+	ip_hdr(skb)->daddr = cp->caddr.ip;
+	ip_send_check(ip_hdr(skb));
+
+	/* Another hack: avoid icmp_send in ip_fragment */
+	skb->local_df = 1;
+
+	IP_VS_XMIT(PF_INET, skb, rt);
+
+	return NF_STOLEN;
+
+      tx_error_icmp:
+	dst_link_failure(skb);
+      tx_error:
+	kfree_skb(skb);
+	return NF_STOLEN;
+      tx_error_put:
+	ip_rt_put(rt);
+	goto tx_error;
+}
+
+#ifdef CONFIG_IP_VS_IPV6
+
+int
+ip_vs_fnat_response_xmit_v6(struct sk_buff *skb, struct ip_vs_protocol *pp,
+			    struct ip_vs_conn *cp, int ihl)
+{
+	struct rt6_info *rt;	/* Route to the other host */
+	int mtu;
+
+	/* lookup route table */
+	if (!(rt = ip_vs_get_rt_v6(&cp->caddr)))
+		goto tx_error_icmp;
+
+	/* MTU checking */
+	mtu = dst_mtu(&rt->u.dst);
+	if (skb->len > mtu) {
+		dst_release(&rt->u.dst);
+		icmpv6_send(skb, ICMPV6_PKT_TOOBIG, 0, mtu, skb->dev);
+		IP_VS_DBG_RL_PKT(0, pp, skb, 0,
+				 "handle_fnat_response_v6(): frag needed for");
+		goto tx_error;
+	}
+
+	/* copy-on-write the packet before mangling it */
+	if (!skb_make_writable(skb, ihl))
+		goto tx_error_put;
+
+	if (skb_cow(skb, rt->u.dst.dev->hard_header_len))
+		goto tx_error_put;
+
+	/* drop old route */
+	skb_dst_drop(skb);
+	skb_dst_set(skb, &rt->u.dst);
+
+	/* mangle the packet */
+	if (pp->fnat_out_handler && !pp->fnat_out_handler(skb, pp, cp))
+		goto tx_error;
+
+	ipv6_hdr(skb)->saddr = cp->vaddr.in6;
+	ipv6_hdr(skb)->daddr = cp->caddr.in6;
+
+	/* Another hack: avoid icmp_send in ip_fragment */
+	skb->local_df = 1;
+
+	IP_VS_XMIT(PF_INET6, skb, rt);
+
+	return NF_STOLEN;
+
+      tx_error_icmp:
+	dst_link_failure(skb);
+      tx_error:
+	kfree_skb(skb);
+	return NF_STOLEN;
+      tx_error_put:
+	dst_release(&rt->u.dst);
+	goto tx_error;
+}
+
+#endif
 
 /*
  *      NULL transmitter (do nothing except return NF_ACCEPT)
@@ -502,6 +1026,163 @@ tx_error_put:
 }
 #endif
 
+/*
+ *      FULLNAT transmitter (only for outside-to-inside fullnat forwarding)
+ *      Not used for related ICMP
+ */
+int
+ip_vs_fnat_xmit(struct sk_buff *skb, struct ip_vs_conn *cp,
+		struct ip_vs_protocol *pp)
+{
+	struct rtable *rt;	/* Route to the other host */
+	int mtu;
+	struct iphdr *iph = ip_hdr(skb);
+
+	EnterFunction(10);
+
+	/* check if it is a connection of no-client-port */
+	if (unlikely(cp->flags & IP_VS_CONN_F_NO_CPORT)) {
+		__be16 _pt, *p;
+		p = skb_header_pointer(skb, iph->ihl * 4, sizeof(_pt), &_pt);
+		if (p == NULL)
+			goto tx_error;
+		ip_vs_conn_fill_cport(cp, *p);
+		IP_VS_DBG(10, "filled cport=%d\n", ntohs(*p));
+	}
+
+	if (!(rt = __ip_vs_get_out_rt(cp, RT_TOS(iph->tos))))
+		goto tx_error_icmp;
+
+	/* MTU checking */
+	mtu = dst_mtu(&rt->u.dst);
+	if ((skb->len > mtu) && (iph->frag_off & htons(IP_DF))) {
+		ip_rt_put(rt);
+		icmp_send(skb, ICMP_DEST_UNREACH, ICMP_FRAG_NEEDED, htonl(mtu));
+		IP_VS_DBG_RL_PKT(0, pp, skb, 0,
+				 "ip_vs_nat_xmit(): frag needed for");
+		goto tx_error;
+	}
+
+	/* copy-on-write the packet before mangling it */
+	if (!skb_make_writable(skb, sizeof(struct iphdr)))
+		goto tx_error_put;
+
+	if (skb_cow(skb, rt->u.dst.dev->hard_header_len))
+		goto tx_error_put;
+
+	/* drop old route */
+	skb_dst_drop(skb);
+	skb_dst_set(skb, &rt->u.dst);
+
+	/* mangle the packet */
+	if (pp->fnat_in_handler && !pp->fnat_in_handler(&skb, pp, cp))
+		goto tx_error;
+	ip_hdr(skb)->saddr = cp->laddr.ip;
+	ip_hdr(skb)->daddr = cp->daddr.ip;
+	ip_send_check(ip_hdr(skb));
+
+	IP_VS_DBG_PKT(10, pp, skb, 0, "After FNAT-IN");
+
+	/* FIXME: when application helper enlarges the packet and the length
+	   is larger than the MTU of outgoing device, there will be still
+	   MTU problem. */
+
+	/* Another hack: avoid icmp_send in ip_fragment */
+	skb->local_df = 1;
+
+	IP_VS_XMIT(PF_INET, skb, rt);
+
+	LeaveFunction(10);
+	return NF_STOLEN;
+
+      tx_error_icmp:
+	dst_link_failure(skb);
+      tx_error:
+	LeaveFunction(10);
+	kfree_skb(skb);
+	return NF_STOLEN;
+      tx_error_put:
+	ip_rt_put(rt);
+	goto tx_error;
+}
+
+#ifdef CONFIG_IP_VS_IPV6
+int
+ip_vs_fnat_xmit_v6(struct sk_buff *skb, struct ip_vs_conn *cp,
+		   struct ip_vs_protocol *pp)
+{
+	struct rt6_info *rt;	/* Route to the other host */
+	int mtu;
+
+	EnterFunction(10);
+
+	/* check if it is a connection of no-client-port */
+	if (unlikely(cp->flags & IP_VS_CONN_F_NO_CPORT)) {
+		__be16 _pt, *p;
+		p = skb_header_pointer(skb, sizeof(struct ipv6hdr),
+				       sizeof(_pt), &_pt);
+		if (p == NULL)
+			goto tx_error;
+		ip_vs_conn_fill_cport(cp, *p);
+		IP_VS_DBG(10, "filled cport=%d\n", ntohs(*p));
+	}
+
+	rt = __ip_vs_get_out_rt_v6(cp);
+	if (!rt)
+		goto tx_error_icmp;
+
+	/* MTU checking */
+	mtu = dst_mtu(&rt->u.dst);
+	if (skb->len > mtu) {
+		dst_release(&rt->u.dst);
+		icmpv6_send(skb, ICMPV6_PKT_TOOBIG, 0, mtu, skb->dev);
+		IP_VS_DBG_RL_PKT(0, pp, skb, 0,
+				 "ip_vs_nat_xmit_v6(): frag needed for");
+		goto tx_error;
+	}
+
+	/* copy-on-write the packet before mangling it */
+	if (!skb_make_writable(skb, sizeof(struct ipv6hdr)))
+		goto tx_error_put;
+
+	if (skb_cow(skb, rt->u.dst.dev->hard_header_len))
+		goto tx_error_put;
+
+	/* drop old route */
+	skb_dst_drop(skb);
+	skb_dst_set(skb, &rt->u.dst);
+
+	/* mangle the packet */
+	if (pp->fnat_in_handler && !pp->fnat_in_handler(&skb, pp, cp))
+		goto tx_error;
+	ipv6_hdr(skb)->saddr = cp->laddr.in6;
+	ipv6_hdr(skb)->daddr = cp->daddr.in6;
+
+	IP_VS_DBG_PKT(10, pp, skb, 0, "After FNAT-IN");
+
+	/* FIXME: when application helper enlarges the packet and the length
+	   is larger than the MTU of outgoing device, there will be still
+	   MTU problem. */
+
+	/* Another hack: avoid icmp_send in ip_fragment */
+	skb->local_df = 1;
+
+	IP_VS_XMIT(PF_INET6, skb, rt);
+
+	LeaveFunction(10);
+	return NF_STOLEN;
+
+      tx_error_icmp:
+	dst_link_failure(skb);
+      tx_error:
+	LeaveFunction(10);
+	kfree_skb(skb);
+	return NF_STOLEN;
+      tx_error_put:
+	dst_release(&rt->u.dst);
+	goto tx_error;
+}
+#endif
 
 /*
  *   IP Tunneling transmitter
@@ -869,7 +1550,8 @@ ip_vs_icmp_xmit(struct sk_buff *skb, struct ip_vs_conn *cp,
 	/* The ICMP packet for VS/TUN, VS/DR and LOCALNODE will be
 	   forwarded directly here, because there is no need to
 	   translate address/port back */
-	if (IP_VS_FWD_METHOD(cp) != IP_VS_CONN_F_MASQ) {
+	if ((IP_VS_FWD_METHOD(cp) != IP_VS_CONN_F_MASQ) &&
+	    (IP_VS_FWD_METHOD(cp) != IP_VS_CONN_F_FULLNAT)) {
 		if (cp->packet_xmit)
 			rc = cp->packet_xmit(skb, cp, pp);
 		else
@@ -943,7 +1625,8 @@ ip_vs_icmp_xmit_v6(struct sk_buff *skb, struct ip_vs_conn *cp,
 	/* The ICMP packet for VS/TUN, VS/DR and LOCALNODE will be
 	   forwarded directly here, because there is no need to
 	   translate address/port back */
-	if (IP_VS_FWD_METHOD(cp) != IP_VS_CONN_F_MASQ) {
+	if ((IP_VS_FWD_METHOD(cp) != IP_VS_CONN_F_MASQ) &&
+	    (IP_VS_FWD_METHOD(cp) != IP_VS_CONN_F_FULLNAT)) {
 		if (cp->packet_xmit)
 			rc = cp->packet_xmit(skb, cp, pp);
 		else
